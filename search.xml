<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>minimizing_congestion_in_general_networks</title>
      <link href="/ExtensiveReading/minimizing-congestion-in-general-networks/"/>
      <url>/ExtensiveReading/minimizing-congestion-in-general-networks/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data-Management-and-Routing-in-General-Networks</title>
      <link href="/ExtensiveReading/Data-Management-and-Routing-in-General-Networks/"/>
      <url>/ExtensiveReading/Data-Management-and-Routing-in-General-Networks/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>oblivious_robust_routing</title>
      <link href="/ExtensiveReading/oblivious-robust-routing/"/>
      <url>/ExtensiveReading/oblivious-robust-routing/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><p>​    近年来，NTRA-DOMAIN流量工程已广受欢迎-好的流量工程工具可以极大地促进大型运营IP网络的管理和性能[4]，[23]。 流量工程的两个重要组成部分是了解流量，以及配置（和设计）路由协议。 这两个部分是相关的-对流量矩阵（TM）的良好理解和流量动态可以通过更适当的流量路由来更好地利用链路容量[11]，这已广为接受。 从理论上讲，如果TM确切已知，则可以通过求解相应的多商品流问题实例来获得针对它的最佳路由[18]。 通过使用最常用的域内路由协议OSPF / IS-IS，可以根据TM调整链路权重，以经常获得接近最佳的利用率[12]。 不幸的是，测量和预测交通需求是一个虚假的问题[4]，[23]。 在网络的所有链路和出口/入口点上很少进行流量测量，甚至更难估计起点-目的地流量集合。 此外，需求会随着时间的变化而变化-在昼夜周期中，并且由于网络内部或外部的特殊事件或故障而难以预测。 这些问题最近已通过模型和测量工具[7]，[10]，[11]，[17]，[21]解决，这些工具和工具可以推断和估算交通需求。 </p><p>​    但是，似乎最大的希望就是对需求的大概了解，而不一定是非常当前的需求。 <u>即使已知当前需求，它们的动态性质也带来了挑战</u>：一方面，希望路由对当前流量需求有效，因此可以根据需求的变化进行调整。 另一方面，人们希望将更改限制在路由上，因为在系统达到一致状态时，更改可能会由于路径移动和收敛时间而导致服务中断。 对于OSPF / IS-IS路由，在[13]中探讨了这种折衷方案，<u>该技术开发了一种技术，该技术可在TM更改时将更改量限制为OSPF / IS-IS链路权重（确定路由</u>）。因此，良好的系统工程要求设计在一定条件下具有鲁棒性。 也就是说，可以针对各种适用的流量需求几乎最佳地执行路由。 我们的主要目标是探索这种路由的可行性，也就是说，在我们了解流量需求的范围内，了解可获得的路由质量的敏感性。 尽管对这两个基本的交通工程构建块，路由和TM估计都进行了深入研究，但对它们之间的相互作用及其潜在的性能折衷还没有很好地理解。</p><p>​    尽管人们普遍认为了解流量需求对于实现网络的良好利用是必不可少的[4]，[11]，[17]，[23]，但这种信念从未得到过仔细的量化：在对TM performance没有认知的情况下（ 或只有基本认知 (ballpark knowledge) 的情况下），如何设计路由性能？ 也就是说，为了保证良好的利用率，需要对流量需求进行估算的精度如何？ 当流量需求发生变化时，在某些性能保证范围内可容许的变化范围是多少？ 当实际流量需求偏离假定流量需求时，针对特定TM设计的最佳路由将如何执行？ 我们提出的问题涉及受管IP网络的基本限制和折衷-我们希望随着路由协议的发展，这些问题将继续存在-特别是在部署更复杂的OSPF / IS-IS权重调整时[12]，[13]  ，并逐步部署了更灵活的协议，例如多协议标签交换（MPLS）协议[3]，[20]及其未来的后续产品。 </p><p>​    为了寻求这些问题的答案，需要一种方法来衡量给定路由在一定范围的流量需求下的性能，以及一种设计在适当范围的流量需求下可以良好运行的路由的方法。 但是，尽管先前已知的算法可以为特定的TM（或一小部分TM）获得最佳路由，但是它们不能扩展为在广泛的TM上工作。 我们工作的核心是新颖的算法，在此算法的基础上，我们构建了可为一系列可能的TM生成最佳路由的软件。 该路由可以在TM范围内最佳地平衡负载-通过为该TM量身定制的最佳路由，可以最大程度地减小任何TM的最大链路利用率偏离最佳状态的程度。 我们的软件还使我们能够通过在适用的TM范围内计算每个路由获得的最差性能比来比较不同的路由。 <u>我们的评估利用了Rocketfuel项目[16]，[22]和[17]中研究的测试网络提供的各种ISP的地图</u>。 </p><p>​    第II节中描述了数据，第III节中描述了我们的绩效指标和方法，随后在IV节中给出了评估结果。 我们使用的LP模型和相关理论在第V–VI节中进行了开发。 在第七节中，我们对一些简单的网络结构进行了渐进分析，对我们的评估进行了补充。</p><h1 id="2-Data"><a href="#2-Data" class="headerlink" title="2 Data"></a>2 Data</h1><blockquote><p>我们描述了我们使用的测试拓扑。 不幸的是，ISP将其拓扑视为专有信息，直到最近，研究人员不得不为专有信息合成数据作好准备。 因此，结论通常缺乏通用性和可验证性。  Rocketfuel项目[22]最近取得了突破，该项目开发了一套新的测量技术，并发布了各种ISP的代表性集合的公开可用的近似路由器级拓扑。 我们使用启发式方法通过链接容量和流量矩阵来扩充此数据。</p></blockquote><h2 id="2-1-Topologies"><a href="#2-1-Topologies" class="headerlink" title="2.1 Topologies"></a>2.1 Topologies</h2><blockquote><p>我们使用来自Rocketfuel数据集的六个ISP映射，这些映射具有相应的OSPF / IS-IS权重[16]。 然后，我们折叠拓扑，以使“节点”对应于城市，以获取近似PoP到PoP（存在点）拓扑。 我们还包括在[17]中评估的14节点和25link的“第1层PoP到PoP拓扑”（在续篇中标记为“ N-14”）。 表I列出了研究的拓扑。</p></blockquote><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201222102423106.png" alt="image-20201222102423106"></p><blockquote><p>ROCKETFUEL（按名称和名称）和[17]（N-14）网络的拓扑。表中列出了我们称为PoP的路由器和链接的数量，城市和城市间链接的数量。 如果删除了1个连接的组件（“悬挂的树”），则最后两个列（减少的城市和链接）列出了剩余的城市和链接的数量。这些组件不会改变不同路由的相对质量（请参阅LEMMA 5.2）。  ，我们可以根据这些减少的图表更快地执行某些计算</p></blockquote><h1 id="2-2-Capacities"><a href="#2-2-Capacities" class="headerlink" title="2.2 Capacities"></a>2.2 Capacities</h1><blockquote><p>Rocketfuel和[17]中提供的拓扑不包括链接的容量，这是我们研究所必需的。 火箭燃料图确实包含派生的链路OSPF / IS-IS权重[16]，这些权重经计算以匹配观察到的路线。 在没有容量的其他信息的情况下，我们使用权重通过根据容量“转变” Cisco推荐的链路权重默认设置来关联希望兼容的能力：Cisco OSPF权重的默认设置为： 将每个链接的权重设置为与它的容量成反比例[8]。</p></blockquote><h2 id="2-3-TMs"><a href="#2-3-TMs" class="headerlink" title="2.3 TMs"></a>2.3 TMs</h2><blockquote><p>通常无法提供准确的流量矩阵。 它们不仅被ISP视为专有，而且，如引言中所述，很难以合理的准确性获得它们。 因此，我们使用了两个合成交通矩阵族，我们将其称为Bimodal和Gravity TM。 </p></blockquote><ul><li>Bimodal TM：观察到只有一小部分的原产地（OD）对具有非常大的流量[6]。 该模型假设这些流量控制了拥塞点。 随机双峰分布随机抽样一小部分OD对，然后从某个范围内随机地均匀分配一个对。[17]中使用了随机双峰分布（和其他随机分布）。</li><li>Gravity TM：由于在设计网络时会考虑一些流量需求，因此需要针对此类流量需求评估不同路由的性能。 我们使用了类似于[21]中建议的Gravity模型来生成“对应”网络的需求。  [21]中的工作提出了一种从对骨干网流入每个PoP的流量进行测量来推断completeTM的方法。 然后，外推法假设来自某个PoP的流量部分在其他PoP处所吸收的流量与在这些PoP处所吸收的总流量成比例。 根据[21]，这个简单的模型出奇地准确。 由于我们甚至没有这些更严格的流量值，因此我们使用了基于容量的启发式方法，该方法假设每个PoP的流入/流出流量与连接链路的总容量成比例。 然后，我们按照[21]中的引力模型来推算完整的TM。</li></ul><h1 id="3-METRICS-AND-METHODOLOGY"><a href="#3-METRICS-AND-METHODOLOGY" class="headerlink" title="3. METRICS AND METHODOLOGY"></a>3. METRICS AND METHODOLOGY</h1><h2 id="3-1-Routing"><a href="#3-1-Routing" class="headerlink" title="3.1 Routing"></a>3.1 Routing</h2><p>f<del>a,b</del>(i,j)是一个比例</p><h2 id="3-2-Metrics"><a href="#3-2-Metrics" class="headerlink" title="3.2 Metrics"></a>3.2 Metrics</h2><p>在一个TM上的指标</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/22/103552-236240.png" alt="image-20201222103535790"></p><p>最优策略的得分</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/22/103612-632161.png" alt="image-20201222103551573"></p><p>对策略的评分</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/22/103637-593208.png" alt="image-20201222103618239"></p><p>一组TM上的评分</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/22/103650-657500.png" alt="image-20201222103646088"></p><p>​    我们将性能比称为路由的oblivious performance ratio。 oblivious ratio是路由相对于所有TM而言最差的性能比率。 最小遗忘率的路由是最佳遗忘路由，其遗忘率是网络的最佳遗忘率。</p><p>​    为了更好地解释性能比，请注意，在集合或链路容量中TM的缩放比例下，它是不变的。 <u><strong>性能比构成了给定拓扑和一组TM上不同路由的比较度量，但是它并不是不同网络拓扑之间有意义的比较度量，</strong>它是相对于最小可能的最大链路利用率来定义的，但是 最小最大利用率本身随拓扑而变化</u>。 <u>还要注意，可能存在许多可能的最佳路由，并且它们在特定TM上的执行方式可能会有所不同</u>。 第七节提供了一些简单网络上的最佳遗忘性能比的说明性示例和分析。</p><h2 id="3-3-computing-an-optimal-routing"><a href="#3-3-computing-an-optimal-routing" class="headerlink" title="3.3 computing an optimal routing"></a>3.3 computing an optimal routing</h2><p>​    直到最近，已知的工具都可以优化针对给定TM的路由，但是除了特定的高度结构化的拓扑（例如超立方网络）以外，关于如何有效地针对广泛的集合构建最佳路由的了解还很少 需求和最佳性能比率是多少。  Räcke[19]最近的一项突破性工作表明（存在）一个令人惊讶的上限：<u><strong>所有对称网络（即，两个方向上的链路容量相同的网络，通常在大型骨干网中都是这样）存在一个路由whose oblivious ratio是节点的对数的多项式。</strong></u>【一个最坏情况，也就是一个下界被bound住了】Räcke的存在边界触发了针对任何网络（对称与否）的最优遗忘路由[5]的多项式时间构造的发展。 文献[5]中的多项式时间算法基于将椭球算法应用于指数大小的LP模型，因此不适用于大型网络。 我们开发了一种新颖，简单，快速的算法（渐进式和实现式），用于计算基于多项式大小LP公式的最佳遗忘路由（请参见第VI节中的详细信息）。 然后，我们扩展模型以针对OD对要求的范围限制优化路由。 在我们的仿真中，我们使用==CPLEX LP解算器==[9]来解决这些LP（也可以应用其他公共领域LP解算器）。</p><h2 id="3-4-Limitations"><a href="#3-4-Limitations" class="headerlink" title="3.4 Limitations"></a>3.4 Limitations</h2><p>​    我们在本节结束时讨论了局限性。 我们的模型和指标无法捕获流量需求与最终实际吞吐量之间的相互作用，而是通过对所有需求的确进行路由而获得的最大链路利用率来比较不同的路由。 这是一个合理的指标，因为利用率越高，数据包丢失和拥塞的可能性就越大。 我们的评估重点是点对点（OD对）需求，而不是点对多点。 点对多点需求通常与大型ISP有关（例如，当有多个对等点指向不同的ISP，因此许多出口点中的任何一个都可以互换使用[11]）。 这种点对点“限制”主要是由于我们数据的局限性，原则上我们的技术和软件可以扩展到涵盖点对多点的需求。 我们针对最大链路利用率和性能比进行了优化。 在特定的实现上下文中，我们的方法可以考虑其他因素（例如，使用MPLS时，除了容量利用率外，可能还需要优化MPLS标签堆栈大小或预配置路径的数量。）。</p><h1 id="4-Experiments-and-results"><a href="#4-Experiments-and-results" class="headerlink" title="4. Experiments and results"></a>4. Experiments and results</h1><p>​    我们要解决的第一个问题是，在不了解流量需求的情况下，在我们的测试网络上可获得的最佳性能比保证是什么？ 表II列出了三种不同路由的遗忘性能比：最佳遗忘路由（使用6-C节中的LP公式计算）和另外两个自然路由-OSPF路由（使用数据集中提供的权重），以及 Gravity TM的最佳路由（通过求解多商品流LP计算）。 每个给定路由的性能比是使用第6-A节中的“slave 属LP”公式计算得出的。 评估的拓扑上的最佳遗忘性能比范围为1.425-1.972，这意味着这些网络具有的路由可确保在任何TM上具有最大链路利用率，最大可达最大表利用率的43％-97％。 为此TM量身定制的可能路由。 评估的其他两个路由的遗忘率明显更差（2-3位），这意味着在某些TM上，它们与定制的最佳路由相差很远。 这些差距表明，在不使用我们的优化工具的情况下，不可能以临时的方式获得接近最佳的遗忘性能比。 </p><p>​    最大利用率的43％–97％（最坏的情况）开销对于正在运行的ISP而言是微不足道的-但是，好消息是，即使不了解流量需求也可以获得这样的保证。 然而，幸运的是，尽管通常很难获得TM的准确的当前估算值，但有关TM的信息还是很多的。  TM可以在某个已知范围内变化，或者可以估计到某个已知精度内。 在这种情况下，我们希望对处于一定范围内的所有TM提供性能保证。 我们要研究的下一个问题是可达到的性能比对已知TM的“误差范围”的敏感性。  （请注意，随着我们扩展针对其计算性能比率的TM集合，该比率只能增加。）</p><ul><li><p>一些定义</p><p>error margin $\omega$</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20201222110046821.png" alt="image-20201222110046821" style="zoom: 80%;" /></li></ul><h1 id="5-basic-properties"><a href="#5-basic-properties" class="headerlink" title="5. basic properties"></a>5. basic properties</h1><p>​    我们建立一些基本属性。 我们将基本TM的最佳路由的性能作为余量的函数进行限制，并建立一些属性以减少实例所需的LP模型的大小。</p><h2 id="5-1-Performance-Deterioration-as-a-Function-of-Margin"><a href="#5-1-Performance-Deterioration-as-a-Function-of-Margin" class="headerlink" title="5.1 Performance Deterioration as a Function of Margin"></a>5.1 Performance Deterioration as a Function of Margin</h2><ul><li>Lemma 5.1</li></ul><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201222111530208.png" alt="image-20201222111530208"></p><p>这是渐近严格的，也就是说，存在无限的实例家族，其中</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/22/111544-931477.png" alt="image-20201222111522288"></p><h2 id="5-2-Reducing-the-Problem-Size"><a href="#5-2-Reducing-the-Problem-Size" class="headerlink" title="5.2  Reducing the Problem Size"></a>5.2  Reducing the Problem Size</h2><p>​    以下引理表明，出于计算性能比率的目的，我们可以“factor out”网络中无法实现路径diversity的部分（因此，所有路由都将执行相同的操作。）。我们使用此引理来减小输入拓扑的大小。</p><ul><li><p>引理5.2：移除degree-one的节点不会影响网络的oblivious ratio。 同样，它不会影响任何一组TM的最佳性能比。 </p><blockquote><p>引理2是以下引理的推论。</p></blockquote></li><li><p>引理5.3：网络的最佳遗忘率可以通过将网络划分为2个边缘连接的组件，并在这些组件上获取最大的遗忘率来计算。 </p><p>​    证明：如果网络不是2边缘连接的，则可以将其划分为两个非空组件，并通过和边缘连接。 很容易看出，的最佳遗忘率至少是和的最大最佳遗忘率的比：对于仅在两个都存在的OD对上具有正需求的TM所获得的最佳性能比on分别 位于）等于（分别为）的最佳遗忘率。 要看到这一点，请注意所有离开/进入的流都必须经过边缘，因此将需求内部路由到边缘并流出边缘永远没有优势，因为该流将必须在同一边缘上返回并形成一个 流周期（对称参数表示）。 的最佳遗忘率至少是这些受限制的TM集合的最佳性能比率。</p><hr><p>​    以下引理指出，对称TM上具有对称定向链路的网络的最佳遗忘率（即，两个方向上的链路容量均相等）与通过替换每个集合而得出的无向网络的遗忘率相同 由具有相同容量的单个无向链接组成的有向链接。</p><p>这个引理意味着无向图的已知边界会carry out到“real” backbone网络（链接是有向的和对称的）。 此引理还可用于减少LP模型的大小。</p></li><li><p>引理5.4：考虑一个无向网络G，以及一个由其衍生的直接网络G^’^，方法是用两个反平行弧替换每条边e，其容量与e相同。  </p><ul><li>G^’^具有对称的最佳遗忘路由。</li><li>（在所有TM上）的最佳遗忘率等于在所有对称TM上的最佳性能率。 此外，的最佳遗忘路由对应于对称TM的最佳路由。<br>   证明：考虑对称有向网络和路由。 我们推导了一个对称路由，其最多具有与相同的遗忘性能比。 设为通过反转流向和OD对获得的“反向”路由。</li></ul></li></ul><blockquote><p>我对这条引理的感觉就是  这是在证明 现实中backbone network (which 通常是双向对称的)的最佳oblivious routing可以通过这种方法降低计算复杂度</p></blockquote><p>可以将引理概括为相对于对称的任何TM子集保持最佳性能比。 一个有趣的问题涉及定向对称网络上所有TM的最佳性能比与对称TM上的最佳性能比之间的关系。 <u><strong>不难看出前者至少是后者的，但最多是后者的两倍</strong></u>。 实际上，任何对称路由都使得其在常规TM上的性能比率最多是其在对称TM上的性能比率的两倍。 <strong><u>有趣的是，该比率是否以及何时可以接近2。</u></strong></p><h1 id="6-LP-models"><a href="#6-LP-models" class="headerlink" title="6. LP models"></a>6. LP models</h1><blockquote><p>首先，我们回顾一下结果[5]，该结果表明可以在网络大小的多项式时间内计算出网络的最优遗忘路由（和遗忘率）。然后，我们开发了一个简化的LP模型，该模型可以实现更快的运行时间 ，并修改此模型以处理OD对要求的范围限制。</p></blockquote><p>A. The LP Model of [5]</p><h1 id="1-questions"><a href="#1-questions" class="headerlink" title="-1. questions"></a>-1. questions</h1><ul><li>CPLEX LP solver是什么<ul><li>常用的功能</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deeprm</title>
      <link href="/PaperReading/deeprm/"/>
      <url>/PaperReading/deeprm/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>方案1：</p><p>一共有j个执行器， 输出的是j维的向量，每个的值就是</p><p>一般是25个node的spark</p><p>状态空间实在是太大了 –》指数级</p><p>方案2：</p><p>每一个执行器执行完之后，就输出一个（从空余的task中选择的）可执行的task</p><p>方案3：<br>输出二维向量 &lt;v ,l&gt;  ( v是node ， l是资源限制 )</p><blockquote><p>==会有很多等价决策 ？？== ，比如说 l分配的比当前的</p></blockquote><p>？ 如果 l 比较大，怎么砍</p><p>v<del>1</del>,v<del>2</del>,v<del>3</del>,v<del>i</del> 下一个要执行的task </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>problemList</title>
      <link href="/Algorithm/problemList/"/>
      <url>/Algorithm/problemList/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="质数相关"><a href="#质数相关" class="headerlink" title="质数相关"></a>质数相关</h1><ul><li><ol start="204"><li><p>计数质数</p><p>统计所有小于非负整数 <em><code>n</code></em> 的质数的数量。</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVE3NDExRTdTdT9mcm9tPXNlYXJjaCZzZWlkPTU4NDM5NTE4NzU2MTc4ODU3Mjc=">优化 : 每次从x**2开始筛<i class="fa fa-external-link-alt"></i></span></p></li></ol></li><li><ol start="264"><li><p>丑数 II</p><p>丑数就是质因数只包含 <code>2, 3, 5</code> 的正整数。</p></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Gurobi</title>
      <link href="/Codes/Gurobi/"/>
      <url>/Codes/Gurobi/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul><li><p>python的扩展对象 TupleList TupleDict  更加高效</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/09/095006-189335.png" alt="image-20201209095006228" style="zoom:67%;" /><pre><code>&gt; 有高效的筛选API，而传统的python对象，就只能通过循环</code></pre><ul><li><p>TupleList快速筛选</p><p>select(‘key’,’*’)</p><p>TupleDict ( gurobi变量一般都是这个 )</p><p>select sum prod </p><p>​    prod其实是逐元素相乘</p></li></ul></li></ul><pre><code>Multidict&lt;img src=&quot;https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/09/095353-622995.png&quot; alt=&quot;image-20201209095343645&quot; style=&quot;zoom:67%;&quot; /&gt;</code></pre><ul><li><p>创建list  列表解析</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/09/112600-482003.png" alt="image-20201209095423990"></p></li><li><p>quicksum</p><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201209112559171.png" alt="image-20201209112559171"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>pythonComplexity&amp;DataStructure</title>
      <link href="/Algorithm/pythonComplexity/"/>
      <url>/Algorithm/pythonComplexity/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul><li><p>refer</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9hOGZhM2QzMWFhNDA=">python常用操作复杂度<i class="fa fa-external-link-alt"></i></span></p></li></ul><hr><h1 id="常用操作的基本复杂度"><a href="#常用操作的基本复杂度" class="headerlink" title="常用操作的基本复杂度"></a>常用操作的基本复杂度</h1><p>很多时候我以为python会优化的…结果居然没有优化…</p><ul><li><p>list</p><p>list.index()    O(n)</p><p>in  O(n)</p></li><li><p>set</p><p>in  最差O(n)，平均情况下是O(1)</p></li><li><p>dict</p><blockquote><p>其实python中的dict就是一个哈希表的实现。</p><p>哈希表最差情况下查找是O(n) ,但是满足一定的假设，可以认为其平均性能是O(1)</p></blockquote><ul><li>插入、访问、清空、删除  都是O(1)</li></ul></li></ul><ul><li>OJ tips<ul><li>一般来说时间复杂度是O(1e9) , 空间复杂度不要超过O(1e7)</li></ul></li></ul><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="deque"><a href="#deque" class="headerlink" title="deque"></a>deque</h2><p>其实API更像是list</p><ul><li><p>pop( ) , popleft( )   –&gt; return ele</p></li><li><p>append( ) ,appendleft( )</p></li><li><p>extend( ) ,extendleft( )</p></li></ul><h2 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h2><ul><li>add()</li><li>pop()</li></ul>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dpSummary</title>
      <link href="/Algorithm/dpProblemsList/"/>
      <url>/Algorithm/dpProblemsList/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="题目总结"><a href="#题目总结" class="headerlink" title="题目总结"></a>题目总结</h1><ul><li><p>买卖股票的最佳时机系列</p><ul><li><p>Ⅰ 121</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvYmVzdC10aW1lLXRvLWJ1eS1hbmQtc2VsbC1zdG9jay9zb2x1dGlvbi9jLWxpLXlvbmctc2hhby1iaW5nLXdlaS1odS15aS1nZS1kYW4tZGlhby16aGFuLXR1LS8=">单调栈的题解以及系列题目<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>单调栈的应用场景 <strong>当你需要高效率查询某个位置左右两侧比他大（或小）的数的位置的时候</strong></p></blockquote></li><li><p><input disabled="" type="checkbox">  似乎也用双指针来解决这个问题</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvYmVzdC10aW1lLXRvLWJ1eS1hbmQtc2VsbC1zdG9jay9zb2x1dGlvbi9ndS1waWFvLXdlbi10aS1weXRob24zLWMtYnktejFtLw==">这个题解<i class="fa fa-external-link-alt"></i></span>真的很不错</p><blockquote><p>本题最妙的方法 其实是 dp思想的优化</p></blockquote><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vdS96MW0v">腐烂的橘子<i class="fa fa-external-link-alt"></i></span>似乎对动归的理解比较深，有时间可以看看他的系列</p><pre><code>* [ ] [背包的理解](https://leetcode-cn.com/problems/coin-lcci/solution/bei-bao-jiu-jiang-ge-ren-yi-jian-da-jia-fen-xiang-/)</code></pre></li><li><p><a href="">123 带冷冻期的股票交易</a></p></li></ul></li></ul></li><li><p>Ⅱ 122</p><ul><li><input disabled="" type="checkbox"> 这个<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvYmVzdC10aW1lLXRvLWJ1eS1hbmQtc2VsbC1zdG9jay1paS9zb2x1dGlvbi90YW4teGluLXN1YW4tZmEtYnktbGl3ZWl3ZWkxNDE5LTIv">精选题解<i class="fa fa-external-link-alt"></i></span>给出了股票交易的一系列算法</li></ul></li><li><p>Ⅲ 123</p><ul><li><p><input disabled="" type="checkbox">  我想写成k在第一维度，day在第二维度的，更像是背包/阶段划分的思想</p></li><li><p><input disabled="" type="checkbox">  有人说就是个背包，其实我觉得就是最后的形式上比较像而已，没有必要强行联想…</p><p>不过可以看下人家怎么理解背包的…2333</p></li><li><p>压缩要倒着写，自己写的时候要注意下</p><ul><li><p><input disabled="" type="checkbox">  但是<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvYmVzdC10aW1lLXRvLWJ1eS1hbmQtc2VsbC1zdG9jay1pdi9zb2x1dGlvbi96aHVhbmctdGFpLXlhLXN1by1zaGktZ3Vhbi15dS1rc2hpLWZvdS1kYW8teHUteWFvLS8=">这篇<i class="fa fa-external-link-alt"></i></span>分析了为什么可以正序</p><blockquote><p>“然计算过程中的一个变量值不同，但这一个值的差异并不会影响最终结果” 有点意思</p></blockquote></li></ul></li><li><p>需要注意初始化，尤其是下面的题目，K&gt;=N/2的情况要注意</p></li></ul></li><li><p>Ⅳ 188</p><ul><li><p>不停看到有人用哨兵/N指针的思路…看看呢</p></li><li><p>309 含冷冻期的买卖</p></li><li><p>714 含手续费的买卖</p></li></ul></li></ul><ul><li><p><strong>打家劫舍系列</strong></p><ul><li><p>打家劫舍Ⅰ</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUva1FmUzVzLw==">周植:最基础的解法<i class="fa fa-external-link-alt"></i></span>:  dp[stage][0/1] &amp; dp[i]代表偷了前i家，且一定偷第i家的(解法复杂) </p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvaG91c2Utcm9iYmVyL3NvbHV0aW9uL2RhLWppYS1qaWUtc2hlLWRvbmctdGFpLWd1aS1odWEtamllLWdvdS1odWEtc2ktbHUtLw==">Krahets：进阶版<i class="fa fa-external-link-alt"></i></span> 虽然想起来比较难，但是时空复杂度都比较低 </p><p>dp[i]代表偷前i家的最大值，dp[i] = max( dp[i-1],dp[i-2]+nums[i] )</p><blockquote><ul><li><input disabled="" type="checkbox"> ==Krahet的题解都不错，有空可以都看看==</li></ul></blockquote></li><li><p>总结的经验就是：</p><p>像这种隔着选的问题，虽然最naive(其实也不很naive 233)的解法是要将当前阶段的决策融入状态中标明的( dp[stage][0/1] )，但其实只有两种选择的情况下，不标明也可以233…</p><p>但我个人的建议还是要标明…因为只有在 只有两种选择的情况下才可以进化成Krahet的形式。如果选择多了的话，其实Krahet的方式不是通用的。</p></li></ul></li><li><p>打家劫舍Ⅱ</p><p>化解为两个单排，问题是：存不存在两个单排的最优解都是没有取到两端的（也就是 optimal[:-1]的解 不包括num[0] ， optimal[1:]的解不包括num[-1]，所以其实第一个和最后一个都没取 ）</p><p>或者另一个思路挺好：第一个和最后一个不能共存，所以就是两种情况的最大值：</p><ul><li><p>可以取第一个，那么最后一个肯定不能取</p><p>把最后一个数设置为0，然后对整个数组进行’打家劫舍Ⅰ’的运算。因为最后一个设置为0，所以就相当于没有取（就算被选中了，也可以删去）。–》那么其实最优解 与nums[:-1]得到的最优解是一样的，所以<u>对nums[:-1]的部分数组进行’打家劫舍Ⅰ’的运算</u>即可。</p><blockquote><p>至于最优解中到底包不包含第一个，其实都可以。我们是要防止 万一最优解中有第一个的情况，此时最后一个坚决不能取。</p></blockquote><blockquote><p>那有没有可能最优解中，没取第一个（取了第二个），也没取最后一个nums[:-1]中的最后一个（也就是原序列的倒数第二个），那么此时完全可以取原序列中的最后一个，且不会产生冲突。【注意，这种情况就属于下面的情况里面包含了】</p></blockquote></li></ul><ul><li><p>一定不取第一个，但可以取最后一个</p><p>把第一个数设置为0，然后对整个数组进行’打家劫舍Ⅰ’的运算。因为第一个一个设置为0，所以就相当于没有取（就算被选中了，也可以删去）。–》那么其实最优解 与nums[1:]得到的最优解是一样的，所以<u>对nums[1:]的部分数组进行’打家劫舍Ⅰ’的运算</u>即可。</p></li><li><p>如果合并后的最优解是头尾都没选，那就说明 着实不需要这两个2333</p></li></ul></li><li><p>打家劫舍Ⅲ  【树形dp】==！！没做完&amp;整理==</p></li></ul></li></ul><ul><li><p>403Frog Jump 青蛙过河</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvZnJvZy1qdW1wL3NvbHV0aW9uL3Fpbmctd2EtZ3VvLWhlLWJ5LWxlZXRjb2RlLw==">官方讲解<i class="fa fa-external-link-alt"></i></span>还是很靠谱的！思路从易到难</p><ul><li>动态规划+哈希表优化</li><li>可行性问题，而不是求最优解问题</li></ul></blockquote><p>​    最简单的能想到的就是 dp[stone][action]，其中stone和action都是 [1:max(stones)] , 因为我们在某个stone处，其实我们也不知道前面一步具体是多少。这个的问题是，直接out of memory。把dp矩阵打印出来也可以发现大部分都是False，which means是稀疏矩阵。也就是说我们的阶段和状态定义的不好。</p><blockquote><p>太可怕了，这个一开始的想法也太愚蠢了吧…</p></blockquote><p>​    我们的阶段实际上就只有stones数组里面的几个数值，并不是连续值，所以阶段就是[stone in stones]。紧接着就是action的设计考量：</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RhX2thb19sYS9hcnRpY2xlL2RldGFpbHMvMTA1MTc2MDY1">想法1<i class="fa fa-external-link-alt"></i></span></p><p>​    action实际上不会超过1100（每步只会增加1，一共最多输入1100个数，还包括0）。但这个想法就是有点浪费空间，因为还是很多action是取不到的。。 但这里的更新方式就比较值得玩味了，是</p><p><code>for i in range(len(stones)): for j in range(len(i)+1)</code></p><p>, 而不是常规的</p><figure class="highlight plain"><figcaption><span>i in range(len(stones)): for j in range(action_lens)```,</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    所以就比较难想。但是如果按照常规的for循环更新，就会设计到查找的优化。下文会体现。</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">  * 想法2</span><br><span class="line"></span><br><span class="line">    ​    一个地方只能从前面的某个石子跳过来，which means也不是连续整数值可选，所以其实也只有O(num(stones))的可选项。所以又回到打家劫舍的问题的里面去了： 前i个stone，所以设计为dp\[stone][stone]表示的就是从stone_idx2跳到stone_idx1是否可行。如下，但是每次状态转移，需要搜索stones的list( O(n) )，最后就是**&lt;u&gt;O(n^3)&lt;&#x2F;u&gt;**的复杂度了--&gt; O(10\^9)直接超时。（可以用一些小trick优化到O(n^2）（[version2](https:&#x2F;&#x2F;github.com&#x2F;hexi519&#x2F;leetcode_prac&#x2F;blob&#x2F;666e94e8c76107980729f0b23a9e621f77671dfb&#x2F;403FrogJump.py#L39)）,但可以看到由于常数项比较大，还是跟下面常用方法2，也就是version3差了不少。)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  **&lt;u&gt;改进思路： 降低查找的复杂度&lt;&#x2F;u&gt;**</span><br><span class="line"></span><br><span class="line">  * [ ] [常用方法1](https:&#x2F;&#x2F;leetcode.com&#x2F;problems&#x2F;frog-jump&#x2F;discuss&#x2F;223586&#x2F;Python-solution)：二分搜索，**&lt;u&gt;O(n^3) --&gt; O(n^2*logn)&lt;&#x2F;u&gt;**</span><br><span class="line"></span><br><span class="line">  * [常用方法2](https:&#x2F;&#x2F;github.com&#x2F;hexi519&#x2F;leetcode_prac&#x2F;blob&#x2F;666e94e8c76107980729f0b23a9e621f77671dfb&#x2F;403FrogJump.py#L65)：使用额外的、低查找开销的数据结构存储经常要查找的东西。这里使用hashMap存储可用的action, 所以每次就不是搜数组，而是搜一个集合，且由于只存前一步可达的，也就是有效的action，所以相当于剪了很多枝。O(n\^3)--&gt;O(n^2)，且前面的常熟会比较低</span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;区间dp？？&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">* [413 等差数列划分题解](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;arithmetic-slices&#x2F;solution&#x2F;dong-tai-gui-hua-by-dream_day-2&#x2F;)  这个虽然不是精选，但是感觉还不错</span><br><span class="line"></span><br><span class="line">  &gt; 以A[i]结尾的子等差序&gt;列的**头指针位置**就比以A[i-1]结尾的子等差序列的**头指针位置**的**选择多一位**，这样也就dp[i] &#x3D; 1 + dp[i-1]</span><br><span class="line"></span><br><span class="line">* [x] &#x3D;&#x3D;446 等差数列划分2&#x3D;&#x3D;  (做是做完了，题目也理解完了，但是感觉很生硬，后续还要复盘一遍)</span><br><span class="line"></span><br><span class="line">  * [这个对为什么用hash Table 讲得很到位](https:&#x2F;&#x2F;www.cnblogs.com&#x2F;grandyang&#x2F;p&#x2F;6057934.html)</span><br><span class="line"></span><br><span class="line">  * 什么时候用hash table来优化...就是一个状态跟之前的稀疏状态集有关联的时候 用于优化存储</span><br><span class="line">  * 经验法则就是：处理连续的子问题的时候，要找O(n)的解； 处理非连续的子问题的时候，要找O(n^2^)的解</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"></span><br><span class="line">**&lt;u&gt;二维动态规划&lt;&#x2F;u&gt;**</span><br><span class="line"></span><br><span class="line">* [x] 64. Minimum Path Sum (Medium) </span><br><span class="line"></span><br><span class="line">* [x] 542. 01 Matrix (Medium)  求出每个1距离最近的0的距离长度</span><br><span class="line"></span><br><span class="line">  * 动归的思路是可以，[官方题解](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;01-matrix&#x2F;solution&#x2F;01ju-zhen-by-leetcode-solution&#x2F;)给出的一个insight就是：矩阵上某个点的信息传播，可以只从左上方和右下方进行传播。</span><br><span class="line">  * 但我觉得这里，官方题解给的bfs思路更好理解一些...</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">* [x] 221. [最大正方形](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;maximal-square&#x2F;) &amp; 1277[统计全为 1 的正方形子矩阵](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;count-square-submatrices-with-all-ones&#x2F;)</span><br><span class="line"></span><br><span class="line">  二维的，跟矩阵有关的，都是dp\[i][j] 表示(i,j)为一个范围的边界点的一个值（这里就是以(i,j)为右下角的矩阵的最大边长）。</span><br><span class="line"></span><br><span class="line">  至于为什么是右下角而不是左上角或者其他角，其实都可以，选右下角主要是为了可以方便矩阵从第一行第一个，往右、往下遍历，这个比较符合人类的直觉。</span><br><span class="line"></span><br><span class="line">  * 一次递归要用到左边,上面,左上角的信息,可以用两个一维数组压缩空间,还可以用一个一维+两个临时变量进行压缩</span><br><span class="line"></span><br><span class="line">    * [ ] 就是221不知道为啥越压缩,时空性能越差....    </span><br><span class="line">      * [ ] 先看下[人家](https:&#x2F;&#x2F;leetcode.com&#x2F;problems&#x2F;count-square-submatrices-with-all-ones&#x2F;discuss&#x2F;643429&#x2F;Python-DP-Solution-%2B-Thinking-Process-Diagrams-(O(mn)-runtime-O(1)-space)怎么做性能优化的吧...说不定是我优化的方式错了...</span><br><span class="line"></span><br><span class="line">  * 至于为什么这么递推,可以看下[这个题解](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;count-square-submatrices-with-all-ones&#x2F;solution&#x2F;tong-ji-quan-wei-1-de-zheng-fang-xing-zi-ju-zhen-2&#x2F;)的简单证明</span><br><span class="line"></span><br><span class="line">  * 1277的思路我觉得看[这个讲解](https:&#x2F;&#x2F;leetcode-cn.com&#x2F;problems&#x2F;count-square-submatrices-with-all-ones&#x2F;solution&#x2F;tong-ji-quan-wei-1-de-zheng-fang-xing-zi-ju-zhen-f&#x2F;)更靠谱...</span><br><span class="line"></span><br><span class="line">    &gt; $\underset&#123;i&#125;&#123;\sum&#125;$宽度为 i 的正方形的个数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* 84</span><br><span class="line"></span><br><span class="line">* 85</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* 小总结</span><br><span class="line">  * 一般的递归就是考虑左边、上面、左上，再难一点就是从多个角度传递消息（目前221可以看出来从左上和右下两个角度传递消息就差不多了），但这种实际上也不是很好想，所以可以退而求其次：</span><br><span class="line">  * 其实矩阵也是一种规整的图，用搜索的思想也很不错</span><br><span class="line">    * 如果想到是的dfs，大概率就是一个比较差的暴力，想办法剪枝 或者 进化&#x2F;优化到dp</span><br><span class="line">    * 可以往bfs想，一般都还不错 ( e.g.1277 )</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">**&lt;u&gt;分割类问题&lt;&#x2F;u&gt;**</span><br><span class="line"></span><br><span class="line">* 279 perfect squares</span><br><span class="line"></span><br><span class="line">  * 动归</span><br><span class="line"></span><br><span class="line">    其实我觉得就是一个多重背包，大家讲得那么复杂...标答和[我的解法](https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;hexi519&#x2F;leetcode_prac&#x2F;master&#x2F;279PerfectSquares.py)实际上就差别就在于内外循环的顺序，但我觉得我的更好用些...</span><br><span class="line"></span><br><span class="line">    时空复杂度O( $n*\sqrt&#123;n&#125;$ ) 和 O(n) </span><br><span class="line"></span><br><span class="line">  * [ ] ~~这个的贪心的证明没有理解~~ 【不想学贪心了...】大部分还要证明...太烦了...</span><br><span class="line"></span><br><span class="line">  * 搜索</span><br><span class="line"></span><br><span class="line">    ![image-20201215205651863](https:&#x2F;&#x2F;gitee.com&#x2F;HesyH&#x2F;Image-Hosting&#x2F;raw&#x2F;master&#x2F;image4typora&#x2F;202012&#x2F;15&#x2F;205858-894216.png)</span><br><span class="line"></span><br><span class="line">    &gt; 平时搜索练的少，但其实万物皆可搜索，所以后面做动归最好也跟上搜索的解法把... [这次](https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;hexi519&#x2F;leetcode_prac&#x2F;master&#x2F;279PerfectSquares.py)写上了</span><br><span class="line"></span><br><span class="line">    时空复杂度为O( $\sqrt&#123;n&#125;^h$ ) 和O(n) 这里h 不好确定，因为是树高，也就是最小需要的组合数，which我们也不好确定...    </span><br><span class="line"></span><br><span class="line">    看到b站题解里面说：&#x3D;&#x3D;如果n超过10^6^,那么空间就开不下了...这个时候别无他法就只能搜索了&#x3D;&#x3D;</span><br><span class="line">    </span><br><span class="line">    有一个在同一层的剪枝优化[]()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;都是逆着的，要想想看为什么是逆着的  ask魏知宇？&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">* 字符串上的文章</span><br><span class="line"></span><br><span class="line">  * [ ] 91 解码方法</span><br><span class="line"></span><br><span class="line">    * [ ] 还有hard的95 解码方式Ⅱ还没做...</span><br><span class="line"></span><br><span class="line">  * [ ] 139 单词拆分</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">**&lt;u&gt;子序列问题&lt;&#x2F;u&gt;**</span><br><span class="line"></span><br><span class="line">&gt; 因为子序列类型的问题，穷举出所有可能的结果都不容易，而动态规划算法做的就是穷举 + 剪枝，它俩天生一对儿。所以可以说只要涉及子序列问题，十有八九都需要动态规划来解决，往这方面考虑就对了。</span><br><span class="line">&gt;</span><br><span class="line"></span><br><span class="line">* 最长上升子序列</span><br><span class="line">  * [红豆薏米的b站视频](https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV17t411E7Xn&#x2F;?spm_id_from&#x3D;333.788.videocard.0)把O(nlogn)的思想解释的很好</span><br><span class="line">  </span><br><span class="line">    最重要的是二分搜索的实现，可以参考[labuladong的小抄](https://images.weserv.nl/?url=https:&#x2F;&#x2F;labuladong.gitbook.io&#x2F;algo&#x2F;di-ling-zhang-bi-du-xi-lie&#x2F;er-fen-cha-zhao-xiang-jie)【着实不错】,要搞清楚你是要查找某个值还是查找某个值的左&#x2F;右边界就可以，在这里&lt;u&gt;查找的是第一个比自己的大的元素的位置（如果已有跟自己相同的元素就什么也不更新就退出）&lt;&#x2F;u&gt;。</span><br><span class="line">  </span><br><span class="line">    &gt; &#x3D;&#x3D;全部用左闭右闭的形式比较方便记忆&#x3D;&#x3D;</span><br><span class="line">  </span><br><span class="line">    * 变体就是最长不减子序列，这个变体也是找第一个比自己大的元素的位置（但是如果有跟自己相同的元素，不会立马退出，会继续往上界搜寻）</span><br><span class="line">  </span><br><span class="line">      &#96;&#96;&#96;python</span><br><span class="line">      # 最长上升</span><br><span class="line">      if mid &#x3D;&#x3D; num: break</span><br><span class="line">      # 最长不减</span><br><span class="line">      if mid &#x3D;&#x3D; num: </span><br><span class="line">          left&#x3D;mid+1  # 继续往上界搜</span><br></pre></td></tr></table></figure></li><li><p>值得注意的是，tail数组并不是最长上升子序列！（自己可以举反例想想）</p></li></ul></li></ul><p>最长上升子序列(LISLIS):Longest Increasing Subsequence<br>最长连续序列(LCSLCS):Longest Consecutive Sequence<br>最长连续递增序列(LCISLCIS):Longest Continuous Increasing Subsequence<br>最长公共子序列(LCSLCS):Longest Common Subsequence</p><hr><p><strong><u>背包问题</u></strong></p><p>==dp为什么是NP？==  感觉O(n)就可以验证啊，所以n也是n的多项式是么</p><ul><li><p>416 分割等和子集</p><p>使用布尔数组，然后使用或运算，快了不少</p><p>看到有更快更省的…用bit以及位运算…</p></li></ul><ul><li><p><input disabled="" type="checkbox">  639 划分为k个相等的子集</p><p>搜索的思想…我还不太会…==感觉todo是搜索里面常用的==</p></li></ul><ul><li><p><input disabled="" type="checkbox">  600 不含连续1非负整数【第一遍做有点吃力】</p><p>实际上是数位dp</p><p>去b站上再看看数位dp的模板…</p></li></ul><hr><ul><li>1147段式回文<ul><li><input disabled="" type="checkbox"> 双指针解法</li><li><input disabled="" type="checkbox"> 贪心解法</li></ul></li></ul><ul><li>1235规划兼职工作</li></ul><p>==感觉这两个应该得好好研究下双指针问题再来做做…==</p><hr><p><strong><u>字符串系列</u></strong></p><ul><li><p><input disabled="" type="checkbox">  最长回文子串，但是我只能想到中心扩散的方式咋整… 而且还没实现完</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvbG9uZ2VzdC1wYWxpbmRyb21pYy1zdWJzdHJpbmcvc29sdXRpb24vemhvbmcteGluLWt1by1zYW4tZG9uZy10YWktZ3VpLWh1YS1ieS1saXdlaXdlaTE0MTkv">这个讲解<i class="fa fa-external-link-alt"></i></span>好详细！</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzZDEzNjkxMi9hcnRpY2xlL2RldGFpbHMvNzg5ODc2MjQ=">这个讲解不错<i class="fa fa-external-link-alt"></i></span></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dp总结</title>
      <link href="/Algorithm/dpSummary/"/>
      <url>/Algorithm/dpSummary/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="dp总结"><a href="#dp总结" class="headerlink" title="dp总结"></a>dp总结</h1><ul><li><p>初始化是很重要的</p><ul><li>如果是求…  ，  就初始化为0</li><li>如果是求… ， 就初始化为maxInf或者</li></ul></li><li><p><strong><u>阶段和状态</u>**的划分开很重要，都是一个维度。（ 其实这里的stage就是 MDP里面的S<del>1</del>，S<del>2</del>，… , S<del>n</del> , state就是每个stage具体可以取的值 s ）。一般阶段都是有</strong><u>顺序性</u>**隐含在内，是事件发生到末端所要经历的必然阶段，状态是这个阶段可以取到的值。再注意，不要把状态 和 我们要求解的值 混肴了。</p><p>很多时候可能大家以为阶段是状态，但其实不是。阶段和状态共同组成我们dp数组的维度，which will be affected by action and transformed to others。举例：</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUva1FmUzVzLw==">周植：序列型动态规划<i class="fa fa-external-link-alt"></i></span>中，阶段是房子的位置，状态是这家房子有没有被打劫。(要打劫整条街，我总得一个一个屋子走过去吧，这就是我要完成打劫这件事所必经的阶段)</p></li><li><p>01背包中阶段是当前要选择放进去的第i个物品，状态是当前这个阶段，包里容量的可能的大小。</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvMi1rZXlzLWtleWJvYXJkL3NvbHV0aW9uL2RvbmctdGFpLWd1aS1odWEteGlhbmcteGktZmVuLXhpLWppZS1zaGktd2VpLXNoaS15Lw==">只有两个键的键盘<i class="fa fa-external-link-alt"></i></span>中，阶段是当前有几个A。如果你采用主动转移的思路，那么当前的状态就是当前粘贴板上的A有多少位。</p><blockquote><p>dp[i][j] = dp[i - j][j] + 1。注意，这里的解法只是比较naive的，进一步是可以状态压缩的。</p><ul><li><input disabled="" type="checkbox"> ==什么时候可以状态压缩==  应该从式子的转移本身就能看出来</li></ul></blockquote></li><li><p>很多时候我们会发现，一个问题也有很多个刻画方式。比如 <span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vcHJvYmxlbXMvaG91c2Utcm9iYmVyLWlpL3NvbHV0aW9uL3RvbmcteW9uZy1zaS1sdS10dWFuLW1pZS1kYS1qaWEtamllLXNoZS13ZW4tdGktYnktLw==">打家劫舍：labuladong解法<i class="fa fa-external-link-alt"></i></span>中，dp[i]表示的是，不是<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUva1FmUzVzLw==">周植<i class="fa fa-external-link-alt"></i></span>大佬讲解中的任意一种：表示到目前为止打劫到的钱的累积金额( 需要第二个维度进行辅助 ) 或者 到目前位置为止，且打劫当前位置，打劫到的钱的累积金额。不过从前往后累积和从后往前累积实际上是差不多的，我只能说，以我的感觉来说”<u><strong>从第i个位置开始，且包括第i个位置</strong></u>“的思路会比较容易理解。(应该会有些场景有区别，目前还没做到相关题目)</p><p>总之，正如<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUva1FmUzVzLw==">周植<i class="fa fa-external-link-alt"></i></span>所说：</p><blockquote><p>状态设计的时候，<u>也会将序列中的位置作为状态表示的一维</u>。例如 dp[i]，而这一维一般来说可以表示这几种信息：</p><ul><li>第 / 前 i 个位置的答案</li><li>前 i 个位置里，第 i 个位置一定选择的答案</li></ul></blockquote></li></ul></li></ul><blockquote><ul><li><input disabled="" type="checkbox"> **<u>卧槽  ，这里两者存在矛盾哇… 一个说“前xx”的思路的复杂度是O(N^2)</u>**，但labuladong写出来的又没有那么复杂…</li></ul></blockquote><h2 id="dfs和dp的关系"><a href="#dfs和dp的关系" class="headerlink" title="dfs和dp的关系"></a>dfs和dp的关系</h2><ul><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jb20vcHJvYmxlbXMvZnJvZy1qdW1wL3N1Ym1pc3Npb25zLw==">403 frog jump<i class="fa fa-external-link-alt"></i></span></li></ul><h1 id="dp分类"><a href="#dp分类" class="headerlink" title="dp分类"></a>dp分类</h1><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUva1FmUzVzLw==">周植：序列型<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vY2lyY2xlL2FydGljbGUvVkZaRVhBLw==">周植：常见普通题型及状态表示<i class="fa fa-external-link-alt"></i></span>  【内含题目和习题】  <span class="exturl" data-url="aHR0cHM6Ly93bmp4eWsudGVjaC8xMTcuaHRtbA==">周植大佬的博客也不错啊！<i class="fa fa-external-link-alt"></i></span>（还有个DP的intro还没来得及看）</p><ul><li><input disabled="" type="checkbox"> 主动转移和被动转移 目前还没有看明白，在后一个blog里面</li></ul></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVk3NDExTjdCbg==">搜索：犹豫就会败北<i class="fa fa-external-link-alt"></i></span>  万物皆可搜索！</p></li><li><p>线性动规，区域动规，树形动规【打家劫舍Ⅲ】，背包动规【股票交易Ⅳ】四类</p></li></ul><h1 id="刷题时常犯的错误-积累的经验"><a href="#刷题时常犯的错误-积累的经验" class="headerlink" title="刷题时常犯的错误/积累的经验"></a>刷题时常犯的错误/积累的经验</h1><ul><li><p>二维矩阵中常常在初始化结果矩阵的时候, 把行和列搞反,导致有时候正方形的样例可以通过,但是矩形的就不行了</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rowNum,colNum = len(matrix), len(matrix[<span class="number">0</span>])</span><br><span class="line">dist = [[<span class="number">20000</span>] * colNum <span class="keyword">for</span> _ <span class="keyword">in</span> range(rowNum)]</span><br></pre></td></tr></table></figure></li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p>b站<span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMTQ5NzU4">nat8023<i class="fa fa-external-link-alt"></i></span>大佬讲得挺好</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93bmp4eWsua2VqaS5tb2UvYWxnb3JpdGhtL2FsZ29yaXRobS1hYmMvc2VxdWVuY2UtZHA=">周植的博客<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>序列型和升级型的DP的总结，还列举除了不少题目</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3UuY29tLmNuL2Jsb2cvMDQwOERvZGdlbWluL2RwLWNvbmNlcHRpb25z">Andrewzdm 的博客<i class="fa fa-external-link-alt"></i></span></p><blockquote><ul><li>阶段和状态的设定必须保证全局唯一（MDP），否则就可以合并。</li><li>将决策写入状态中以消除后效性影响。</li><li>提到了主动状态转移和被动状态转移的区别（大部分题目是没有区别的），并用例子进行了时间复杂度分析。</li></ul></blockquote></li><li><p>zzx的分类列表</p><blockquote><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTA0OA==">https://www.luogu.org/problemnew/show/P1048<i class="fa fa-external-link-alt"></i></span> 采药（01背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTczNA==">https://www.luogu.org/problemnew/show/P1734<i class="fa fa-external-link-alt"></i></span> 最大约数和（01背包） 【明天把两种筛法都做一下】</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTA0OQ==">https://www.luogu.org/problemnew/show/P1049<i class="fa fa-external-link-alt"></i></span> 装箱问题（01背包）</p></li><li><p>有约束的01背包</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjY2Mw==">https://www.luogu.org/problemnew/show/P2663<i class="fa fa-external-link-alt"></i></span> 越越的组队（01背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjQzMA==">https://www.luogu.org/problemnew/show/P2430<i class="fa fa-external-link-alt"></i></span> 严酷的训练（01背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTkyNg==">https://www.luogu.org/problemnew/show/P1926<i class="fa fa-external-link-alt"></i></span> 小书童（01背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTgwMg==">https://www.luogu.org/problemnew/show/P1802<i class="fa fa-external-link-alt"></i></span> 5倍经验日（01背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTYxNg==">https://www.luogu.org/problemnew/show/P1616<i class="fa fa-external-link-alt"></i></span> 疯狂的采药（完全背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTY3OQ==">https://www.luogu.org/problemnew/show/P1679<i class="fa fa-external-link-alt"></i></span> 神奇的四次方数（完全背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjkxOA==">https://www.luogu.org/problemnew/show/P2918<i class="fa fa-external-link-alt"></i></span> 买干草（完全背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjM0Nw==">https://www.luogu.org/problemnew/show/P2347<i class="fa fa-external-link-alt"></i></span> 砝码称重（多重背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTkxMA==">https://www.luogu.org/problemnew/show/P1910<i class="fa fa-external-link-alt"></i></span> L国的战斗之间谍（二维背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTUwNw==">https://www.luogu.org/problemnew/show/P1507<i class="fa fa-external-link-alt"></i></span> NASA的食物计划（二维背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTUwOQ==">https://www.luogu.org/problemnew/show/P1509<i class="fa fa-external-link-alt"></i></span> 找啊找啊找GF（二维背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTg1NQ==">https://www.luogu.org/problemnew/show/P1855<i class="fa fa-external-link-alt"></i></span> 榨取kkksc03（二维背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTc1Nw==">https://www.luogu.org/problemnew/show/P1757<i class="fa fa-external-link-alt"></i></span> 通天之分组背包（分组背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTMzNg==">https://www.luogu.org/problemnew/show/P1336<i class="fa fa-external-link-alt"></i></span> 最佳课题选择（分组背包）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTIxNg==">https://www.luogu.org/problemnew/show/P1216<i class="fa fa-external-link-alt"></i></span> 数字三角形</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTUwOA==">https://www.luogu.org/problemnew/show/P1508<i class="fa fa-external-link-alt"></i></span> likecloud-吃吃吃</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTExNQ==">https://www.luogu.org/problemnew/show/P1115<i class="fa fa-external-link-alt"></i></span> 最大子段和</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTcxOQ==">https://www.luogu.org/problemnew/show/P1719<i class="fa fa-external-link-alt"></i></span> 最大加权矩形</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMzkwMg==">https://www.luogu.org/problemnew/show/P3902<i class="fa fa-external-link-alt"></i></span> 递增（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjc4Mg==">https://www.luogu.org/problemnew/show/P2782<i class="fa fa-external-link-alt"></i></span> 友好城市（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTA5MQ==">https://www.luogu.org/problemnew/show/P1091<i class="fa fa-external-link-alt"></i></span> 合唱队形（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTAyMA==">https://www.luogu.org/problemnew/show/P1020<i class="fa fa-external-link-alt"></i></span> 导弹拦截（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTIzMw==">https://www.luogu.org/problemnew/show/P1233<i class="fa fa-external-link-alt"></i></span> 木棍加工（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjAwOA==">https://www.luogu.org/problemnew/show/P2008<i class="fa fa-external-link-alt"></i></span> 大朋友的数字（LIS）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTU2OQ==">https://www.luogu.org/problemnew/show/P1569<i class="fa fa-external-link-alt"></i></span> 属牛的抗议</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTA2Mw==">https://www.luogu.org/problemnew/show/P1063<i class="fa fa-external-link-alt"></i></span> 能量项链（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTg4MA==">https://www.luogu.org/problemnew/show/P1880<i class="fa fa-external-link-alt"></i></span> 石子合并（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjMwOA==">https://www.luogu.org/problemnew/show/P2308<i class="fa fa-external-link-alt"></i></span> 添加括号（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTYyMg==">https://www.luogu.org/problemnew/show/P1622<i class="fa fa-external-link-alt"></i></span> 释放囚犯（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjczNA==">https://www.luogu.org/problemnew/show/P2734<i class="fa fa-external-link-alt"></i></span> 游戏（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTIyMA==">https://www.luogu.org/problemnew/show/P1220<i class="fa fa-external-link-alt"></i></span> 关路灯（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTc5OQ==">https://www.luogu.org/problemnew/show/P1799<i class="fa fa-external-link-alt"></i></span> 数列（区间dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTQ3NA==">https://www.luogu.org/problemnew/show/P1474<i class="fa fa-external-link-alt"></i></span> 货币系统（计数类dp）</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTE5Mg==">https://www.luogu.org/problemnew/show/P1192<i class="fa fa-external-link-alt"></i></span> 台阶问题</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjgwMA==">https://www.luogu.org/problemnew/show/P2800<i class="fa fa-external-link-alt"></i></span> 又上锁妖塔</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjY5Nw==">https://www.luogu.org/problemnew/show/P2697<i class="fa fa-external-link-alt"></i></span> 宝石串</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTE2NA==">https://www.luogu.org/problemnew/show/P1164<i class="fa fa-external-link-alt"></i></span> 小A点菜</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTA1Nw==">https://www.luogu.org/problemnew/show/P1057<i class="fa fa-external-link-alt"></i></span> 传球游戏</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMTAwNg==">https://www.luogu.org/problemnew/show/P1006<i class="fa fa-external-link-alt"></i></span> 传纸条</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3Uub3JnL3Byb2JsZW1uZXcvc2hvdy9QMjE5Ng==">https://www.luogu.org/problemnew/show/P2196<i class="fa fa-external-link-alt"></i></span> 挖地雷</p></li></ul></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MeetingNotes1101</title>
      <link href="/MeetingNotes/MeetingNotes1101/"/>
      <url>/MeetingNotes/MeetingNotes1101/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><span class="exturl" data-url="aHR0cHM6Ly93eC52emFuLmNvbS9saXZlL3R2Y2hhdC0xNTY1MzUyMTUzP3NoYXJldWlkPTMzNzU0MTY1NCZ2cHJpZD0wJnNoYXJldHN0YW1wPTE2MDM1ODc1NjA4MTkjLw==">视频地址<i class="fa fa-external-link-alt"></i></span></p><h1 id="陈凯-net-4-AI"><a href="#陈凯-net-4-AI" class="headerlink" title="陈凯 net 4 AI"></a>陈凯 net 4 AI</h1><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/18/163439-988187.png" style="zoom:50%;" /><ul><li><p>compress 传输量 并不能降低尾部传输时间</p><p>当然，平均的时延是会降低</p><p>说明瓶颈不在于传输量</p></li><li><p>丢一定量的数据包并不会影响模型的convergence</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/18/163348-450748.png" alt="image-20201118161135895" style="zoom:50%;" /><ul><li>那么应该丢哪些包？ 后层的gradient和larger gradient更重要</li></ul></li><li><p>DNN流的特性：跟以前的信息包不一样，前者是一个message包含多个包（包之间存在依赖性），现在是一个包包含多个message（包与包之间关联性不大），所以不用太多去考虑包乱序等事情。</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/18/163350-390697.png" alt="image-20201118163215817" style="zoom:50%;" /><blockquote><p>至于现在 一个包 包含多个message这个特性是怎么来的，我就没有细究了。</p></blockquote><p>之前的ECMP等负载均衡，就会考虑 perflow的粒度性能就差了，perpacket的粒度还得考虑乱序问题。</p></li></ul><h1 id="李丹-Net-4-AI"><a href="#李丹-Net-4-AI" class="headerlink" title="李丹 Net 4 AI"></a>李丹 Net 4 AI</h1><p>使用==贝叶斯优化==</p>]]></content>
      
      
      <categories>
          
          <category> MeetingNotes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>recommand-sys-learning</title>
      <link href="/Codes/recommend-sys-learning/"/>
      <url>/Codes/recommend-sys-learning/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly90aWFuY2hpLmFsaXl1bi5jb20vY29tcGV0aXRpb24vZW50cmFuY2UvNTMxODQyL2luZm9ybWF0aW9u">赛题<i class="fa fa-external-link-alt"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9uYnZpZXdlci5qdXB5dGVyLm9yZy9naXRodWIvaGV4aTUxOS90ZWFtLWxlYXJuaW5nLXJzL2Jsb2IvbWFzdGVyL1JlY29tbWFuZE5ld3MvUmVjb21tYW5kLXN5cy5pcHluYg==">myCodes<i class="fa fa-external-link-alt"></i></span> &amp; <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleGk1MTkvdGVhbS1sZWFybmluZy1ycy9ibG9iL21hc3Rlci9SZWNvbW1hbmROZXdzL0Jhc2VsaW5lLmlweW5i">Baseline after comments<i class="fa fa-external-link-alt"></i></span></p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><ul><li><p>数据</p><p><code>sample_submit.csv</code>：提交样例文件，对应50000个用户对5个文件的点击数预测</p><p><code>train_click_log.csv</code>：训练集用户点击日志</p><p><code>testA_click_log.csv</code>：测试集用户点击日志</p><p><code>articles.csv</code>：新闻文章信息数据表</p><p><code>articles_emb.csv</code>：新闻文章embedding<u>向量表示</u></p></li><li><p>指标</p><p>MRR(Mean Reciprocal Rank)，关注top5的预测结果。其中越前面的匹配上了就得分越高（具体可以看下baseline代码里面的讲解</p></li></ul><h1 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h1><p>reduce_mem节省内存，就是尽量降低数据精度</p><h1 id="questions"><a href="#questions" class="headerlink" title="questions"></a>questions</h1><ul><li>如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中</li></ul><blockquote><p>没懂这是什么意思</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recommendation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Metro</title>
      <link href="/ExtensiveReading/Route/Metro/"/>
      <url>/ExtensiveReading/Route/Metro/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li><p>FRR (fast rerouting</p></li><li><p>reverse path forwarding (RPF)</p></li><li><p>光看related work其实还是不是很明白别人做的是什么</p></li></ul><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​    在大型网络中，故障是常见的，而不是例外。 为了向上层应用提供高质量的服务，期望在发生故障时能够快速启动融合备份路径。 在本文中，我们设计了一种基于IP的快速重路由(IP based Fast ReRouting)方案，该方案称为Metro，它可以解决任意单个链路/节点故障且后备路径扩展性低的情况下的流量重路由收敛问题。<br>   当网络中发生故障时，Metro首先指示将受到故障影响的所有网络区域，然后查找一些网桥链接以将受影响的网络区域中的流量排放到不受故障影响的网络区域 。 这样，Metro无需配置隧道，封装或修改数据包，因此易于在当前网络中部署。 大量的仿真表明，Metro可以解决备用路径比最新解决方案短的任意单链路/节点故障，并且Metro中约98％的备份路径延伸与最佳隧道方案相同。</p><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><blockquote><p>​    ISP网络或数据中心网络的网络都遭受无法预测的故障。 发生故障时，一个或多个网络组件（例如节点和链接）将无法传递流量，从而导致大量流量损失[1]，[2]。 此外，这种流量丢失可能给网络顶部运行的应用程序带来较大的响应延迟。 由于当前网络中的许多应用程序都对延迟敏感，因此较大的响应延迟可能会大大降低应用程序性能和用户体验。 因此，在网络故障发生后，需要快速重路由（FRR）方案来快速恢复流量传递。 为了使恢复时间最短，在这项工作中，我们集中于预先计算重新路由路径以应对网络故障的方案。  <u>FRR机制的主要关注点在于如何在效率和有效性这两个重要方面之间做出明智的权衡</u>。 一方面，FRR机制应该简单有效，以至于它几乎没有增加数据平面的开销。 另一方面，它应该达到理想的保护范围。 传统的基于纯IP的FRR机制，例如无环路替代（LFA）[3]和Uturn [4]注重效率，而许多基于隧道的机制则注重有效性。 基于IP的FRR的目标是通过使用预先计算的备用IP下一跳将故障反应时间减少到10毫秒。 在基于隧道的FRR机制中，有一些是通过多协议标签交换（MPLS）隧道实现的，例如RSPV-TE [5]，[6]，而另一些则是通过IP-in-IP隧道，数据包封装或数据包实现的。 标记[7] – [9]。 与FRR本身的实现相比，其相应平台的部署要复杂得多，更不用说由其他操作引起的其他问题了，例如数据包分段和封装。<br>   为了兼顾效率和有效性，在本文中，我们提出了Metro，一种用于处理网络故障的高效流量快速重路由方案。 就我们所知，Metro是第一个无需隧道的FRR机制，可以处理任意单个链路/节点故障而无需修改任何数据包。 与Uturn [4]相似，Metro中的交换机进行反向路径转发（RPF）检查以发出故障信息。 但是，Metro对网络拓扑进行了透彻的分析，以便在Uturn相同情况下提供全面的保护。</p></blockquote><blockquote><p>​    为了勾勒出Metro的核心概念和方法，我们看一下华盛顿特区真正的Metro（图1）的面料特征。 在华盛顿特区的地铁网络中，有许多线路通向中央枢纽站。 还可以找到许多秘密通道，这些通道主要由维护人员用于在线路之间快速行驶。 如果有人沿着其中一条线路步行到枢纽，并且发现地铁隧道被阻塞，则他/她可以通过这些秘密通道到达其他线路，而其他线路的通向枢纽的路径将绕过阻塞的线路。<br>​    Metro遵循地铁架构的相同理念，以实现基于IP的纯FRR。 对于网络中的任何目标，Metro通过分析路由树并在分支之间找到桥梁，Metro将受故障影响的分支上的流重定向到其相邻分支。</p></blockquote><ul><li><p>贡献</p><p>​    我们从理论上证明Metro可以处理任意单链路故障（SLF）和单节点故障（SNF），而无需修改重新路由的数据包。 评估真实世界和人工网络拓扑的方法也证实了这一点。<br>​    评估还表明，Metro通常会找到比其他FRR机制更短的备份路径来重定向受影响的流。<br>​    本文的其余部分安排如下。 第二节介绍FRR的背景。 第三部分简要介绍了Metro设计。 第四，第五和第六部分介绍了设计细节。 第七节对Metro进行了实际和人工拓扑评估。 最终，第八节总结了本文。</p></li></ul><h1 id="2-Background-and-relatede-works"><a href="#2-Background-and-relatede-works" class="headerlink" title="2 Background and relatede works"></a>2 Background and relatede works</h1><h2 id="A-Fast-Rerouting"><a href="#A-Fast-Rerouting" class="headerlink" title="A. Fast Rerouting"></a>A. Fast Rerouting</h2><p>​    当组件故障(链路故障或节点故障)发生在网络中，重新计算恢复方案，刷新路由表并等待路由信息收敛需要几秒钟到几分钟。 在这样的恢复期间，某些数据包可能会由于传递路径不完整或由于将流量转移到绕过故障的链路而导致的临时网络拥塞而丢失。 在高速网络中，即使恢复时间很短，也可能导致巨大的数据包丢失[10]，[11]。 为了减少网络恢复期间的流量损失，FRR旨在将受故障影响的数据包定向到预先计算的备份路径，这些路径在新路由最终收敛之前便已到达目的地[12]，[13]。<br>   反应时间对于FRR至关重要，因此在发生故障时查找备用路径是不切实际的。 转发引擎需要基于预先计算的信息在本地立即对故障做出反应[14]。 对于任何FRR机制，全面保护单个故障非常重要，这包括两个方面：</p><p>​    •对SLF的全面保护：对于网络中的任何SLF，如果故障链路的两端仍然连接，则应始终确定一条备份路径 从其中一个转移到另一个。<br>   •对SNF的全面保护：对于网络中的任何SNF，如果故障节点没有将整个网络分成多个部分，则应始终为通过该故障节点的每条路径找到备份路径。</p><p>​    在设计FRR方案时，除了确保全面保护单个故障外，还应考虑网络延迟，备份路径长度，拥塞级别[14]等。</p>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>grdientVisualization</title>
      <link href="/Codes/grdientVisualization/"/>
      <url>/Codes/grdientVisualization/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VLB</title>
      <link href="/ExtensiveReading/Route/VLB/"/>
      <url>/ExtensiveReading/Route/VLB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul><li>全称 valiant load balance ( 这里的Valiant是个人名)</li></ul><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><blockquote><p>在许多网络中，流量矩阵要么难以度量和预测，要么随时间变化很大。 在这些情况下，使用Valiant负载平衡（VLB）支持所有可能的流量矩阵是一种有吸引力的选择。 例如，即使由于高水平的聚集而导致Internet主干网中的流量非常平滑，但仍然很难测量。 准确地测量流量矩阵（例如使用NetFlow）太昂贵了，无法一直进行下去，而使用链路测量的标准方法会产生20％或更多的误差。 </p><p>即使可以令人满意地获得当前的流量矩阵，但由于Internet流量增长的不可预测性，将其推断到未来仍充满不确定性。 最后，由于Internet流量是动态的，因此流量矩阵可以随时偏离其正常值，从而可能导致拥塞。 网络看到的流量需求可以由流量矩阵表示，该矩阵表示每个节点向每个其他节点发起流量的速率。 我们说如果网络中的每个链接的流量矩阵所引起的负载小于链接的容量，则网络可以支持流量矩阵。 当网络无法支持提供给它的流量矩阵时，网络中至少一个链路的负载大于其容量。 发生拥塞，缓冲区中的积压积淀在拥塞的链路上，从而导致数据包丢失，增加的延迟以及延迟的高度变化。 理想情况下，我们希望设计一种可以支持各种流量矩阵的网络，以使拥塞很少发生或根本不发生。 </p><p>在本文中，我们讨论了VLB在构建网络中的使用，该网络可以有效地支持不会超额预订任何节点的所有流量矩阵。 我们首先简要地调查了VLB在网络各个方面的广泛使用，并描述了在网络中使用VLB的基本情况。</p></blockquote><ul><li><p>文章结构</p><p>第2.2节将VLB从同质设置扩展到具有任意容量的网络，第2.3节介绍了如何预防和快速恢复VLB网络中的故障，第2.4节建议使用VLB在两个网络之间路由流量。 最后，第2.5节讨论了未来可能的工作。</p></li></ul><h2 id="1-1-wide-use-of-VLB"><a href="#1-1-wide-use-of-VLB" class="headerlink" title="1.1 wide use of VLB"></a>1.1 wide use of VLB</h2><blockquote><p>在1980年代初期，Valiant [19]首次提出了一种通过随机挑选的中间节点到数据包目的地的路由方法。 他表明，<u>在N节点的二元立方网络中，在任何排列流量矩阵的情况下，分布式两阶段随机路由可以在O（log N）时间内以压倒性的概率将每个数据包路由到其目的地。 这是在O（log N）时间内在稀疏网络中路由任意置换的第一个方案</u>。 <strong>从那时起，这种随机路由已被广泛使用，通常称为（VLB），随机负载平衡或两阶段路由</strong>。  VLB具有许多良好的特性。 <strong>它是分散的，每个节点都在本地决策。 这也使该方案可扩展。</strong>  VLB is agonistic to traffic matrix，because <u><strong>randomness erases the traffic pattern ( 我觉得这里的意思是随机性会抵消流量模式 )，and different traffic pattern can result in the same load on the links</strong></u>。 </p><p><u>在发明之后不久，它就被用于其他互连网络中以进行并行通信，以缩短传送时间[1]，并减轻不利的流量模式的影响[13]</u>。 ==还有这种作用…[13]里面提到的omega network又是什么?下面的torus network又是啥…== 近年来，它适用于环形网络（torus networks）中的路由[17，18]，以便在不牺牲平均情况性能的情况下提供最坏情况的性能保证。 关键是使用VLB adaptively，这是基于以下观察：在低负载下，仅进行少量负载平衡就可以避免拥塞。  VLB还用于楼宇网络交换机，具有极大的可扩展性和性能保证，而无需集中式调度程序。 它用于ATM交换机[7]，路由器[4、5]，光路由器[3、9]和软件路由器[2]。 特别是，该方案is rediscovered (我觉得这里可以理解为重新挖掘)，用于设计路由器交换结构[4]来缓解路由器的扩展挑战，因为集中式方案很难跟上不断增长的链路速度。 在这种情况下，已证明拆分流量 in a round-robin fashion对链路负载的影响与随机拆分[4]相同，就支持所有流量矩阵所需的总互连容量而言，这是最有效的[8]。 </p><p>几乎同时，几个groups将VLB的思想独立地应用于Internet的流量工程和网络设计，以便有效地支持所有可能的流量矩阵。  Kodialam等人的两阶段路由[11，12] 是个traffic engineering方法，其中在固定容量的链路上建立了完整的隧道网格，并在网络的两个阶段（即两跳）中发送数据包。 网络。  Winzer等人的选择性随机负载平衡[14、16、21]使用VLB及其变体来设计经济高效的光网络。 他们的模型假设链路的成本包括光纤和终端设备，因此有减少链路的动机。 在最佳设计中，流量仅负载均衡到几个中间节点。  Zhang-Shen和McKewon [23，25]提出在骨干网的逻辑全网状网络( logical full mesh )上使用VLB，以支持所有流量矩阵并快速从故障中恢复。 另外，VLB还用作以太网LAN [20]中的光路由策略，用于城域WDM环中的调度[10]，电路交换网络[22]，以及数据中心网络的规模化和commoditizing[6]。</p><p>对VLB网络的排队属性的研究[15]发现，VLB消除了网络中的拥塞，伪随机（例如，循环）负载平衡减少了排队延迟。 当用于在网络之间路由流量时，VLB还可以消除对等链路上(peering links)的拥塞[26]。</p></blockquote><ul><li><p>==??== 如何做到的，本地决策，随机路由？还是没说啊…</p></li><li><p>可以在application flow level 处理 packet-by-packet或者flow-by-flow</p></li><li><p>分割按照random和deterministic都是一样的效果（已经证明出来</p></li></ul><h2 id="1-2-Simple-VLB-Network"><a href="#1-2-Simple-VLB-Network" class="headerlink" title="1.2 Simple VLB Network"></a>1.2 Simple VLB Network</h2><blockquote><p>这里的capacity指的是可以发起(initiate)和接收(receive)多少流量，缓冲区采用absorb这个词</p></blockquote><p>在full-mesh且每个节点的接收容量都是r的前提下，我们可以得到结论 : 相比于没有LB的（routing through direct path），VLB可以达到N/2倍的效率</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20201111145531666.png" alt="image-20201111145531666" style="zoom:80%;" /><h1 id="2-VLB-in-Heterogeneous-Networks"><a href="#2-VLB-in-Heterogeneous-Networks" class="headerlink" title="2 VLB in Heterogeneous Networks"></a>2 VLB in Heterogeneous Networks</h1><p>牵扯到分配比了，异构里面最简单的就是按r<del>i</del>的大小为权重进行分配，which is a direct generalization from uniform multicommodity flow in the homogeneous case to product multicommodity flow.</p><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li>里面有问题还是要ask下…<ul><li>smooth traffic</li><li>NetFlow to measure traffic matrix accurately<ul><li>using link measurement ，难道还有别的方法么？</li><li>配置在哪里，需要路由器配置一些特殊服务么？</li></ul></li><li>N-node binary cube network这个架构要了解下，可以问问王帅</li></ul></li><li>应该找个综述看看…(比如说18年那个)</li><li>路由分割如何保证包不乱序</li><li>流量工程和路由什么关系…</li></ul><ul><li>整理下好词好句</li></ul><h1 id="inspiration"><a href="#inspiration" class="headerlink" title="inspiration"></a>inspiration</h1><ul><li>感觉思路是 证明是NP难问题，然后用强化学习去解？</li></ul><h1 id="基于Internet的路由策略综述研究-另外开一个中文综述的文件"><a href="#基于Internet的路由策略综述研究-另外开一个中文综述的文件" class="headerlink" title="基于Internet的路由策略综述研究 另外开一个中文综述的文件"></a><span class="exturl" data-url="aHR0cDovL3d3dy5qc2preC5jb20vQ04vYXJ0aWNsZS9vcGVuQXJ0aWNsZVBERi5qc3A/aWQ9MTUxODE=">基于Internet的路由策略综述研究<i class="fa fa-external-link-alt"></i></span> 另外开一个中文综述的文件</h1><blockquote><p>这篇文章不错啊，文绉绉的。</p></blockquote><ul><li><p>QoS路由问题的核心就是对网络多约束条件下路由选择中的额NP完全性问题求解。</p></li><li><p>这是为啥</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20201111154656841.png" alt="image-20201111154656841" style="zoom:67%;" /></li><li><p>路由策略设计原则</p><ul><li><p>等强设计原则</p></li><li><p>降低成本原则</p><ul><li>需要信息越多，消耗的成本越高</li></ul></li><li><p>面向应用中的服务质量要求的原则</p><ul><li>网络应用大致分为四类<ul><li>非实时数据</li><li>实时图像</li><li>实时声音</li></ul></li><li>视频会议</li></ul></li></ul></li><li><p>03年的时候，不确定模型、动态模型、自适应模型是研究热点</p><ul><li><p>不确定性模型</p><p>针对网络状态信息不精确提出的。途径有：</p><ul><li><p>采用模糊理论进行不精确描述和概率分析 ；</p><ul><li>鉴 于神经网络不需要精确的系统描述（？这个着实没懂😓），只需要训练学习，能够实现联 想推理，容错性强，且 具有并行结构，实时性强 ，因此可以采用神经络对不精确模型进行 建模 ；</li><li>在网络系统的路由 、调度 、接纳控制等算法中引入随机 性方 法 与策 略 ；</li></ul></li><li><p>将预先计算和在线计算相结合</p></li></ul></li><li><p>动态模型</p><p>动态特性，即系统必须在运行过程中实时处理出现的异常、随机事件和局部故障，实现动态重构。【有点像快速重路由干的事情】</p></li><li><p>自适应模型</p><p>感觉就是我们现在做的事情</p></li></ul></li></ul><h1 id="基于深度强化学习的物联网智能路由策略"><a href="#基于深度强化学习的物联网智能路由策略" class="headerlink" title="基于深度强化学习的物联网智能路由策略"></a>基于深度强化学习的物联网智能路由策略</h1>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NUM</title>
      <link href="/NUM/"/>
      <url>/NUM/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote><p>考虑一个由一组容量的单向链路组成的网络，该网络由一组源共享，其中源的特征在于效用函数的传输速率呈凹形增加，目标是计算使总和最大化的源速率 的公用事业超过了容量限制。 集中解决该问题不仅需要了解所有实用程序功能，而且更糟糕的是，由于通过共享链接进行的源耦合，可能导致所有源之间的复杂协调。 取而代之的是，我们提出了一种分散式方案，该方案消除了这一要求，并自然地适应了不断变化的网络状况。 关键是要考虑对偶问题，其结构建议将网络链接和源视为分布式计算系统的处理器，以使用梯度投影法解决对偶问题。 每个处理器执行局部算法，将其计算结果传达给其他处理器，然后重复该循环。 该算法采用熟悉的反应流控制形式。 每个链路基于本地总的源速率，计算出链路上带宽单位的“价格”。源被反馈到标量价格，在标量价格中，使用的所有链路的总和将被收取，并且它选择传输速率以最大化自身的利益。 公用事业减去带宽成本。 这些单独的最优价格对于一般的价格向量可能不是社会最优的，即，它们可能不会使总效用最大化。 该算法迭代地接近使个人和社会最优性保持一致的价格向量，从而确实使总效用最大化。<br>   该算法是部分异步的[5，Ch。  [图6]中，源和链路可以基于过时的信息进行计算，它们可以在不同的时间以不同的频率进行通信，并且通信延迟可能很大，不同并且随时间变化。 我们证明只要更新之间的间隔是有界的，该算法就会收敛以产生最佳速率。 在平衡状态下，共享相同链接的源不一定平等地共享可用带宽。 相反，它们的份额反映了它们如何根据效用函数来表示对资源的重视程度，以及它们对资源的使用如何暗含了他人的成本。 这可能是根据不同的费率分配提供差异化服务的基础。 推导了基本算法，并在静态环境中证明了其收敛性，该环境中的链路容量和活动源集保持不变。 该算法直接推广到时变环境的情况。 我们从原型中给出了一些测量结果，这些测量结果说明了网络条件变化时算法的收敛性。 本文的结构如下。 在第二节中，我们提出了优化问题及其激励我们方法的对偶。 在第三部分中，我们导出了同步算法并描述了其收敛性。 该算法及其收敛证明在第四节中扩展为异步设置。 在第五节中，我们谈到公平和定价。 在第六节中，我们介绍了从原型获得的收敛性实验结果。 收敛性证明在两个附录中。  </p></blockquote><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​    We propose an optimization approach to flow control where the objective is to maximize the aggregate source utility over their transmission rates。 我们将网络链接和源视为分布式计算系统的处理器，使用gradient project algorithm去解决dual problem。 在此系统中，源选择传输速率以最大化their own benefits, utility minus bandwidth cost，and network links adjust bandwidth prices to coordinate the sources’ decisions.  We provide asynchronous distributed algorithms and prove their convergence in a static environment. We present measurements obtained from a preliminary prototype to illustrate the convergence of the algorithm in a slowly time- varying environment. We discuss its fairness property.。 我们允许 feedback delays to be different, substantial（很大的意思），and time varing，并且链接和源可以在不同的时间以不同的频率进行更新。 我们提供了异步分布式算法，并证明了它们在static environment中的收敛性。我们介绍了从初步原型获得的测结果，以说明算法在slowly time-varying的环境中的收敛性。 我们讨论其公平性(We discuss its fairness property)。</p><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><p>It seems better to 使用可变比特率（ABR）而不是恒定比特率（CBR）服务为可变带宽的弹性流量[31]提供服务[31]。的确，这种folklore可以在以下抽象模型中得到正式证明：假设网络为一组弹性资源提供固定和可变带宽，并根据过量需求对其定价，并且资源自由购买以最大程度地发挥自己的利益。 解释是，在模型中仅需要固定带宽的源实际上将订阅CBR，而同时需要固定带宽和可变带宽的源将subscribe to ABR with a minimum cell-rate guarantee。 我们在[23]，[24]中表明，在均衡状态下，所有信号源都处于最佳状态，需求等于供给，每个信号源都希望有严格正数的可变带宽。 这种观察可能为端到端流量控制提供了另一个动机，因为无功流量控制是提供可变带宽的一种实用方法，在无功流量控制中，源响应网络条件的变化来调整其传输速率。 本文的目的是提出一种流量控制的优化方法，其中将控制机制作为优化网络性能全局度量的一种手段。 我们将介绍同步和异步算法，并证明它们在静态网络环境中的收敛性。 然后，我们将描述一个原型，并提供实验测量值以说明算法的收敛性。</p><blockquote><p>这里把reactive flow control都叫做无功流量控制…</p></blockquote><h2 id="A-summary"><a href="#A-summary" class="headerlink" title="A summary"></a>A summary</h2><ul><li><p>背景/元素介绍</p><ul><li><p>a set L of 无向链路 of capacities $c_l, l\in L$</p></li><li><p>the network is shared by a set of $S$ of sources , and $s$ is characterized by a utility function  $U_s(x_s)$, <strong><u>which is concave</u></strong> increasing in its transmission rate $x_s$  ==居然是凹的..能理解为啥一定要是凹的么==</p></li><li><p>The goal is to calculate source rates that maximize the sum of the utilities $\sum_{s\in S} U_s(x_s)$ over $x_s$ subject to capacity constraints</p><p>集中解决该问题不仅需要了解所有实用程序功能，而且更糟糕的是，由于通过共享链接进行的源耦合，可能导致所有源之间的复杂协调。 取而代之的是，我们提出了一种分散式方案，**<u>该方案消除了这一要求</u>**【==居然可以去耦合，惊了==】，并自然地适应了不断变化的网络状况。 关键是要考虑对偶问题，其结构建议将网络链接和源视为分布式计算系统的处理器，以使用梯度投影法解决对偶问题。 每个处理器执行局部算法，将其计算结果传达给其他处理器，然后重复该循环。</p></li></ul></li></ul><ul><li><p>该算法采用熟悉的**<u>reactive flow control</u>**。</p><ul><li><p>流程</p></li><li><p>每个链路$l$基于local aggregate source rate==这个指的是收包的速率?==，计算出链路上带宽单位的“价格”$p_l$。A source $s$ is fed back the scalar price  $p^s=\sum p_l$，where the sum is taken over all links that  $s$ uses, and it chooses a transmission rate  $x_s$  that maximizes it own benefit $U_s(x_s)-p^sx_s$ , utility minus the bandwidth cost。</p></li><li><p>这些单独的最优价格对于a general price vector( $p_l,l\in L$ )可能不是social optimal，i.e.，它们可能不会使总效用最大化。该算法iteratively approaches a price vector ( $p_l^*,l\in L$ ) that aligns 个人和社会最优性保持一致的价格向量，从而( $x(p_l^{*s}),s\in S$ )确实使总效用最大化。</p><blockquote><p>我觉得这里a general price vector翻译成总体的价格向量</p><p>==所以这里的意思是调整价格向量？==</p></blockquote></li><li><p>该算法是<u>部分异步</u>的[5,Ch. 6]中，源和链路可以基于过时的信息进行计算，它们可以在不同的时间以不同的频率进行通信，并且通信延迟可能很大，不同并且随时间变化。 </p><ul><li><p>我们证明只要更新之间的间隔是有界的，该算法就会收敛以产生最佳速率。 </p></li><li><p>在平衡状态下，共享相同链接的源不一定平等地共享可用带宽。 相反，它们的份额反映了how they value their use of the resources，以及它们对资源的使用如何暗含了a cost on others。 这可能是根据不同的费率分配提供差异化服务的基础。 </p></li><li><p>基本算法 is derived and its convergence proved in a <u>static environment</u>，where 链路容量和活动源集保持不变。 该算法直接推广到时变环境的情况。 我们从原型中给出了一些测量结果，这些测量结果说明了<u>网络条件变化时</u>算法的收敛性。 </p><blockquote><p>定义了什么是static environment</p></blockquote></li></ul></li></ul></li><li><p>本文的结构如下。</p><ul><li>在第二节中，我们提出了优化问题及其激励我们方法的对偶。 </li><li>在第三部分中，我们导出了同步算法并描述了其收敛性。</li><li>该算法及其收敛证明在第四节中扩展为异步设置。</li><li>在第五节中，我们谈到公平和定价。 </li><li>在第六节中，我们介绍了从原型获得的收敛性实验结果。 收敛性证明在两个附录中。</li></ul></li></ul><h2 id="B-extensions"><a href="#B-extensions" class="headerlink" title="B extensions"></a>B extensions</h2><ul><li><p>现在，我们评论过去的作品和扩展。 **<u>基本算法已在[20]中提出，初步原型在[19]中进行了简要讨论</u>**。 在本文中，我们通过分析和实施来分析其收敛性和公平性。 基本算法要求将链接价格传递给源，将源速率传递给链接，<u>因此无法在Internet上实现</u>。 </p></li><li><p><u><strong>如下[25]，[21]大大简化了此通信要求</strong></u>。</p><p>在[25]中，我们描述了一种使用本地信息进行链接以估算源速率的方法，并证明了仍然保持了最优性。 这消除了从源到链接的显式通信的需要。 </p><p>相反，我们在[21]中提出了一种方法，该方法仅使用二进制反馈即可完成从链接到源的通信。 这可以通过使用IP头[9]，[27]中建议的显式拥塞通知（ECN）位来实现。 这两个简化组合成一个流控制方案，我们称之为随机早期标记（REM），它是随机早期检测（RED）的一种形式[10]，它不仅可以稳定网络队列，而且可以跟踪全局最优值。 面对较大的反馈延迟，使链接的价格取过去价格的加权平均值，REM变得更强大[1]。  REM及其增强功能将在本文的第二部分中详细介绍。</p></li></ul><ul><li><p>**<u>本文提出的优化模型具有双重价值</u>**。 首先，although it may not be possible, or critical, that optimality is exactly attained in a real network，但优化框架提供了一种将整个网络明确引导至desirable operating point的方法。下面我们将看到流控制可以看作是网络上的分布式计算，因此，整个网络的行为很容易理解。 其次，将实用的流控制方案简单地视为某种优化算法的实现是有用的。 然后，优化模型使系统的方法可以设计和完善这些方案，其中对流控制机制的修改以对优化算法的修改为指导。</p><p>例如，众所周知，牛顿算法的收敛速度比梯度投影算法快得多。 通过用牛顿算法代替本文提出的梯度投影算法，我们在[2]中推导了一种实用的牛顿式流量控制方案，该方案可以证明保持最佳状态，并且与此处的基本方案具有相同的通信要求，但享有更好的收敛性。 我们还将线性控制中的pole-placement technique应用于此模型，以在面对较大的反馈延迟时稳定其瞬态。 这导致了更健壮的REM，见[1]。 </p></li></ul><h2 id="C-related-work"><a href="#C-related-work" class="headerlink" title="C related work"></a>C related work</h2><p>​    关于流量控制的文献很多，包括原始的TCP流量控制[15]和最近[10]的enhancement，例如[28]，[6]的二进制反馈方案，[22]的两位反馈方案。例如[3]，[29]，[7]等的控制理论方法。另请参阅[14]中的recent review。 </p><p>​    基于优化的流量控制的关键前提[8]，[11]-[13]，[16]，[17]，[19]-[21]，[25]是带宽评估不同的源应做出不同的反应去应对网络拥塞。所有这些工作都通过优化问题来激发流控制，并导出其控制机制作为优化问题的解决方案。 它们在目标功能或解决方案的选择上有所不同，并导致在源和网络链路上实施的流控制机制大不相同。</p><p>我们的模型最接近[16]，[17]。 确实，他们和我们的工作都具有最大化总source utility的相同目标。 在[16]，[17]中，该目标被分解为网络和资源的优化子问题，并且他们为解决方案提出了一种不同的机制，其中每个资源选择支付意愿，网络将价格分配给这些资源, in a way that is proportionally fair。 他们的方法的一个有趣特征是，它允许用户决定他们的payments并接收what the network allocates，而在我们的方法中，users decide their rates and pay what the network charges。 </p><p>参见第3节中算法A1之后的Remark 3中的更详细比较。</p><h1 id="2-Optimization-Problem"><a href="#2-Optimization-Problem" class="headerlink" title="2 Optimization Problem"></a>2 Optimization Problem</h1><p>In this section, we state the optimization problem that leads to our congestion control framework, and suggest a solution approach. Algorithms to solve the problem will be given in the following sections.</p><h2 id="A-Primal-Problem"><a href="#A-Primal-Problem" class="headerlink" title="A Primal Problem"></a>A Primal Problem</h2><ul><li><p>无向链路集合<img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/19/061641-41204.png" alt="image-20201112093628276">with capacity $c_L$ , and node set $S$</p></li><li><p>source $s$ is characterized by 4 parameters $(L(s),U_s,m_s,M_s )$</p><ul><li><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/093928-566242.png" alt="image-20201112093823706">是s使用的链路</li><li><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/093928-477615.png" alt="image-20201112093839793">是效用函数 ==这里给映射到负的去了。。可以。不过效用函数本来是正的 ？？why一定positive== 是严格凹的 in its argument 【==in its argument就不是很懂什么意思了…==】</li><li><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/093931-317765.png" alt="image-20201112093928373">是最小和最大的传输速率，required by source $s$. <img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/19/061911-954792.png" alt="image-20201112094016129"><ul><li>这里画蛇添足定义了个区间<img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/094201-949888.png" alt="image-20201112094200258"> and vector <img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/094251-895066.png" alt="image-20201112094214541">，也许是为了后面方便描述吧</li><li>以及<img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/094319-535488.png" alt="image-20201112094302977"> 还有他们之间的关系 : <img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/094409-28038.png" alt="image-20201112094353039"><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/094418-230495.png" alt="image-20201112094417287"></li></ul></li></ul></li><li><p>目标是</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/100622-139567.png" alt="image-20201112094447875"></p><p>​    约束（2）说，任何链路上的总源速率不超过容量。 由于目标函数严格是凹的，因此是连续的，并且可行解集很紧凑，因此存在一个称为初始最优解的唯一最大化器。</p><p>​    尽管目标函数是分散在$x_s$中的，但源速率是由约束条件（2）耦合的。 解决原始问题（1）–（2）直接需要可能所有来源之间的协调，这在实际网络中是不切实际的。 分布式和分散式解决方案的关键是看它的dual。</p></li></ul><h2 id="B-dual-problem"><a href="#B-dual-problem" class="headerlink" title="B dual problem"></a>B dual problem</h2><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/19/031850-49320.png" alt="image-20201112100641332"></p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/19/031915-980440.png" alt="image-20201112101120788"></p><p>==这里的转换后面要再品品==</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/12/101552-854681.png" alt="image-20201112101128691"></p><p>至于$p_l$和$c_l$为什么能提出来，是因为其与$s$无关。这里$p$一定是正的，因为这里是拉格朗日的罚函数</p><ul><li>假如把$p_l$当作是link l 每单位带宽的价格，那么$p^s$就是节点s所有links的总的带宽均价，所以$x_sp^s$代表 s 以一定速率传输时源的带宽成本 , and $B_s(p^s)$ 代表在给定价格$p^s$下可以实现的最大收益我们将在下面看到，该标量$p^s$ summarizes了所有源需要知道的拥塞信息。</li><li>A source $s$ can be induced to solve maximization (3) by bandwidth charging. 【我这里的理解就是，可以通过调节s的charging，也就是调节p，来达到最大化全局奖励】对于每一个$p$，都有一个唯一的最大化器，用表示，因为它是严格凹的。</li><li>通过对偶理论… 因此，我们将专注于解决对偶问题（5）。 一旦我们获得了$p^*$, 原始的最佳源速率就可以通过（3）求解by简单的最大化（见下面的（6））。<strong>要注意的重要一点是，给定单个来源可以独立求解（3），而无需与其他来源进行协调。 从某种意义上说，它是将（3）的个人最优与（1）的社会最优对齐的协调信号</strong>。</li></ul><blockquote><p>对偶问题，最小化对偶问题，就是最大化原始问题的上界</p></blockquote><h2 id="C-Notations-and-Assumptions"><a href="#C-Notations-and-Assumptions" class="headerlink" title="C Notations and Assumptions"></a>C Notations and Assumptions</h2><p>routing matrix $R_{ls}$</p><ul><li>第一段的==induced norm?==</li><li>Kuhn-Tucker theorem 就是KKT条件</li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p>abstract都没怎么看懂…</p></li><li><p>对偶问题，拉格朗日要满组KKT才是强对偶（check</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9zbGlkZXBsYXllci5jb20vc2xpZGUvODExMzQxMi8=">这个link<i class="fa fa-external-link-alt"></i></span>是这篇文章的slide link</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZWNlLnJ1dGdlcnMuZWR1L35tYXJzaWMv">这个老师的博客<i class="fa fa-external-link-alt"></i></span></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MRTE</title>
      <link href="/ExtensiveReading/Route/MRTE/"/>
      <url>/ExtensiveReading/Route/MRTE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LearningToRoute</title>
      <link href="/ExtensiveReading/Route/LearningToRoute/"/>
      <url>/ExtensiveReading/Route/LearningToRoute/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li><p>传统的问题是</p><ul><li>1</li><li>2</li></ul><blockquote><p>==其实感觉跟CC方面遇到的问题很相似？==</p></blockquote></li><li><p>建模假设</p><ul><li>流量需求的历史情况包含未来的一些信息</li><li>DM存在一定的规律</li></ul></li><li><p>思路是，如果已知DM，自然是可以用LP做全局优化，但是现在未知。另一方面，先预测后做决策的效果太慢了。</p></li></ul><ul><li>这篇文章的文笔很好…写作可以学习（辞藻、结构、连接句 都可，一开始的时候我还没有好好看…）</li></ul><p><u><strong>使用的是TRPO</strong></u></p><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​    近来，人们已经集中精力关注是否/何时依赖于人类专家的算法洞察力的传统网络协议设计可以被数据驱动（即机器学习）方法代替的问题。 我们在可能是最基本的网络任务：路由的背景下探讨这个问题。 是否可以利用机器学习（ML）的思想和技术来自动生成“良好”的路由配置？ 我们关注域内流量工程的经典设置。 我们注意到，这种情况对数据驱动协议设计提出了重大挑战。 关于数据驱动路由功能的初步结果表明，在这种情况下应用ML（特别是深度强化学习）可产生高性能，并且是进一步研究的有希望的方向。 我们概述了ML导向路由的研究议程（We outline a research agenda for ML-guided routing）。</p><h1 id="1-Introducion"><a href="#1-Introducion" class="headerlink" title="1 Introducion"></a>1 Introducion</h1><h2 id="why-apply-ML-to-routing"><a href="#why-apply-ML-to-routing" class="headerlink" title="why apply ML to routing"></a>why apply ML to routing</h2><p>​    传统上，路由优化以两种方式之一来应对未来交通状况的不确定性：</p><ul><li>针对先前观察到的交通状况优化路由配置，希望这些配置也能与未来相得益彰 ，</li><li>针对各种可行的交通场景进行优化，以期在整个范围内提供高性能[7，10，16，29]。 </li></ul><p>​    缺陷是</p><pre><code>* &lt;u&gt;即使在不太不同的流量条件下，针对特定流量条件进行优化的路由配置也可能惨败，无法获得良好的性能&lt;/u&gt;* &lt;u&gt;此外，在各种考虑的交通场景中优化最坏情况的性能可能会以远离实际交通状况的最佳实现为代价。&lt;/u&gt;</code></pre><p>​    机器学习提出了第三种选择：利用有关过去交通状况的信息来学习针对未来状况的良好路由配置。 尽管决策者事先无法确定确切的未来流量需求，但现实的假设是流量需求的历史记录包含有关未来的一些信息（例如，一天中的流量变化，流量的偏斜度，是否一定的结束时间）  -主机经常通信等）。 因此，一种自然的方法是持续观察流量需求，并根据（隐式或显式）关于未来的预测调整路由。</p><h2 id="intradomain-TE-as-a-case-study"><a href="#intradomain-TE-as-a-case-study" class="headerlink" title="intradomain TE as a case study"></a>intradomain TE as a case study</h2><p>​    我们通过检查域内TE的经典环境[10、15-17、24、29、50]来启动ML引导路由的研究，which是在a single,self-administered 网络中优化路由的方法。 <u>我们将在其他情况下对数据驱动路由的研究留给以后的研究（第7节）。 我们提供了一个基于数据驱动（域内）路由的模型，该模型建立在域内TE [10、15–17、24、29、50]和[多商品[5、7、10、16、22，  29，43]）流程优化</u>。 </p><p>​    我们在这个模型中研究了不同的机器学习范式和机器的应用。 在我们研究ML引导域内TE的过程中，**<u>我们解决了两个主要问题</u>**：</p><ul><li>如何将路由表述为ML问题？  </li><li>在该领域学习的输入和输出是什么合适的表示？ 接下来，我们将探讨这些挑战中的每一个。</li></ul><h3 id="learn-what-future-TE-demands-or-routing-configurations-Supervised-learning-or-RL"><a href="#learn-what-future-TE-demands-or-routing-configurations-Supervised-learning-or-RL" class="headerlink" title="learn what ? future TE demands or routing configurations? Supervised learning or RL?"></a>learn what ? future TE demands or routing configurations? Supervised learning or RL?</h3><p>​    一种基于ML的路由的自然方法如下：观察过去的流量需求，应用ML明确预测即将到来的流量需求，并根据预测的需求优化路由。 用机器学习的术语来说，这是一个监督学习任务[39]。</p><p>​    我们评估了几种监督学习方案，以预测交通需求。 我们的初步结果令人沮丧，这表明<u>如果交通状况不具有很高的规律性，监督学习可能会无效</u>。 接下来，我们将注意力转向另一种方法：强化学习[45]。 现在，与其明确地了解未来的流量需求并针对这些需求进行优化，不如从观察到的流量需求历史到路由配置中学习一个良好的映射。 我们的初步结果表明，这种方法更有希望，但要意识到这一点需要谨慎，如下所述。</p><h3 id="What-should-the-output-of-the-learning-scheme-be"><a href="#What-should-the-output-of-the-learning-scheme-be" class="headerlink" title="What should the output of the learning scheme be?"></a>What should the output of the learning scheme be?</h3><p>​    域内路由上下文对强化学习的应用提出了重大挑战。 一个关键挑战是路由方案的自然“输出”是一组规则的集合，这些规则指定如何将流量从每个源转发到每个目的地。 此输出的幼稚表示形式涉及大量参数（与之相对，例如，从相当小的集合中选择单个动作[32，33]）。我们的初步结果表明，这会使学习缓慢而无效。 因此，我们设计了一些方法来限制输出的大小，而又不会在路由选择的复杂性上“损失太多”。 我们利用有关逐跳流量工程的文献[16、35、50]的思想，通过深度强化学习有效地学习良好的路由配置。 我们的初步发现表明，这是改善当今域内TE的有希望的方向。</p><h3 id="Outlining-a-research-agenda-for-data-driven-routing"><a href="#Outlining-a-research-agenda-for-data-driven-routing" class="headerlink" title="Outlining a research agenda for data-driven routing"></a>Outlining a research agenda for data-driven routing</h3><p>我们相信下面的investigation仅仅只是在数据驱动路由领域隔靴搔痒。 我们给读者留下了许多有趣的研究问题，包括</p><ul><li>将我们的方法扩展到其他路由环境</li><li>检查其他性能指标</li><li>识别更好的监督学习方法以进行流量需求估算</li><li>扩展 在这种情况下以及其他情况下的强化学习</li></ul><p>我们将在第7节中讨论此研究议程。</p><h1 id="2-Data-driven-routing-model"><a href="#2-Data-driven-routing-model" class="headerlink" title="2 Data-driven routing model"></a>2 Data-driven routing model</h1><p>​    在我们的框架中，决策者（网络运营商/自动化系统）反复选择路由配置。 流量条件各不相同，并且路由决策不会影响未来的流量需求。 我们的重点是将流量工程literature中的链接的over-utilization最小化（也称为最小化拥塞）的常规优化目标[7，10，16，29]。</p><h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><blockquote><p>我们将网络建模为a capacitated directed graph G =（V，E，c），其中V和E分别是顶点和边集，而c：E→R +为每个边分配一个容量。 令n表示V中的顶点数，而Γ（v）表示G中顶点v的相邻顶点。</p></blockquote><h2 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h2><blockquote><p>该网络的路由策略R为每个源顶点s和目标顶点 t 指定了遍历v的从s到t的流量如何在v的邻居之间分配。 因此，路由策略为每个顶点v和源－目的地对（s，t）指定了一个介于v的邻居到值[0，1]，Rv，（s，t）的映射：Γ（v  ）→[0，1]，因此Rv，（s，t）（u）是从s到t穿越v且v转发到其邻居u的流量的一部分。 我们要求对于每个s，t∈V和v，t，Pu∈Γ（v）Rv，（s，t）（u）= 1（在非目标位置没有流量被Blackholed），并且对于每个 s，t∈V，u∈Γ（v）Rt，（s，t）（u）= 0（到目的地的所有流量都在该目的地吸收）。</p></blockquote><h2 id="Induced-flows-of-traffic"><a href="#Induced-flows-of-traffic" class="headerlink" title="Induced flows of traffic"></a>Induced flows of traffic</h2><blockquote><p>需求矩阵（DM）D是一个n×n矩阵，其第（i，j）个条目Di，j指定了源i和目的地j之间的流量需求。 观察到任何需求矩阵D和路由策略R都会引起网络中的流量流，如下所述。 从每个来源s到目的地t的流量都根据Rs（s，t）在s的邻居之间分配。 同样，从s到t的流量经过s的邻居v会根据Rv，（s，t）等在v的邻居之间分配。</p></blockquote><h2 id="How-good-is-a-traffic-flow"><a href="#How-good-is-a-traffic-flow" class="headerlink" title="How good is a traffic flow"></a>How good is a traffic flow</h2><blockquote><p>我们采用了最小化链接（过度）使用率的经典目标函数[7，10，16，29]。 特定多商品流f下的链路利用率为maxe∈Ec（e），<strong>其中fe是流f下横穿edge e的流的总量</strong>。 我们的公式很容易扩展到其他基于多商品流的目标函数。 我们将其他目标（例如，流完成时间，延迟）的评估留给以后的研究（第7节）。</p></blockquote><p>hesy: 这里的居然不是所有流经过该链路的总流量,而是某个流 f 经过该链路的流量。【注意跟别的文章的区分，也许别的文章就是在讲这个】</p><p>我们指出，对于任何给定的需求矩阵，可以通过线性编程[7，16，22]以一种计算有效的方式来执行使链路利用率最小的多商品流f的计算。 <strong>相反，我们的重点是在实际情况下事先不知道DM。</strong></p><h3 id="Routing-future-traffic-demands"><a href="#Routing-future-traffic-demands" class="headerlink" title="Routing future traffic demands"></a>Routing future traffic demands</h3><p>​    时间分为连续的间隔，称为“时期”，其长度为<u><strong>δt（δt由网络运营商确定</strong></u>）。 在每个时期t的开始，确定该时期的路由策略R（t）。  R（t）只能取决于过去的流量模式和路由策略的历史记录（从时期1，…，t-1）。 </p><p>​    我们做出两个简化的假设：</p><ul><li>需求矩阵在每个时间段都是固定的；==这个假设没有很懂==</li><li>事后可以推断出需求矩阵（例如，通过网络测量）。</li></ul><p>​    我们将对数据驱动路由的研究放在更复杂的流量模式下（例如，IP流在每个时期内进出），以及对信息约束的路由决策（例如，仅关于过去流量需求的部分信息）的研究。</p><p>​    在选择了针对时间段t的路由策略R（t）之后，针对时间段t的需求矩阵以及相关的成本就最大的链路利用而言被揭示出来。 决策者的目标是选择一种路由策略，其方式应始终导致较低的链路过度使用率。</p><h1 id="3-What-to-learn"><a href="#3-What-to-learn" class="headerlink" title="3 What to learn"></a>3 What to learn</h1><p>我们的基本假设是DM中存在某种规律性，下面的研究目的是探索如何推断出这种规律性并利用它们来优化路由。 <strong>我们考虑两种不同的规律性表现形式：将确定性规律性嵌入DM序列中，并从固定的概率分布中抽取DM。还有两种高级学习方法：监督学习和强化学习</strong>。</p><h2 id="3-1-Supervised-Learning-Approach"><a href="#3-1-Supervised-Learning-Approach" class="headerlink" title="3.1 Supervised Learning Approach"></a>3.1 Supervised Learning Approach</h2><blockquote><p>由于对于给定的需求矩阵（DM），最佳路由策略是可有效计算的，因此自然的方法是反复尝试预测（即学习）下一个DM，然后为该DM计算最佳路由策略。 用机器学习术语来说，这是一个监督学习问题。</p></blockquote><h3 id="什么是监督学习"><a href="#什么是监督学习" class="headerlink" title="什么是监督学习"></a>什么是监督学习</h3><h3 id="如何生成DM"><a href="#如何生成DM" class="headerlink" title="如何生成DM"></a>如何生成DM</h3><ul><li>gravity model [40] &amp; bimodal model[34]</li><li>sparsification of gravity/bimodal DMs</li></ul><blockquote><p>我们考虑生成DM的两种标准方案：（确定性）引力模型[40]和（概率性）双峰模型[34]。 直观地，前者捕获了端点之间的通信与它们的输出带宽成比例的场景，而后者捕获了通信端点被分为小流量（小鼠）和大流量（大象）的场景。 <a href="">****</a></p><p>我们还考虑了重力/双峰DM的“稀疏化”，它是通过随机地均匀选择通信对的p分数（对于p∈[0，1]）并消除所有其他交通需求而产生的 对考虑。 我们将p称为DM的稀疏性。 我们的实验需要生成DM序列，为每个时间段指定一个DM。 </p></blockquote><p>我们检查了两类DM序列：</p><h4 id="Class-I"><a href="#Class-I" class="headerlink" title="Class I"></a>Class I</h4><p>DM sequences in which the next DM is deterministically derived from past DMs.</p><p>DM是有周期性规律的，我们评估了周期为q的DM cycles，which q=5，10，15，20，其中每个DM是前q=5，10，15，20个DM的均值。且DM为稀疏的。</p><blockquote><p>这里还给了一个例子，which证明了流量模式具有temporal consistencies</p></blockquote><h4 id="Class-Ⅱ"><a href="#Class-Ⅱ" class="headerlink" title="Class Ⅱ"></a>Class Ⅱ</h4><p>DM sequences in which each DM is independent of the previous DMs. </p><p>现在，与每个DM上的固定概率分布（即稀疏重力/双峰DM）无关地绘制每个时期的DM。 <u>我们指出，这种流量模式通常用于评估数据中心的体系结构和协议[4、19、25、51]，</u><strong>因为数据中心的流量通常被认为是高度偏斜且不可预测的[18、20]。</strong>    </p><h3 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h3><p>评估了3种不同的DNN体系结构。 这三种架构的输入都是最近观察到的k个DM，而输出则是DM。 我们检查k的不同值（5、10和20）。 我们使用Frobenius（或l2）范数[21]来量化相对于实际DM的输出质量。 三种体系结构的不同之处在于，神经网络的结构将输入层（代表DM的k长历史记录）和输出层（代表下一个DM）相互连接。 我们评估</p><ul><li>FCN，一个三层全连接网络</li><li>CNN，一个四层卷积神经网络[30]</li><li>NAR-NN，一个非线性自回归模型[11] 通过四层神经网络实现，对于输入需求矩阵D(1),…, D(k)学习k矢量α＝（α1，…，αk）和n×n矩阵β，并输出<img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201104154216675.png" alt="image-20201104154216675">。</li></ul><h3 id="evaluation-framework"><a href="#evaluation-framework" class="headerlink" title="evaluation framework"></a>evaluation framework</h3><p>​    在稀疏度p = 0.3、0.6、0.9、1和每个顶点传出带宽的值（从10 MB到10 GB）变化的情况下，我们选取了(9×9, 12×12, 23×23, 30×30, 50 × 50, and 100 × 100) size的模型。</p><p>​    我们考虑了各种DM序列长度来训练和测试模型（从DM的10到100的范围）。 对于为q，p，k和序列长度分配参数的每个选择，我们都会生成10个DM序列的训练集和3个DM序列的测试集。 我们将学习epoch定义为训练集的完整遍历。 我们为每个神经网络训练<strong>2000个学习epoch</strong>。</p><h3 id="results"><a href="#results" class="headerlink" title="results"></a>results</h3><p>​    我们的实验结果（针对测试的DM序列）表明，对于表现出确定性的DM序列（即DM和“平均DM”的周期），仅NAR-NN的性能相当好，并且仅针对所检查历史之间的特定关系 （k），周期的大小/ DM的平均值超过（q）。 具体而言，当q≤k时，NAR-NN对DM的周期很好地逼近下一个DM，并且在平均DM上表现良好。 当q&gt; k时，NAR-NN在平均DM上继续表现良好，但在q&gt; k的DM周期中失败。 对于随机生成的DM，所有3种架构都无法近似下一个DM（这并不奇怪，因为序列中DM之间没有时间相关性）。 我们在具有30个顶点的网络G上显示NAR-NN的代表性结果。 我们根据预测的DM与实际DM的距离（y轴）绘制学习历元（x轴）上的损失。 图1b和图1a表明，使用平均和循环DM序列生成时，该模型成功学习了下一个DM。 图1c展示了从概率分布中得出的学习下一个DM的失败。 我们将继续研究在未来对交通需求进行更好的监督学习是否可行（请参见第7节）。<br>   3.2</p><p>16:40开始读阿里的</p><h1 id="questions"><a href="#questions" class="headerlink" title="questions"></a>questions</h1><h2 id="to-be-summarized"><a href="#to-be-summarized" class="headerlink" title="to be summarized"></a>to be summarized</h2><h3 id="辞藻"><a href="#辞藻" class="headerlink" title="辞藻"></a>辞藻</h3><p>Unfortunately 是另一个能很好的表达转折意味的副词</p><p>a rich body of 丰富的 （ a rich body of literature/researches )</p><p>a bunch of </p><p>render 造成 –&gt; make</p><p>devise  发明，想出，设计  design</p><h2 id="others"><a href="#others" class="headerlink" title="others"></a>others</h2><ul><li><p>勾画出来的文献要整理一下 </p></li><li><p>==有实验数据或者论文支撑么==</p><blockquote><p>intro: 我们评估了几种监督学习方案，以预测交通需求。 我们的初步结果令人沮丧，这表明<u>如果交通状况不具有很高的规律性，监督学习可能会无效</u></p></blockquote></li><li><p>文中标红的再看一下</p></li><li><p>第三章节的建模里面： 三种体系结构的不同之处在于，神经网络的结构将输入层（代表DM的k长历史记录）和输出层（代表下一个DM）相互连接。？？？</p></li><li><p>TRPO是15年的论文，DDPG是16年的，为什么17年投的这篇Hotnets应该做的时候两个算法都有，且DDPG更为state-of-art，想请问下采用DDPG</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>paperWriting</title>
      <link href="/Summary/paperWriting/"/>
      <url>/Summary/paperWriting/</url>
      
        <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <div class="hbe-input-container">  <input type="password" id="hbePass" placeholder="" />    <label for="hbePass">Hey, password is required here.</label>    <div class="bottom-line"></div>  </div>  <script id="hbeData" type="hbeData" data-hmacdigest="4d1623528c7a47c5fc34f8a69e4c2cd762849291765d20620f0830d39897dc47">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</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Writing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fuzzy Kanerva-based TCP Q-learning</title>
      <link href="/ExtensiveReading/CC/FuzzyKanerva-basedTCPQ-learning/"/>
      <url>/ExtensiveReading/CC/FuzzyKanerva-basedTCPQ-learning/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Hesy-summary"><a href="#Hesy-summary" class="headerlink" title="Hesy summary"></a>Hesy summary</h1><p>主要用于梳理下行文思路，用于写作学习。abstraction,design,performance都很出彩</p><ul><li><p><a href="#abstract">abstract</a>的三段论值得学习</p></li><li><p>introduction的逻辑应该是 <code>我们提出了XXXX，能克服前人工作的xx缺点</code> 而不是<code>前人工作有xx缺点，为此我们提出了XXXX</code></p></li><li><p>related work里面的抨击值得摘抄！</p></li><li><p>design的逻辑很好！</p><ul><li>整体的运行架构是什么 （ 如何将Q-learning算法结合我们的场景进行运行</li><li>RL的几个要素分别是什么 （ 如何结合Q-learning算法和我们的问题进行芥末</li><li>实现上遇到的challenge 以及我们的解决方案 , which is another 华彩</li></ul></li><li><p><a href="#Performance">performance</a>的逻辑和布局也学习到了！</p><ul><li>实验设置</li><li>整体在xx 和 yy 方面的提升 &amp;  为何会出现这样情况的分析</li><li>在xx方面的结果 翔实的展示； 在yy方面的结果 翔实的展示</li></ul></li><li><p>小细节</p><ul><li>自己拼接造出的单词 ，dash别忘了<ul><li>sub-component</li><li>pre-configured</li><li>re-think</li></ul></li></ul></li></ul><a id="more"></a><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><ul><li><p>【<strong>Background: important things and urgent need</strong>】 </p><p>Advances in YY technology have resulted in <strong>pervasive deployment</strong> of devices of … . <strong>The need</strong> for <strong>XX</strong> that ….( 描述下对XX的性能期待, e.g. 高吞吐,低延迟 )  <strong>necessitate re-thinking</strong> of conventional design of （你要研究的领域/东西）.</p><blockquote><p>无线技术的进步已导致在尺寸，存储和计算能力方面具有高度可变性的设备的普遍部署(pervasive deployment)。 为了保持以高可靠性传送数据的连续连接，需要重新考虑传统的传输层协议设计。</p></blockquote></li></ul><ul><li><p>【<strong>What we propose and what’s its features</strong>】</p><p><strong>This paper investigates</strong> the use of  <strong>ZZ ** （你使用的算法/技巧/工具） in **YY</strong>（你研究的领域）… , <strong>wherein</strong> …（描述下你做了什么）. <strong>Furthermore</strong>, it demonstrates how …(具体描述下研究工作中华彩的细节，套路大概就是”我发现了xx(性能瓶颈)在实现的时候很关键，我们是这样解决的”)</p><blockquote><p>本文研究了在拥塞避免状态期间Q学习在TCP cwnd adaptation中的使用，其中窗口的经典alternation已被replaced，从而允许协议立即响应先前看到的网络条件。此外，它展现了内存如何在构建探索空间中发挥关键作用，并提出了通过函数逼近来减少此开销的方法。[ 后面这句话实际上不是一个addtional point，还是在讲这个scheme本身，只不过是scheme的细节，which 是自己的巧思体现之处。] </p></blockquote></li></ul><ul><li><p>【<strong>Performance description</strong>】</p><p><strong>The superior performance</strong> of <u>our</u> approach over <em>Baseline XX</em> is <strong>demonstrated through a comprehensive simulation study</strong>, <strong>revealing</strong> xx% and xx% improvement in <em>metric1</em> and <em>metric2</em> respectively,on real-world(classic) traces/topologies. <strong>We also show</strong> <strong>how</strong> <strong>ZZ **（你使用的算法/技巧/工具） **can be used to</strong> (处理上一段所说的性能瓶颈，while 保持了一个好的performance( 高吞吐/低延迟,这个还是要细点说的) ) .</p><ul><li>这里our换成别个描述characteristic的形容词更好，e.g. learning-based/data-driven</li></ul><blockquote><p>通过全面的仿真研究证明了基于学习的方法优于TCP New Reno的性能，对于评估的拓扑，吞吐量和延迟分别提高了33.8％和12.1％。 我们还展示了如何使用函数逼近来显着降低基于学习的协议的内存需求，同时保持相同的吞吐量和延迟。</p></blockquote></li></ul><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><p>快到1页</p><p>==这里的表达不应该是“以往的工作有xx缺点，为改进此缺点我们提出…”，而应该是“以往的工作有xx缺点。我们提出了基于xx技术的XX。它的表现…and… ”==</p><h1 id="2-motivation-and-practical-relevance"><a href="#2-motivation-and-practical-relevance" class="headerlink" title="2 motivation and practical relevance"></a>2 motivation and practical relevance</h1><p>快到1页</p><h1 id="3-related-work"><a href="#3-related-work" class="headerlink" title="3 ==related work=="></a>3 ==related work==</h1><blockquote><p>这一段写的贼好，要好好学习！</p></blockquote><p>一栏</p><ul><li><p>传统CC的问题</p></li><li><p>现在CC的问题</p></li><li><p>其他CC相关的工作</p><blockquote><p>应用机器学习来帮助提高TCP性能的其他工作很少。 例如，[13]使用机器学习来构建损耗分类器，以区分链路损耗和拥塞损耗，[14]和[15]使用机器学习来更好地估计RTT和吞吐量。 这些技术都不能直接调整cwnd。</p></blockquote></li></ul><h1 id="4-Q-learning-based-TCP"><a href="#4-Q-learning-based-TCP" class="headerlink" title="4 Q-learning-based TCP"></a>4 Q-learning-based TCP</h1><blockquote><p>整体</p></blockquote><p>​    我们提出的算法TCPLearning是基于强化学习的协议。 在强化学习中，学习主体在没有先验知识的情况下与环境交互，根据所学习的策略选择动作，获得正面或负面的奖励，然后观察环境的下一个状态。学习代理的目标是制定一种策略，即状态空间到动作空间的映射，以最大化长期打折的奖励。 此后，TCPLearning不再想PCC那样使用probe来检测不同动作对性能的影响，而是使用增强算法Q-Learning来学习最佳策略，以根据经验直接在每个状态下做出动作选择。<br>   TCPLearning发送方使用New Reno协议的正常慢启动阶段。 如果慢启动在cwnd超过阈值时结束，则拥塞控制过程将进入拥塞避免阶段，我们的学习算法将接管控制cwnd。 如果由于观察到拥塞而导致慢速启动结束，则New Reno协议继续，并且不使用学习算法。 如果在拥塞避免阶段检测到数据包丢失，则学习算法将停止，并且将应用New Reno协议来实现快速重传和快速恢复。<br>   <strong>与在New Reno中一样，TCPLearning的最重要任务是调整cwnd的大小。 在每个时间段（通常是一个RTT）中，我们的算法通过处理ACK信息来收集吞吐量和RTT值，然后将它们组合成单个效用函数U。效用函数随着吞吐量的增加和延迟的减少而增加。 该算法的目标是了解cwnd大小的变化如何增加效用函数的值。<br>   学习算法使用Q学习来学习策略以选择动作并实现其目标。Q学习使用简单的值迭代更新过程。 在时间t处，对于每个状态st和at处的每个动作，算法按如下方式计算对其预期折现奖励或动作值函数Q（st，at）的更新：</strong></p><p>​    其中rt + 1是时间t +1的即时奖励，αt（st，at）是折现因子，使得0≤γ&lt;1。Q学习是学习率，使得0≤αt（st，at）≤  1和γ将Q（st，at）值存储在称为Q表的表中。 更新Q（st，at）值的时间复杂度为O（| A |），其中| A | 是动作数。</p><hr><blockquote><p>状态</p></blockquote><p>​    系统的状态由四个状态变量表示，<u>状态变量的值通过离散化划分</u>：</p><p>   •新接收到的ACK之间的间隔时间的移动平均值，离散为10个间隔。<br>   •发送方发送的数据包之间的间隔时间的移动平均值，离散为10个间隔。<br>   •当前的RTT与到目前为止找到的最佳RTT之比，离散为10个间隔。<br>   •缓慢启动阈值，离散为10个间隔。</p><hr><blockquote><p>动作</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/25/210337-366485.png" alt="image-20201025210336629"></p><p>​    表II总结了更改cwnd的可用操作。 </p><p>​    奖励函数基于效用值的变化：</p><p>​                U = loge（吞吐量）-δ×loge（延迟）吞吐量</p><p>​    其中δ表示延迟相对于效用函数的相对重要性。 在我们的实验中，δ设置为1。</p><p>​    奖励函数等于：</p><ul><li>+2，如果效用在时间段t之后增加</li><li>-2，如果效用在时间段t之后减少。    </li></ul><p>​    其中t设置为0.1s（在我们的实验中为一个RTT）</p><h1 id="5-FUZZY-KANERVA-BASED-TCP-Q-LEARNING"><a href="#5-FUZZY-KANERVA-BASED-TCP-Q-LEARNING" class="headerlink" title="5  FUZZY KANERVA-BASED TCP Q-LEARNING"></a>5  FUZZY KANERVA-BASED TCP Q-LEARNING</h1><blockquote><p>先讲总体的思路，再讲细节的设计</p></blockquote><blockquote><p>==对应于我就是先讲总体的流程，然后再讲 1. lstm的设计  2. attention的设计（不仅能提高观察，还能提高性能 !  理由，在平缓的时候关注点能平坦,,, 在剧烈变化的时候关注点能聚焦… –&gt; 需要做个对比试验，此外，关于理由还是要再想清楚点.. ）==</p></blockquote><ul><li><p>function approximator的重要性</p><ul><li><p>现有的一些方法，以及他们存在的一些问题</p></li><li><p>我们使用的Kanerva编码的原理和formulation，以及如何融入我们这个框架里面的 【创新和修改部分】</p><blockquote><p>请注意，这里阐述细节并不是为了讲算法原理，而是要讲清楚如何讲算法应用到我们这里面来的</p></blockquote></li><li><p>给出伪代码</p></li><li><p>描述伪代码的流程 ( lines xx-xx ) ，这里还分析了下代码的时空复杂度</p></li></ul></li></ul><h1 id="6-Performance-Evaluation"><a href="#6-Performance-Evaluation" class="headerlink" title="6 Performance Evaluation "></a>6 Performance Evaluation <h2 id="Performance"></h2></h1><ul><li>实验设置<ul><li>评估了三个方法，baseline是New Reno</li><li>单源拓扑上测试了性能，哑铃状拓扑测试了公平性，每个算跑8次</li><li>链路设置：RTT为100ms；每800s在7.5Mbps和2.5Mbps之间切换；缓冲区大小为BDP，which is 50个数据包</li><li>每个算法跑了8次</li></ul></li></ul><blockquote><p>我们使用基于ns-3的数据包级仿真，通过与TCP New Reno进行比较，来评估在不同带宽条件下TCPLearning，CMAC和Fuzzy TCPLearning的性能。 我们从图1（a）所示的单瓶颈网络开始，然后将评估范围扩展到图1（b）所示的更复杂的多流网络，以进行与公平相关的研究。 我们使用这些拓扑来演示受控环境中学习的特征，并显示对吞吐量和延迟的影响。 瓶颈带宽（在路由器-接收器链路上）每800s交替在7.5Mbps和2.5Mbps之间切换。 网络RTT设置为100ms，缓冲区大小设置为BDP，在我们的仿真中为50个数据包。 我们使用每种算法进行8个实验，并报告平均吞吐量和延迟。 值的标准偏差使用误差线显示。<br>   一种。</p></blockquote><blockquote><p>We use ns-3 based packet level simulations to evaluate the performance of TCPLearning, CMAC and Fuzzy TCPLearning in varying bandwidth conditions by comparing with TCP New Reno. We begin with a single-bottleneck network shown in Fig. 1(a) and later extend the evaluation to a more complex multi-flow network shown in Fig. 1(b) for fairness-related studies. We use these topologies to demonstrate the characteristic features of learning in controlled environments and show the impact on throughput and delay. The bottleneck bandwidth (on the router-receiver link) switches alternately between 7.5Mbps and 2.5Mbps every 800s. The network RTT is set to 100ms and the buffer size is set to BDP, which is 50 packets in our simulation. We conduct 8 experiments using each algorithm and report the average throughput and delay. The standard deviation of values is shown using error bars.</p></blockquote><h2 id="A-TCP-Learning-without-Function-Approximation"><a href="#A-TCP-Learning-without-Function-Approximation" class="headerlink" title="A. TCP-Learning without Function Approximation"></a>A. TCP-Learning without Function Approximation</h2><p>在这种情况下，我们禁用函数逼近并设置探索率？ 对于TCPLearning到0.1。 初始学习率α设置为0.3，并且每隔10s降低0.995倍。 总仿真时间设置为<u>6400s</u>。</p><hr><ul><li><p>平均吞吐量和延迟： 【是一个总体的视图】</p><ul><li><p><strong>陈述了</strong>不同带宽情况下，算法和baseline之间的吞吐量情况差距</p><blockquote><p>​    <strong>图2（a）</strong>比较了TCP New Reno和TCPLearning在瓶颈带宽每800s介于7.5Mbps和2.5Mbps之间切换时获得的<strong>平均吞吐量</strong>。 结果表明，随着瓶颈带宽的波动，TCPLearning的性能明显优于TCP New Reno。 我们观察到，在7.5Mbps的瓶颈带宽下，TCPLearning的平均吞吐量为6.72Mbps，而TCP New Reno的平均吞吐量为4.46Mbps。 在瓶颈带宽为2.5Mbps的情况下，TCPLearning的平均吞吐量为2.27Mbps，而TCP New Reno的平均吞吐量为2.26Mbps。 我们注意到，由于默认缓冲区大小在100ms的网络RTT和2.5Mbps的瓶颈带宽下是最佳的，因此TCP New Reno充分利用了该缓冲区，并且TCPLearning获得了同样好的性能。</p><p>​    <strong>图2（b）</strong>比较了在相同网络设置下TCP New Reno和TCPLearning实现的<strong>平均RTT</strong>。 结果表明，在瓶颈带宽为7.5Mbps时，TCPLearning的平均RTT为111ms，而TCP New Reno的平均RTT为109ms。 在瓶颈带宽为2.5Mbps时，TCPLearning的平均RTT为114ms，而TCP New Reno的平均RTT为154ms。 在任何瓶颈带宽下，TCPLearning在平均吞吐量方面都优于TCP New Reno。 图2（a）表明，在这种高带宽波动的网络中，TCPLearning将平均吞吐量提高了33.8％。 当考虑图2（b）所示的延迟时，尽管TCPLearning的性能稍差一些，但在这种情况下，在2.5Mbps的瓶颈带宽下性能下降了1.8％，在7.5Mbps的瓶颈带宽下，其性能优于TCP New Reno 26％。 平均而言，TCPLearning可将延迟减少12.1％。</p></blockquote></li><li><p>开始<strong>分析解释</strong>为啥人家会差【我觉得这一段批评classic的，我可以学习下】，我们会好</p><p>请注意，<strong>要用图片来佐证你的分析</strong></p><blockquote><p>​    我们观察到，TCP New Reno的平均吞吐量为4.46Mbps，远小于瓶颈带宽7.5Mbps。 这是因为TCP New Reno的预定义的拥塞避免算法使cwnd超出了连接所能支持的范围，最终使网络拥塞，最终导致cwnd和吞吐量显着下降。 <u>更糟糕的是，由于TCP New Reno算法无法存储过去的操作以及这些操作对性能的影响，因此它会重复相同的行为。 图3显示了在模拟TCP New Reno期间cwnd的大小与时间的关系。 该图表明，该算法反复做出相同的错误决策，从而降低了性能。</u><br>   另外，TCP new Reno在cwnd每次<u>显着下降之后需要花费大量时间来恢复</u>，因为它必须在避免拥塞阶段线性增加cwnd。 但是，TCPLearning通过学习经验来克服了这一缺陷。 图3还显示了在TCPLearning仿真期间，cwnd的大小与时间的关系。 该图显示，随着学习过程的进行，TCPLearning进行了各种实验，这些实验会修改cwnd直到110s。  110s之后，学习到的动作值函数Q（s，a）收敛到最佳动作值函数Q ∗（s，a）。这时，TCPLearning找到一个最佳动作，该动作充分利用了缓冲区并且不会触发任何动作 数据包丢失。 这种习得的动作使cwnd足够大，可以达到良好的性能，但是比发生包丢失的上限稍小。 通过这种最佳操作获得的高吞吐量将保持稳定，直到800s之后，瓶颈带宽才会切换。</p></blockquote></li></ul></li></ul><hr><blockquote><p>讲完整体视图/情况  以及 为什么会这样 之后，开始讲实时的指标 ( 细化 )</p></blockquote><ul><li><p>实时吞吐量 【还是踩了别人一脚，分析也比较少了</p><blockquote><p>​    图4显示了TCP New Reno和TCPLearning的实时吞吐量，其中每800s的高带宽在7.5Mbps和2.5Mbps之间切换。 该图显示，当瓶颈带宽为7.5Mbps（在最初的800秒钟内）时，TCP New Reno会经历重复的数据包丢失，从而导致平均吞吐量较低且不稳定。 当瓶颈带宽切换到一个较小的值（800s后为2.5Mbps）时，TCP New Reno会充分利用缓冲区并获得高而稳定的吞吐量。 我们观察到，在使用TCP New Reno时，那些具有高瓶颈带宽的方案会有效并严重降低吞吐量。 但是，波动的瓶颈带宽对TCPLearning实现的吞吐量影响很小。 如图4所示，TCPLearning用110s来学习7.5Mbps瓶颈带宽时的最佳策略，并保持高而稳定的吞吐量，直到800s。 当瓶颈带宽在800s之后切换到2.5Mbps时，TCPLearning会非常迅速地收敛，并且仍然可以实现稳定的吞吐量，直到瓶颈带宽再次切换为止。</p></blockquote></li><li><p>实时RTT 【</p><blockquote><p>图5显示了在上述相同带宽切换情况下TCP New Reno和TCPLeaning的实时RTT。 我们发现，在瓶颈带宽波动的情况下，TCPLearning比TCP New Reno实现了更稳定和更低的RTT。</p></blockquote></li></ul><h2 id="B-TCPLearning-with-Function-Approximation-We"><a href="#B-TCPLearning-with-Function-Approximation-We" class="headerlink" title="B. TCPLearning with Function Approximation We"></a>B. TCPLearning with Function Approximation We</h2><blockquote><p>我们通过将CMAC算法和Fuzzy TCPLearning算法应用于图1（a）所示的相同网络拓扑来评估其性能。  CMAC算法将状态动作空间划分为一组不同的图块，并创建多个图块以在学习中提供粗粒度和细粒度的概括。 在我们的实验中，我们使用5个切片，每个切片有3,125个切片，因为我们有5个可能的操作和4个状态变量，每个变量均等地划分为5个间隔。 要学习动作值，我们需要存储15625个θ值，这些值等于每个平铺3125个图块乘以5个平铺。 由于每个平铺都有大的平铺，因此需要较少的内存来存储所有θ值。  Fuzzy TCPLearning算法将函数逼近与连续的隶属度等级结合使用，以控制并显着减少存储学习值（对于TCPLearning而言是Q表）所需的内存量，同时保持性能。<br>   为了进行实验，我们首先随机生成一组100个原型，然后初始化相应的θ值。 然后，使用等式2通过Q学习过程更新每个原型的θi值。</p></blockquote><ul><li><p><strong>平均吞吐量和延迟</strong></p><blockquote><p>图2还比较了CMAC和Fuzzy TCPLearning在两个交替的瓶颈带宽下获得的平均吞吐量和延迟。我们观察到，在两个不同的瓶颈带宽上，CMAC和Fuzzy TCPLearning在吞吐量和延迟方面都优于TCP New Reno。我们注意到，当瓶颈带宽为7.5Mbps时，与TCPLearning相比，CMAC和Fuzzy TCPLearning的吞吐量都有轻微下降。 当瓶颈带宽为2.5Mbps时，可以观察到几乎相同的吞吐量。 此外，就两个瓶颈带宽的延迟而言，CMAC和Fuzzy TCPLearning的性能均比New Reno更好，而性能比TCPLearning差。 我们得出结论，就吞吐量和延迟而言，平均而言，TCPLearning表现最佳。 但是，利用功能逼近技术，CMAC和模糊TCPLearning可以显着减少内存使用，同时实现可比的性能。</p></blockquote></li><li><p><strong>减少内存使用的影响</strong></p><blockquote><p>TCPLearning算法分配内存以存储可能遇到的50,000个状态操作对中的每对。 由于4个字节用于存储与一个状态操作对相对应的Q值，因此TCPLearning使用200KB的内存存储。 相反，CMAC算法仅需要存储θ值，该值可能远小于状态动作对的数量。 我们的实验中使用的θ值总数为15,625，最终的内存使用量为62.5KB，不到TCPLearning使用的内存的1/3。 模糊TCPLearning算法为100个状态-动作对分配存储。 由于需要20个字节来存储一个状态-动作对，另外400个字节用于存储100个原型的θ值，因此它仅使用2.4KB内存，因此非常适合物联网应用。</p></blockquote></li></ul><h2 id="C-Fairness-Observations"><a href="#C-Fairness-Observations" class="headerlink" title="C. Fairness Observations"></a>C. Fairness Observations</h2><p>​    我们通过评估图1（b）所示的哑铃网络拓扑中的性能来评估TCPLearning算法的公平性。 该拓扑包括<u>2个发送器和2个接收器，它们在100ms RTT时共享2.5Mbps的瓶颈带宽。 瓶颈路由器缓冲区大小设置为100个数据包</u>。 两个流中的数据传输同时开始。 表III显示了TCP New Reno和TCPLearning的两个竞争流的平均吞吐量。 我们观察到，使用TCP New Reno和TCPLearning两种流的平均吞吐量几乎相同，因此在the那教的公平性指数中得分均相等。</p>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>QTCP, Adaptive Congestion Control with Reinforcement Learning</title>
      <link href="/ExtensiveReading/CC/Q-TCP/"/>
      <url>/ExtensiveReading/CC/Q-TCP/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​    下一代网络访问技术和Internet应用程序增加了向具有传统拥塞控制协议的用户提供令人满意的体验质量的挑战。 在广泛的网络场景下，通过根据特定的网络体系结构或应用程序修改核心拥塞控制方法来优化TCP性能的努力并未得到很好的推广。 这种限制源于基于规则的设计原理，其中，性能与网络的观察状态到相应操作之间的预定映射有关。 因此，这些协议无法适应其在新环境中的行为，也无法从经验中学习以获得更好的性能。 我们通过在我们称为QTCP的方法中将基于增强的Q学习框架与TCP设计集成在一起来解决此问题。  QTCP使发送者能够以在线方式逐渐了解最佳拥塞控制策略。  QTCP不需要硬编码的规则，因此可以推广到各种不同的联网方案。 此外，我们开发了一种广义的Kanerva编码函数逼近算法，该算法降低了值函数的计算复杂度和状态空间的可搜索大小。 我们展示了QTCP在保持低传输延迟的同时，提供了59.5％的更高吞吐量，从而胜过了传统的基于规则的TCP。</p><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li>这篇由于篇幅够长，所以逻辑上的展开比DCOSS’16的那一篇要好不少，尤其是还有不少[好词好句好图](#good sentense &amp; good pics)值得学习(introduction的论述也可以摘抄)</li></ul><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1. introduction"></a>1. introduction</h1><ul><li><p>这段抨击rule-based CC特别值得学习</p><ul><li><p>指出classical CC的特征rule-based 并解释 rule-based的具体体现是什么</p><p>This limitation stems from the fact that these protocols are built on the common concept of relying on <u>pre-configured</u> rules to guide the behavior of end hosts (e.g., how to change the congestion window size) given specific observations of the surrounding environment (e.g., mea- sured throughput, RTT). For example, the NewReno protocol uses the well-known additive increase, multiplicative decrease (AIMD) strategy, and Cubic adopts a well-crafted function to adjust the congestion window size (cwnd) given feedback from the receiver.</p></li><li><p>说明rule-based带来了两方面的影响【我觉得缺少引用】</p><p>This rule-based design can cause two problems: First, it causes congestion control protocols to be unable to adapt to new scenarios when a network environment changes. Since different kinds of networks differ in significant ways with respect to bandwidth, delay and network topology, a given TCP flavor that works well for a specific network might not work in another. Second, the rules of operation are usually built upon standard assumptions or the network model. When either changes, the fixed mapping between observation and actions means that TCP does not intelligently adjust its behavior by learning from experience. As a result, the protocol repetitively adopts the same cwnd changing rules that bring sub-optimal performance, without the flexibility to adjust behaviors for better performance (Sec. 2).</p></li></ul></li><li><p>proposed approach:</p><ul><li><p>先描述这是个什么</p><ul><li><p>功能、使用的工具简介 ( 主要要针对你要抨击的点 )</p><blockquote><p>在这项工作中，我们使用强化学习（RL）设计一种称为QTCP（基于Q学习的TCP）的拥塞控制协议，该协议可以自动识别最佳的拥塞窗口（cwnd）变化策略，并对此进行了观察。 在线方式连接周围的网络环境。 它不需要手工制定的规则集或耗时的离线培训过程。  RL使代理能够根据实时反馈调整其行为，并通过阻止无效行为来避免重复相同的错误。 </p></blockquote></li><li><p>主打的特点 ( 还是要针对你要抨击的点 )</p><blockquote><p>我们在QTCP中利用此功能，使发件人可以动态地学习不同的策略以更好地适应各种网络情况，而不必机械地遵循固定的规则。 具体来说，QTCP基于从网络环境收集的性能指标的测量值，连续更新协议的可能状态-动作对的值，并使用Q学习算法搜索最佳动作，即如何调整Cwnd。 在特定状态下，以使发送者的长期回报最大化。</p></blockquote></li></ul></li></ul></li><li><p>Challenges and Innovations: </p><blockquote><p>尽管已证明RL在许多困难的问题（例如Go，自动驾驶）上表现良好，但由于问题的连续高维状态空间，将其应用于TCP拥塞控制尤其具有挑战性。 状态空间的大小可以随状态空间的大小呈指数增长，从而导致存储状态操作值所需的表的大小显着增加。 在如此大的表中更新条目通常非常耗时，这会导致培训时间过长。 为了加快学习过程2327-4697并使QTCP易于处理，我们应用了函数逼近[6]，这是一种有效的方法，可以减少使用抽象状态表示进行搜索和探索所需的状态空间大小。 尽管有许多函数逼近算法可用，但我们选择Kanerva编码[7]，也被称为稀疏分布式内存（SDM），因为它的复杂度低，收敛速度快，并且在解决大，高维和连续状态的问题上的有效性 空格。  Kanerva编码的思想考虑了这样一种设置：整个状态空间由精心选择的状态空间子集表示，基于该子集存储训练值并评估派生的策略，从而显着降低了内存消耗和价值训练的计算复杂性 。 但是，我们发现，由于状态空间子集的选择不当，原始Kanerva编码的性能在实践中并不令人满意。 为了解决这个问题，我们提出了一种新的方法，即基于泛化的Kanerva编码，该方法可以调整状态空间子集的每个条目的抽象级别，从而在探索该子集时动态重新分配该子集以找到其接近最佳的结构。 状态空间。 我们的方法允许根据访问状态来更改状态抽象的粒度，其中将检查具有不正确泛化级别的子集的不太重要的条目，并将其替换为提供更好泛化的条目。 这克服了传统的Kanerva编码算法及其变体的局限性，使QTCP具有更快的收敛速度和更好的整体学习性能。</p></blockquote></li><li><p>Contribution</p><p>• 我们描述了QTCP，这是一种基于Q学习的拥塞控制协议，它可以自动学习有效的策略来调整cwnd以在线方式实现高吞吐量和低延迟。 这从根本上改变了以前类似NewReno的TCP变体的设计，这些变体需要固定的手动选择的规则。<br>  • 我们提出了一种新型的Kanerva编码算法，该算法在应用于大型复杂状态空间时可以很好地缩放，并且可以大大加快收敛速度并提供稳定的性能。 我们的算法允许学习值不再以表格形式存储，因此消除了在应用于大规模问题域时RL技术的重要限制，例如无法处理巨大状态。</p></li></ul><h1 id="2-Background-and-motivation"><a href="#2-Background-and-motivation" class="headerlink" title="2. Background and motivation"></a>2. Background and motivation</h1><h1 id="3-QTCP-APPLY-Q-LEARNING-TO-TCP-CONGES-TION-CONTROL"><a href="#3-QTCP-APPLY-Q-LEARNING-TO-TCP-CONGES-TION-CONTROL" class="headerlink" title="3. QTCP: APPLY Q-LEARNING TO TCP CONGES- TION CONTROL"></a>3. QTCP: APPLY Q-LEARNING TO TCP CONGES- TION CONTROL</h1><ul><li><p>good sentenses</p></li><li><p>逻辑</p></li><li><p>开场白如上</p></li><li><p>overveiw of Q-TCP</p><ul><li><p>交互框架</p></li><li><p>强化学习问题的五元素 简介（具体的再后面有更加翔实的接好</p><blockquote><p>这里给出了一个很好的提醒，应该是“马尔可夫<strong>过程</strong>”和“强化学习<strong>问题</strong>”，以前一直说的是“马尔可夫<strong>问题</strong>”，which不正确哇，MDP是用于RL问题建模中的一部分而已。</p></blockquote></li><li><p>实现中的challenge以及我们的解决方案（华彩</p></li></ul></li></ul><p>……</p><h1 id="good-sentense-amp-good-pics"><a href="#good-sentense-amp-good-pics" class="headerlink" title="good sentense &amp; good pics"></a>good sentense &amp; good pics</h1><ul><li><p>preliminary statements of Section 3</p><p>​    在本节中，我们探索使用RL来自动设计拥塞控制策略。RL具有克服上述基于规则的TCP问题的潜力，因为它可以使代理从过去的经验中学习，而无需手动制定规则或网络场景的先验知识。<br>​    Specifically，**<u>我们讨论如何将经典的RL算法Q学习应用于拥塞控制问题和提出QTCP领域</u>**：一种新的拥塞控制协议，该协议使发送者可以通过与 网络方案。</p></li></ul><hr><ul><li>good pics</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/111948-47405.png" alt="image-20201026111944751"></p>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spinningUpCodesReading</title>
      <link href="/Codes/spinningUpCodesReading/"/>
      <url>/Codes/spinningUpCodesReading/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rlDemo</title>
      <link href="/Codes/rlDemo/"/>
      <url>/Codes/rlDemo/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RhdGF3aGFsZWNoaW5hL2xlZWRlZXBybC1ub3Rlcy9ibG9iL21hc3Rlci9jb2Rlcy9RLWxlYXJuaW5nL21haW4ucHk=">base代码<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 老是说我没有权限就很烦...</span></span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py <span class="comment"># use default config  0.9,0.9,0.1,200,0.1,500</span></span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py --gamma 0.95 --me 100</span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py --gamma 0.95 --es 0.99 --me 100</span><br></pre></td></tr></table></figure><ul><li><p>ε-decay和ε-start还有ε-end是耦合的，第一个感觉比较难调整，就调后面两个好了</p>  <img   src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031909-640019.png" alt="image-20201022023149453" style="zoom: 50%;" /><ul><li><p>先用默认参数跑了下，发现其实100步已经妥妥收敛了（右边），所以<strong>me果断设置100</strong> ，确实还不错（见下）</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030751-545506.png" alt="image-202010220307622" style="zoom: 67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031416-949404.png" alt="image-20201022041939" style="zoom:67%;" /></p></li><li><p>最短路径是15步，所以<strong>gamma</strong>我取了个1-1/15，<strong>约等于0.95</strong></p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/025053-715031.png" alt="image-20201022025051942" style="zoom: 67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031206-822872.png" alt="image-20201022024836105" style="zoom:50%;" /></p><p>目前看效果还不错（如上），肯定是train好了，接着调</p></li><li><p><strong>ee 调到0.99</strong>，希望一开始探索多一点</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031126-830561.png" alt="image-20201022025738159" style="zoom:67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031206-89443.png" alt="image-20201022025802328" style="zoom:67%;" /></p><blockquote><p>可以看到一开始探索多了以后，学习得居然也快了,说明探索到了好的方法</p></blockquote></li><li><p>再分别试试<strong>调大学习率</strong>（0.15）和<strong>调小学习率（0.05</strong>）</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030056-455700.png" alt="image-20201022030055460" style="zoom:67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030335-443486.png" alt="image-20201022030055460" style="zoom:67%;" /></p><blockquote><p>学习率大了以后果然学的就是快hhh </p></blockquote></li></ul></li></ul><h1 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h1><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>游戏：CartPole-v0，action是两维度(左和右，分别用0和1表示)， state是四维的（$x,\overset{·}x,\theta,\overset{·}\theta$）（位置，速度，杆子与竖直方向的夹角，角度变化率）；左移或者右移小车的<em>action</em>之后，<em>env</em>会返回一个+1的<em>reward</em>。其中<em>CartPole-v0</em>中到达200个<em>reward</em>之后，游戏也会结束，而<em>CartPole-v1</em>中则为<em>500</em>。最大奖励（<em>reward</em>）阈值可通过前面介绍的注册表进行修改。</p><h2 id="错误记录-amp-修正"><a href="#错误记录-amp-修正" class="headerlink" title="错误记录 &amp; 修正"></a>错误记录 &amp; 修正</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;main.py&quot;</span>, line 158, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="built_in">eval</span>(cfg)</span><br><span class="line">  File <span class="string">&quot;main.py&quot;</span>, line 130, <span class="keyword">in</span> <span class="built_in">eval</span></span><br><span class="line">    action = agent.choose_action(state,train=False)  <span class="comment"># 根据当前环境state选择action</span></span><br><span class="line">  File <span class="string">&quot;/home/hesy/rlreview/leedeeprl-notes/codes/dqn/agent.py&quot;</span>, line 76, <span class="keyword">in</span> choose_action</span><br><span class="line">    q_value = self.target_net(state)</span><br><span class="line">  File <span class="string">&quot;/home/hesy/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;</span>, line 541, <span class="keyword">in</span> __call__</span><br><span class="line">    result = self.forward(*input, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/hesy/rlreview/leedeeprl-notes/codes/dqn/model.py&quot;</span>, line 29, <span class="keyword">in</span> forward</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">  File <span class="string">&quot;/home/hesy/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py&quot;</span>, line 541, <span class="keyword">in</span> __call__</span><br><span class="line">    result = self.forward(*input, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/hesy/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py&quot;</span>, line 87, <span class="keyword">in</span> forward</span><br><span class="line">    <span class="built_in">return</span> F.linear(input, self.weight, self.bias)</span><br><span class="line">  File <span class="string">&quot;/home/hesy/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py&quot;</span>, line 1370, <span class="keyword">in</span> linear</span><br><span class="line">    ret = torch.addmm(bias, input, weight.t())</span><br><span class="line">RuntimeError: Expected object of device <span class="built_in">type</span> cuda but got device <span class="built_in">type</span> cpu <span class="keyword">for</span> argument <span class="comment">#2 &#x27;mat1&#x27; in call to _th_addmm</span></span><br></pre></td></tr></table></figure><blockquote><p>choose_action在eval的时候默认选择了CPU，但是模型可能load在GPU上..</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/18/130645-532470.png" alt="image-20201118130642905"></p></blockquote><ul><li>==？==我想问下这里使用CPU进行evaluation是必须的么？是考虑到不想把变量转移到GPU上增加开销才写死到CPU上进行evaluation的吗？写死的话…就会出现问题….</li></ul>]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MORL</title>
      <link href="/PaperReading/MORL/"/>
      <url>/PaperReading/MORL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation<br>NIPS’19  普林斯顿</p><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>我们引入了一种具有==线性偏好==的多目标强化学习（MORL）的新算法(with linear preferences)，其目标是能够对新任务进行少量调整。 在MORL中，目的是学习有关多个竞争目标的策略，这些目标的相对重要性（偏好）对于代理人是未知的。 虽然这减轻了对标量奖励设计的依赖，但是策略的预期收益会随着偏好的变化而发生显着变化，这使得学习单一模型以在不同的偏好条件下产生最优策略具有挑战性。 我们提出Bellman方程的广义形式，以学习在所有可能的偏好范围内获得最优政策的单个参数表示。 <strong>在初始学习阶段之后，我们的代理可以在任何给定的首选项下执行最佳策略</strong>，或者自动通过很少的样本来推断潜在的首选项。 在四个不同领域的实验证明了我们方法的有效性。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><blockquote><p>我们解决了MORL中的两个具体挑战：</p><ol><li>提供具有线性偏好的MORL多目标版本Q学习的理论收敛性结果，以及</li><li>证明有效利用深度神经网络将MORL扩展到更大的领域。 </li></ol><p>我们的算法基于两个关键的见解</p><ol><li>带有偏好的Bellman方程[10]的广义版本的最优算子是有效收缩，以及</li><li>多目标Q值的凸包络的优化确保了 偏好与相应的最优政策之间的有效协调。 我们使用HER对有采样优先级的经验回放[11]和homotopy optimization[12]的学习过渡，以确保易于学习。 此外，我们还演示了如何通过策略梯度和对偏好参数的随机搜索的组合，使用训练有素的模型自动推断新任务的隐性偏好（仅提供标量奖励）。</li></ol><p>此外，我们还演示了如何使用我们训练有素的模型，通过结合政策梯度，在仅提供标量奖励的情况下自动推断新任务的隐藏偏好。</p></blockquote><h1 id="2-Background"><a href="#2-Background" class="headerlink" title="2 Background"></a>2 Background</h1><h2 id="MOMDP"><a href="#MOMDP" class="headerlink" title="MOMDP"></a>MOMDP</h2><ul><li>Parrto Frontier</li><li>CCS</li></ul><h2 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h2><ul><li>MORL <ul><li>single-policy 在给定preference的情况下学习一个策略 &amp; multiple-policy 在不同preference情况下学习多组相应最优的策略</li><li>scalarized Q-learning  使用ourler loop去搜索最佳策略(OLS)<ul><li>[里面引用了2016年开源的那篇文章]</li></ul></li></ul></li></ul><h1 id="3-算法"><a href="#3-算法" class="headerlink" title="3 算法"></a>3 算法</h1><ul><li>T $\mathcal{T}$ 单目标和多目标中Q函数的贝尔曼优化算子</li><li>H $\mathcal{H}$  单目标和多目标中Q函数的optimal filter</li><li>d( Q,Q’ )</li><li>$L^A(\theta)$ 与$L^B(\theta)$ </li><li>learning algorithm 以及 policy adaption两个part</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/25/140616-919388.png" alt="image-20201025140615145"></p><h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a>4 Experiments</h1><ul><li></li><li><p>实验设置</p><ul><li>指标 CR （Coverage Ratio）、AE（Adaptation Error）、UT（Average Utility）</li><li>四个场景<ul><li>DST FTN Dialog  SuperMario</li></ul></li><li>三个baseline<ul><li>==check下哪个可以输出连续动作哇…==</li></ul></li></ul></li><li><p>结果</p><ul><li>几个指标上的胜利，但是提升的点并不是很多哇</li><li>scalability</li><li>sample efficiency</li><li>policy adaptation</li><li>revealing underlyging preferences<ul><li>这部分的结果分析的意思应该是，policy adaptaion不是一个必要环节，one of its 作用就是去uncover underlying preferences.</li></ul></li></ul></li></ul><h1 id="questions"><a href="#questions" class="headerlink" title="questions"></a>questions</h1><ul><li><p>optimality filter 指的是argmax 或者 sup ?</p></li><li><p>o.w.什么意思…</p></li><li><p>truncated multivariable Gaussian distribution 是什么意思</p></li></ul><p>prediction based</p><hr><h1 id="abstract-1"><a href="#abstract-1" class="headerlink" title="abstract"></a>abstract</h1><p>许多现实世界中的控制问题都涉及目标冲突，我们需要一套密集而高质量的控制策略，这些策略对于不同的目标偏好是最优的（称为帕累托最优）。 尽管为解决此类问题已进行了多目标强化学习（MORL）的广泛研究，但对于复杂连续机器人控制的多目标优化仍处于探索中。 在这项工作中，我们提出了一种有效的进化学习算法，通过扩展最先进的RL算法并提出一种新颖的预测模型来指导学习过程，从而找到连续机器人控制问题的帕累托集近似值 。 除了有效地发现Pareto前沿的单个策略外，我们还通过Pareto分析和内插法构造了一组连续的Pareto最优解。 此外，我们设计了七个具有连续动作空间的多目标RL环境，这是第一个评估MORL算法解决各种机器人控制问题的基准平台。 我们对提出的基准问题测试了先前的方法，并且实验表明，与现有算法相比，我们的方法能够找到更密集，质量更高的帕累托策略集。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><blockquote><p>​    多目标问题已经引起了广泛的关注，因为大多数现实情况都涉及对不同性能指标的权衡。 在机器人控制中尤其如此，其中性能概念通常涉及不同的冲突目标。例如，当为运行中的四足机器人设计控制策略时，我们需要考虑两个相互矛盾的目标：运行速度和能效。与单目标环境相比，单目标环境使用单个标量值来衡量性能，并且在存在单个最佳解决方案的情况下，对于多目标问题，性能是使用多个目标进行衡量的，并且存在多个最佳解决方案。 一种最优策略可能会以降低能源效率为代价来偏爱高速度，而另一种最优策略可能会以降低速度为代价偏向于高能量效率。 通常，根据这两个度量之间的选择权衡，存在许多最佳策略。 最后，由人负责在不同指标之间选择偏好，这决定了相应的最佳策略。</p><p>​    解决多目标控制问题的一种流行方法是计算meta policy（Chen等，2018）。 元策略是一种通用策略，它不一定是最佳策略，但可以相对快速地适应性能目标之间的不同折衷。 不幸的是，这种adaptive的控制策略不一定是最优的。例如，为四足机器人适应通用元控制策略以使其尽可能快地运行，通常会导致该指标的策略欠佳。 例如，为四足机器人适应通用元控制策略以使其尽可能快地运行，通常会导致该指标的策略欠佳。</p><p>​    在这项工作中，我们表明，获得多目标机器人控制的最佳性能折衷的有效代表是一组帕累托控制策略。 我们的经验表明，不能使用单个连续的策略族来有效地表示帕累托集。 相反，帕累托集由一组不相交的策略族组成，每个策略族在参数空间中占据一个连续的流形，并负责性能空间中帕累托前沿的一个部分（图1）。</p><p>为了找到这种帕累托表示，我们提出了一种有效的算法来计算帕累托策略集。 我们的算法分两个步骤进行。 第一步，我们使用基于a novel prediction-guided evolutionary learning algorithm，在帕累托前沿找到密集且高质量的策略集。 在每一generation中，每种策略都适合使用分析模型，以预测沿每个优化方向的预期改进。 然后解决优化问题，以选择可以最好地改善Pareto质量的策略和相关的优化方向。 在第二步中，我们对计算出的Pareto最优策略进行Pareto分析，以识别不同的策略系列，并为每个策略系列计算连续的表示形式。</p><p>​    ==上面这一段的翻译不是很好==</p><p>​    为了对我们提出的算法进行基准测试，我们设计了一组具有连续动作空间的多目标机器人控制问题。 可以使用基于物理的模拟系统来评估每个策略的性能（Todorov等，2012）。 我们的实验表明，与现有方法相比，该算法可以有效地找到一组质量更高的帕累托最优策略。 此外，基于这些策略，它可以重建跨越整个帕累托前沿的连续策略系列。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> PaperReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rlReview</title>
      <link href="/Summary/rlReview/"/>
      <url>/Summary/rlReview/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="回顾时-一下子没想出来的问题"><a href="#回顾时-一下子没想出来的问题" class="headerlink" title="回顾时 一下子没想出来的问题"></a>回顾时 一下子没想出来的问题</h1><ul><li><p>强化学习相对于监督学习为什么训练会更加困难？（强化学习的特征）</p><ul><li><p>强化学习处理的多是序列数据，其很难像监督学习的样本一样满足IID（独立同分布）条件。( needs trivial handling )</p></li><li><p>强化学习有奖励的延迟（Delay Reward），即在Agent的action作用在Environment中时，Environment对于Agent的State的奖励的延迟（Delayed Reward），使得反馈不及时。</p></li><li><p>相比于监督学习有正确的label，可以通过其修正自己的预测，强化学习相当于一个“试错”的过程，其完全根据Environment的“反馈”更新对自己最有利的Action。</p></li></ul></li><li><p>为什么在马尔可夫奖励过程（MRP）中需要有<strong>discount factor</strong>?</p><ul><li><p>有些马尔可夫过程是<strong>带环</strong>的，它并没有终结，然后我们想<strong>避免这个无穷的奖励</strong>；</p></li><li><p>当前步对遥远未来的reward的<strong>贡献</strong>比较小，所以用discount factor弱化未来的奖励在当前步骤的累加值；</p></li><li><p>考虑奖励的<strong>不确定性</strong>：假设在从当前步采取同样的action开始，采样不同的trace，可能有的会会有最终奖励、有的不会（这里以打游戏为例，通关得到的最终奖励远大于平时每个步骤得到的微小奖励 ( 有的设置里面平时的奖励实际上都没有，就只设置最终步骤的奖励 ) ）。综上，未来的奖励是受后续trace影响的，也就是不确定的，有一定概率的，所以从这个角度来看，我们也要给这个未来奖励打一个折扣。</p><blockquote><p>从另一个角度思考，考虑不打折扣的情况–》γ都是1的情况下，就很糟糕。</p></blockquote></li></ul></li><li><p>为什么说Sarsa ( on-policy ) 更加保守，而Q-learning ( off-policy ) 更加大胆且鼓励探索呢？</p><p><img src="https://images.weserv.nl/?url=https://datawhalechina.github.io/leedeeprl-notes/chapter3/img/3.18.png" alt="img"></p><ul><li><strong>鼓励探索</strong></li></ul><p>可以看到，虽然都是使用ε-greedy算法选择动作，但是对于同一个动作( especially探索出来的动作 )，Q-learning给分会比较高（毕竟是给了一个argmax的action对应的值哇）。那么一旦给分高了以后，偏向选择这个动作的概率就会大，就会探索出更多以这个action开头的trace，其中说不定能找到一个比之前更好的trace。而如果是Sarsa的话，这一次探索之后该动作对应的Q值一跃成为最大值可能性就小很多了。与之相比，Q-learning其实就是鼓励探索的。</p><ul><li><strong>更加大胆</strong></li></ul><p>一个很经典的例子就是cliffWalking里面，Q-learning的最终解可以贴着悬崖边上走，但是SARSA是不可以的，这是因为SARSA会考虑到这个贴着悬崖的状态有ε/4的概率会选择向下的动作，然后掉下去( 非最优动作的探索率是 ε/|A|,这里一共有四个动作:上\下\左\右 )，所以这ε/4的低分(死亡)会把这个状态的分数拉下去(而远离悬崖的状态都安全多了，不会有掉下去的概率)；但是Q-learning是只看这个状态会导致的最好结果，which means只看到最后成功的结果，忽视会掉下去的情况，倾向于”铤而走险“。所以个人认为，单纯从找到一个解决方案来看，还是Q-learning比较占优势。</p><blockquote><p> <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGV2aWxtYXljcnk4MTI4Mzk2NjgvcC8xMDMxMjY4NS5odG1s">但是实际中SARSA会比Q-learning表现得更好<i class="fa fa-external-link-alt"></i></span> 其实我觉得这个还得看我们用强化学习来解决什么问题了。我们是要用它来找到一个最优解，还是要让他从头到尾”完备、安全“地做完某事。博客中显然是选择了前一种的概念。</p></blockquote><blockquote><p><code>&quot;那么一旦给分高了以后，偏向选择这个动作的概率就会大&quot;</code></p><p> 这里要区分一个概念：对于ε-greedy来说，除了使得值函数的值最大的那个action以外，其他所有的action的选取概率实际上都是一样的。如果想要按照值函数大小为概率来选择动作的话，可以考虑玻尔兹曼策略或者UCB策略。</p><p>所以，这句话的隐含意思是，<strong>很大可能</strong>这次更新后( 因为加上的是最大值啊喂 )，这个动作对应的Q-value就一跃成为最大值（之一）了，此时其被选取、探索的概率就会变大。</p></blockquote><blockquote><p><strong>个人认为</strong>，Q-learning这方法会跟UCB做赌博机的那个实验效果一样，倾向于<strong>把所有的动作空间都try一遍</strong>（因为一旦概率落到新动作上，如果学习率比较大，那么这个新动作的Q值一下子就会变得很大，一跃成为Q值最大的，所以下次会优先(大概率)选择它，然后就相当于展开了以它为根结点的探索空间）……</p><p>支撑论据：</p><blockquote><p>refer@<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzI2ODQ2MTg2Ng==">知乎<i class="fa fa-external-link-alt"></i></span>，which第一个高票回复我觉得不对，直接在评论里面怼回去了。</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/011454-204261.png" alt="image-20201021175117502" style="zoom: 70%;" /><ul><li><p>可以看到同样的情况下，Q-learning收敛比较慢（因为探索的概率更大哇），但是一旦收敛，就比较稳定了。但是Sarsa就不一样，收敛了以后，由于探索性探索到的动作之前没有好好学习到，所以经常会出现锯齿（which Q-learning已经在前期探索到比较好的策略了）[所以<span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjMvY2hhcHRlcjM=">有人<i class="fa fa-external-link-alt"></i></span>说的“sarsa因为要兼顾探索所以策略不稳定“是这个意思( 并不是说q-learning就没有兼顾探索了hh) ]</p></li><li><p>另一方面，Sarsa由于缺乏探索性（偏向保守），所以没有收敛到一个最优解，也许需要更长的时间才能收敛到Q-learning的程度 ( 可以看到收敛曲线其实还是在缓慢下降的 )</p></li></ul></blockquote><p>所以动作空间别太大哈，不然不就凉凉了2333 【个人觉得off-policy 学习率大的时候适合动作空间比较小的】</p><blockquote><p>which事实证明并不是的2333….我着实没想通</p></blockquote></blockquote><blockquote><p><strong>异策略可以保证充分的探索性</strong>。例如⽤来评估和改善的策略是贪婪策略，⽤于产⽣数据的探索性策略为探索性策略，如ε-soft策略。  – 郭宪 《深入浅出强化学习：原理入门》</p></blockquote></li></ul><ul><li><p>ε-greedy策略是是ε-soft策略中的一种</p><p>如果“严格”的说，ε-greedy策略是 $\frac{\epsilon}{A(s)}-soft$ 的策略。</p><p>解释请参考<span class="exturl" data-url="aHR0cDovL2ZhbmN5ZXJpaS5naXRodWIuaW8vYm9va3MvcmwzLw==">这个博客<i class="fa fa-external-link-alt"></i></span></p><p>进行符号测试： $\frac{\epsilon}{A(s)}-soft$  成果</p><p>进行符号测试： $ \frac{\epsilon}{A(s)}-soft $  成果</p><p>符号 $$ \frac{\epsilon}{A(s)}-soft$$  测试2</p></li><li><p>值迭代和策略迭代</p><ul><li><p>参考<span class="exturl" data-url="aHR0cDovL3d1bGMubWUvMjAxOC8wNS8wNS8lRTUlQkMlQkElRTUlOEMlOTYlRTUlQUQlQTYlRTQlQjklQTAlRTclQUMlOTQlRTglQUUlQjAoMSktJUU2JUE2JTgyJUU4JUJGJUIwLw==">这个笔记<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>policy iteration 最后收敛的 value V 是当前 policy 下的 value 值（也做对policy进行评估），目的是为了后面的policy improvement得到新的policy；所以是在<strong>显式地不停迭代 policy</strong>。</p><p>而value iteration 最后收敛得到的 value 是当前state状态下的最优的value值。当 value 最后收敛，那么最优的policy也就得到的。虽然这个过程中 policy 在也在隐式地更新，但是<strong>一直在显式更新的是 value</strong> 的，所以叫value iteration。</p><blockquote><p>那从这个角度来看，PG似乎应该属于policy gradient 2333,毕竟是直接对策略进行更改 ( PG中是直接输出策略而非值函数了，也就是update参数实际上就是update策略 。DQN的话update 参数其实是在更新值函数，因为其模型输出是值函数233 ） </p></blockquote></blockquote></li><li><p>SARSA和Q-learning也都是值迭代引出来的，只不过一个是同策略（on-policy），另一个是异策略（off-policy）。至于是TD还是MC，只不过采样方式和训练效率上的差别而已。</p></li></ul></li><li><p>PG和AC的划分标准可以参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MTY0NTc2OA==">这个知乎<i class="fa fa-external-link-alt"></i></span></p><ul><li><p>A2C实际上是Advantage Actor-Critic的缩写</p></li><li><p><code>在PG策略中，如果我们用Q函数来代替R，那么我们就得到了Actor-Critic方法。</code></p><blockquote><p>所以这里我的理解是：引入了值函数去估计期望累计回报，which作为critic，就是Actor-Critic，有没有baseline并不是最重要的（AC里面，baseline也不一定要用$V(S_t)$ ，不过是因为一般来说，都有了$Q(s,a)$去估计累计期望回报，没道理不用$V(S_t)$作为baseline ,Vanilla PG里面的baseline也是用的$V(S_t)$,但还是PG系列 ）</p></blockquote></li></ul></li></ul><ul><li><p>环境non-deterministic 和 deterministic的区别</p><ul><li><p>取决于state是不是只受action影响，env自己是不是也在演化。</p></li><li><p>比如下棋，俄罗斯方块，你做了你的决定，你的下一个状态不是确定的 ( P(s,a)转移阵不是非0即1的 )</p><p>俄罗斯方块游戏里面的状态是</p></li><li><p>马里奥游戏就是deterministic的</p></li></ul><blockquote><p>网络中，输入的流量矩阵也是一个会引起state变化的，有一定概率的东西，所以也是non-deterministic</p></blockquote><ul><li>non-stationary和non-deterministic异同：env肯定都是在演化的，但是前者env演化的模式并不固定( 以泊松分布为例，env的演化可以符合参数为$\lambda$的泊松分布( non-derterministic ) (这是一个概率分布)，但是$\lambda$参数本身不能随时间变化，否则相当于演化的概率分布发生了变动，也就是演化的模式是不固定的(non-deterministic)  )</li></ul></li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p>data-whale强化学习教程</p></li><li><p>刘建平的系列博客确实不错,有空回顾下</p><ul><li><p>已完成</p><ul><li><p>8(<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvOTcxNDY1NS5odG1s">价值函数的近似表示与Deep Q-Learning<i class="fa fa-external-link-alt"></i></span>) [NIPS’13] + 9(<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvOTc1NjA3NS5odG1s">Deep Q-Learning进阶之Nature DQN<i class="fa fa-external-link-alt"></i></span>) [NIPS’15]</p><ul><li><p>三种神经网络的输入输出方式</p></li><li><p>NIPS’13 , 改进主要是经验池回放 ,Q-learning–&gt;DQN</p></li><li><p>NIPS’15 , 改进主要是双网络,  DQN –&gt;Nature DQN</p><blockquote><p>注意,<u>双网络并不是DDQN才提出来的</u></p></blockquote></li><li><p>介绍了下CartPole-v0的基本情况</p></li><li><p>8里面说PG用的是交叉熵，我就不是很懂了</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/14/104102-559352.png" alt="image-20201114104101708"></p><ul><li><p><input disabled="" type="checkbox">  【建模思想】奖励设置要均匀，进一步还可以尝试下下归一化 ==其实我是有点疑惑，后面看看能不能找到理论依据==</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/14/111303-795092.png" alt="image-20201114110105580"></p></li></ul></li><li><p>8的评论里面还提到了为何现在用的都是TD(0)：实现方便，如果是多步TD，需要改变buffer的构造，改成( s,a,r,s’,a’,r’,s’’… ) ，比较麻烦。虽然经验表明了TD(λ)在λ&gt;1的时候效果比较好（注意，TD(λ)是给多步TD加了权重，更复杂），但是实际上单步TD就够用了。</p></li></ul></li><li><p>10(<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvOTc3ODA2My5odG1s">Double DQN (DDQN)<i class="fa fa-external-link-alt"></i></span>)</p><ul><li><p>DQN存在过度估计的问题,which我没有细究(原文有),有一些文章(e.g.<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85Nzg1MzMwMA==">JQWang的知乎专栏<i class="fa fa-external-link-alt"></i></span>)在对论文的详解中有说,但是刘建平这里缺失了</p><blockquote><ul><li><p><input disabled="" type="checkbox">  JQWang的论文解读专栏还是挺详细的</p></li><li><p><input disabled="" type="checkbox">  评论里面提到了过度估计的事情，which感觉还不错。==优先学习一下==</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjcvY2hhcHRlcjc=">DataWhale的教程<i class="fa fa-external-link-alt"></i></span>给的解释还是不错的，但其实我觉得没有说清楚:过高估计本身是没影响的，最重要的还是策略的问题，有了双网络，就能有个理性的target，朝正确的方向更新，本身选动作不是很重要，没选到$\underset{a}argmax Q’(s,a)$的话我就当作探索的一个experience也可以哇，重要的是更新价值函数！！</p></li></ul></blockquote></li><li><p>改进就是 表现网络/当前网络中找action ( via argmax ),在target网络中找Q值</p></li><li><p><input disabled="" type="checkbox">  提到了ICML’16的<span class="exturl" data-url="aHR0cHM6Ly9pY21sLmNjLzIwMTYvdHV0b3JpYWxzL2RlZXBfcmxfdHV0b3JpYWwucGRm">rl tutorial<i class="fa fa-external-link-alt"></i></span> ,也可以翻翻后面几年的</p></li><li><p><input disabled="" type="checkbox">  由S和A得到R, S’和is_end时，R和is_end是根据环境反馈回来的，which对应的是：<strong>S</strong>是否is_end以及S情况下采取A得到的R</p><blockquote><p>确定么？我总感觉是S’是否是end ， V(end_state)=0</p></blockquote></li></ul></li><li><p>11(<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvOTc5NzY5NS5odG1s">Prioritized Replay DQN<i class="fa fa-external-link-alt"></i></span>)</p><ul><li></li></ul></li><li><p>19<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcGluYXJkL3AvMTA2MDkyMjguaHRtbA==">AlphaZero<i class="fa fa-external-link-alt"></i></span>建模设计中有奖励回溯的部分</p></li></ul></li></ul></li><li><p><input disabled="" type="checkbox">  抓到一个大佬的<span class="exturl" data-url="aHR0cHM6Ly9odWppYW4uZ2l0Ym9vay5pby9kZWVwLXJlaW5mb3JjZW1lbnQtbGVhcm5pbmcv">gitbook<i class="fa fa-external-link-alt"></i></span> (hujian.gitbook.io)</p></li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input disabled="" type="checkbox">  【强化学习】中Q-learning,DQN等off-policy算法不需要重要性采样的原因</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg5NTMzOS9hcnRpY2xlL2RldGFpbHMvODQ4ODExNjk=">CSDN<i class="fa fa-external-link-alt"></i></span></p></li><li><p>同策略 采样大，收敛慢； Q-learning 是异策略，还不需要importance sampling </p><blockquote><p>但是我看Q-learning也是一步一更新哇…感觉采样大这个劣势并没有利用好？</p></blockquote></li></ul></li><li><p><input checked="" disabled="" type="checkbox">  编程实战书P21 要结合历史观测 是因为部分可观测性？而不是因为非马尔可夫性？</p><p>似乎说得通… 我是因为没有认清当前的状态是什么所以才需要多个state拼在一起的窗口</p></li><li><p><input disabled="" type="checkbox">  交叉熵与one-hot之间的联系</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjQvY2hhcHRlcjQ=">百度飞桨部分给出了一些解释<i class="fa fa-external-link-alt"></i></span>给出了点解释，which我觉得还是没有讲清楚</li><li>check下<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3pob3Vib2xlaS9pbnRyb1JM">强化学习纲要<i class="fa fa-external-link-alt"></i></span>对应部分的讲解</li></ul></li><li><p><input disabled="" type="checkbox">  epsilon的减小方式有没有什么特别的讲究\</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXdhNHkxNzdRMQ==">正月灯笼<i class="fa fa-external-link-alt"></i></span>函数式编程让我感到疑惑:</p><p>up说函数式编程可以避免在debug的时候陷入循环中，那么我很好奇函数式编程如何debug<br>list.append为何拖累了速度呢？up有没有相关资料可以分享一下~<br>想问下第二种方式和第三种方式是不是除了形式上并没太大的区别，主要还是第一种方式里面的append是性能瓶颈?</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach</title>
      <link href="/ExtensiveReading/Route/DRL-TE/"/>
      <url>/ExtensiveReading/Route/DRL-TE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li><p>感觉这篇文章文笔不行啊…一看就是中国人写的…[果然，作者全都是中国名…]</p></li><li><p>整体思路是：</p><p>​    决定链路分割比是一个连续控制问题，如果用的是离散控制的强化学习算法，会导致解空间成指数级的爆炸性增长，所以我们要使用连续控制的强化学习算法。连续型的，一开始的想法就是怼一个state-of-art的模型上去。但问题是，做出来效果不好，所以就用了AC算法，并基于AC算法加了<u>两个改进</u>：TE-aware exploration &amp; 训练上的trick。前者实际上就是结合网络的这个背景，对探索进行了一定的约束，后者实际上就是添加了优先级回放的功能。</p></li></ul><hr><ul><li>evaluation还是很不错==哪里不错??==</li></ul><ul><li><p>创新点/主要思想</p><ul><li><p>首次用DRL做TE</p></li><li><p>提出了DRL-TE的框架 </p><blockquote><p>这里主要指的是 将DRL用在网络中需要改进的一些点 ( action<del>base</del> )</p></blockquote></li><li><p>改进了算法</p></li></ul></li><li><p>算法使用</p><ul><li>RL （AC）<ul><li>进行了技术上的改进：TE-aware expoloration : 在action<del>base</del>上添加噪声； 添加了缓冲区权重</li></ul></li></ul></li><li><p>实验设置</p><ul><li>集中式的</li><li>ns3</li><li>代表性和随机性的网络拓扑  （from zoo and generated by brite）</li></ul></li><li><p>效果</p><ul><li>提升了吞吐，降低了延迟 ( 毕竟考虑了延迟的这个目标 )</li><li>对网络变化更有鲁棒性  (==evaluation部分是如何得出这个结论的？==需要再整理下)</li></ul></li></ul><hr><ul><li><p>排队论不适合多跳排队问题的建模</p><ul><li>强假设不能满足</li><li>多跳排队还是个open problem  </li><li>为什么排队论和NUM不适合</li></ul><p>==那排队论研究的是什么问题??==</p></li></ul><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​        现代通信网络已经变得非常复杂且高度动态，这使其难以建模，预测和控制。 在本文中，我们开发了一种新颖的体验驱动方法，可以像人类学习新技能（例如驾驶，游泳等）一样，根据自身的经验而不是准确的数学模型来学习很好地控制通信网络。 具体来说，我们首次建议利用新兴的深度强化学习（DRL）在通信网络中实现无模型控制； 并针对基础网络问题：流量工程（TE），提出了一种新颖且高效的基于DRL的控制框架DRL-TE。通过共同学习网络环境及其动态性，并在强大的深度神经网络（DNN）的指导下进行决策，<strong>所提出的框架最大程度地提高了广泛使用的效用函数</strong>。<strong>我们提出了两种新技术</strong>，即TE感知探索和基于行为者批评的优先体验重播，以优化通用DRL框架，尤其是针对TE的框架。 为了验证和评估所提出的框架，我们在<strong>ns-3</strong>中实施了该框架，<strong>并使用代表性和随机生成的网络拓扑进行了全面测试</strong>。 </p><blockquote><p>这里的代表性和随机性</p></blockquote><p>​    广泛的数据包级仿真结果表明：1）与几种广泛使用的基准方法相比，DRL-TE显着<u>降低了端到端延迟</u>，并不断提高了网络实用性，<u>同时提供了更好或相当的吞吐量</u>；  2）DRL-TE对网络的变化更具有鲁棒性； 和3）DRL-TE始终优于最新的DRL方法（用于连续控制），即深度确定性策略梯度（DDPG），which不能提供令人满意的性能。</p><blockquote><p>创新：</p><ul><li>我们是第一个为TE提供高效，实用的基于DRL的经验驱动控制框架DRL-TE。（就是第一个用DRL做TE的）</li><li>对结合network使用RL做出了巨大的贡献：1. 提出了DRL-TE的框架； 2. 在AC上进行改进，实验证明比ddpg效果要好不少</li></ul></blockquote><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><blockquote><p>Our general goal(e.g. 拯救世界)  &amp;  SDN is promising</p></blockquote><p>​    因此，我们的目标是开发一种新颖的，无需经验的无模型方法，该方法可以像人类学习技能（例如驾驶，游泳等）一样，从经验中学习很好地控制通信网络，而不是精确的数学模型。我们认为，某些新兴的联网技术，例如软件定义网络（SDN）[18]，可以很好地支持这种体验/数据驱动的方法。 例如，SDN中的<strong>Openflow</strong>控制器可以用作中央控制单元，用于收集数据，制定决策和部署解决方案。</p><blockquote><p>开始喷前人的工作</p></blockquote><p>​    一个基本的网络问题是流量工程（TE）：给定一组具有源节点和目标节点的网络流，请找到一种解决方案，以最大化实用功能为目标转发数据流量。 简单且广泛使用的解决方案包括：始终通过最短路径路由流量（例如，开放式最短路径优先（OSPF）[24]）； 或通过多个可用路径平均分配流量（例如，有效负载平衡<strong>（VLB）[38]**）。 显然，它们都不是最优的。 如果存在针对网络环境，用户需求及其动态的准确且数学可解的模型，则可以开发出更好的解决方案。 <u>排队论已被用于对通信网络进行建模并协助资源分配[15]，[25]，[26]，[37]</u>。 **但是，由于以下原因，它可能不适用于涉及多跳路由和端到端性能（例如延迟）的网络问题</strong>：1）在排队论中，queueing network（而不是单个队列）中的许多问题仍然是开放问题，而具有网状拓扑结构的通信网络则表示相当复杂的多点到多点排队网络，其中来自一个队列可以被分布到多个下游队列，并且一个队列可以从多个不同的上游队列接收分组。  2）<u>排队理论只能在一些强假设下（例如，元组到达遵循泊松分布等）提供准确的排队延迟估计，但是在复杂的通信网络中可能不成立</u>。 请注意，即使到达每个源节点的数据包都遵循泊松分布，到达中间节点的数据包也可能不会。</p><p>​    另外，对**<u>网络效用最大化（NUM）[17]</u><strong>的研究也很深入，它通常通过制定和解决优化问题来提供资源分配解决方案。 但是，</strong>这些方法可能会遇到以下问题**：1）它们通常假定一些关键因素（例如用户需求，链接使用等）作为输入给出，但是，这些因素很难估计或预测。  2）由于给定了资源分配的决策变量（例如TE），因此很难通过显式地将其包含在效用函数中来直接最小化端到端延迟，因此很难在 由于需要一个精确的数学模型来实现此目的，因此它们必须是封闭的形式（尽管如上所述，排队理论在这里可能不起作用）。  3）这些工作未能很好地解决网络动态性问题。 他们中的大多数声称提供了一种“良好”的资源分配解决方案，该解决方案是最佳的或接近最佳的，但仅适用于网络快照。 但是，大多数通信网络时变很大。 这些NUM方法尚未很好地解决如何调整或重新计算资源分配以适应这种动态情况。 </p><blockquote><p>讲了下为何用DRL</p></blockquote><ul><li><p>DRL is in succsess</p><ul><li>DRL is promising<ul><li>model-free ,not relying on exact model (e.g. queueing model)<ul><li>handle complicated action space with DDPG</li><li>can handle dynamic env， due to it is AI method</li></ul></li></ul></li></ul></li></ul><blockquote><p>contribution</p></blockquote><ul><li><p>我们是第一个为TE提供高效，实用的基于DRL的经验驱动控制框架DRL-TE。</p></li><li><p>我们讨论并表明，**<u>直接应用最先进的DRL解决方案进行连续控制，即深度确定性策略梯度（DDPG）[16]，对TE问题效果不佳。</u>** 【有意思了。意思来了】</p><blockquote><p>论文中并没有分析为什么DDPG做的不好，我们的理解是，他只是想体现他的工作量：他做了这么多建模和算法上的尝试。</p></blockquote></li><li><p>我们提出了两种新技术，即TE-aware exploration 和 AC-based prioritized experience replay，以优化通用DRL框架，尤其是针对TE的框架。 </p><p>我们通过使用具有代表性和随机网络拓扑的ns-3进行的广泛数据包级仿真，表明DRL-TE明显优于几种广泛使用的基线方法。</p></li></ul><h1 id="2-DRL"><a href="#2-DRL" class="headerlink" title="2 DRL"></a>2 DRL</h1><h1 id="3-Problem-Statement"><a href="#3-Problem-Statement" class="headerlink" title="3 Problem Statement"></a>3 Problem Statement</h1><p>==这里是为啥突然要提出delay这个指标来着？==</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/210803-186164.png" alt="image-20201104210801863" style="zoom: 80%;" /><p>分割比$w_{k,j}$ , 备选路径集合$P_k$ , traffic load $f_{k,j}$</p><ul><li><p>$\alpha-faireness$ 的文献要好好读读这个指标的含义</p><ul><li><p>又提到了，$\alpha$ 可以被用来balance fairness和efficiency 。 当$\alpha=1$的时候，可以获得proportional fairness</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211336-513625.png" alt="image-20201104211329992" style="zoom: 80%;" /></li><li><p>仿照Remy提了个指标</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211424-585348.png" alt="image-20201104211423959" style="zoom:80%;" /></li></ul></li></ul><h1 id="4-Proposed-DRL-Based-Control-Framework"><a href="#4-Proposed-DRL-Based-Control-Framework" class="headerlink" title="4. Proposed DRL-Based Control Framework"></a>4. Proposed DRL-Based Control Framework</h1><p>在本节中，我们介绍了针对上述TE问题的建议的基于DRL的控制框架DRL-TE。</p><p>所提出的控制框架的核心是一个代理，该代理运行DRL算法（算法1）以在每个决策时期找到最佳动作，将动作带入网络（**<u>例如，通过网络控制器</u><strong>），观察网络状态，并 收集过渡样本。  TE问题显然是一个</strong><u>连续的控制问题</u>**。</p><ul><li><p>state</p><p>点对的集合</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211803-272410.png" alt="image-20201104211802927"></p><ul><li><p>actors</p><p>分割比的集合</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/03/121443-968455.png" alt="image-20201203121442730"></p></li><li><p>reward</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/03/121455-73685.png" alt="image-20201203121454816"></p><ul><li><p>algorithm :</p><ul><li><p>AC算法</p></li><li><p>动作加随机噪声</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/212915-598687.png" alt="image-20201104212913054"></p><p>​    所提出的控制框架不限于针对abase的任何特定的基础TE解决方案，可以通过许多不同方式来获得该解决方案。 </p></li></ul></li></ul><blockquote><p> 例如，一种简单的解决方案是使用最短路径为每个通信会话传递所有数据包，这在大多数情况下不是最佳的，但足以切断作为探索的基准。</p><p>另一种解决方案是将每个通信会话的流量负载平均分配到所有候选路径。</p><p>基于NUM的方法也可以用于查找基本解决方案。 例如，我们可以通过解决以下数学编程来获得TE解决方案：</p><p>​                                    <img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/213935-479446.png" alt="image-20201104213933393"  />    </p></blockquote><p>​    In this formulation，目的是使产量方面的总效用最大化。 请注意，很难在效用函数中包含端到端延迟项，因为不存在可以准确地在端到端延迟与其他决策变量&lt;xk，fk,j&gt;</p><blockquote><p> Note that it is hard to include the end- to-end delay term in the utility function since there does not exists a mathematical model that can accurately establish a connection between end-to-end delay and the other decision variables &lt; xk, fk,j &gt;. </p></blockquote><p>​    这就是为什么NUM上大多数现有作品都没有很好地解决端到端延迟的原因。</p><p>​    约束（6b）确保每条链路上的总流量负载不超过其容量Ce，其中pj是Pk中的第j条路径。 约束（6c）确保每个会话k的总吞吐量不超过其需求Bk（可以估算）。 约束（6d）在两组决策变量<xk>和&lt;fk，j&gt;之间建立联系。 如果α= 1，Uα（xk）= log xk，则该问题变为凸编程问题，which可以通过我们的实现中使用的Gurobi Optimizer [10]有效解决。</p><hr><blockquote><p>建模完成后就开始说如何解了</p></blockquote><p><strong>AC算法</strong></p><ul><li><p>加上了优先级经验回放，which author claim 是他们的扩展，不是AC本身自带的</p></li><li><p>网络架构</p><ul><li><p>Actor</p><ul><li>2 FC ( 64,32 ) Leaky Rectifier激活函数，输出层softmax作为激活函数来确保输出值的总和等于1。</li></ul></li><li><p>Critic</p><ul><li>2 FC ( 64,32 ) Leaky Rectifier激活函数</li></ul><blockquote><p>A和C最后一层网络架构的不一样的原因是，前者输出动作概率，所以需要softmax，后者只要输出一个数值，所以不需要用softmax归一化。</p></blockquote></li><li><p>本算法对于优先级采样的一些设计/改进</p><ul><li><p>为了以等式（9）给出的概率对N个转换进行采样，将范围[0，p<del>total</del>]划分为N个子范围，并从每个子范围中均匀采样一个转换，其中p<del>total</del>是重播缓冲区中的所有transition的他优先级之和。 正如[30]所建议的，我们使用求和树来实现优先级概率，这类似于二进制堆。</p></li><li><p>区别在于1）叶节点存储转换的优先级；  2）内部节点存储其子节点的总和。 这样，root的值为p<del>total</del>，更新和采样的时间复杂度为O（logN<del>tree</del>），其中N<del>tree</del>是求和树中节点的数量。</p></li><li><p>超参数设置</p><p>ξ：= 0.01，β<del>0</del>：= 0.6，β<del>1</del>：= 0.4，γ：= 0.99，ϕ：= 0.6，η<del>π</del>：= 0.001，η<del>Q</del>：  = 0.01，τ：= 0.01，N = 64。</p></li></ul></li></ul></li></ul><h1 id="5-Performance-Evaluation"><a href="#5-Performance-Evaluation" class="headerlink" title="5. Performance Evaluation"></a>5. Performance Evaluation</h1><ul><li><p><strong>Testbed</strong></p><p>ns-3, Tensorflow, with topo of NSFNET[23] &amp; ARPANET[1] &amp; 网络拓扑生成器BRITE [19]随机生成了一个具有20个节点和80个链接的网络拓扑</p></li><li><p>实验设置</p><p>对于每种网络拓扑，我们分配 <strong><u>K = 20 </u>**个通信会话，每个会话都有随机选择的源节点和目标节点。 对于每个通信会话，我们选择3条最短路径（就跳数而言）作为其候选路径。 每个链接的容量设置为</strong><u>100Mbps</u><strong>。 数据包到达每个通信会话的源节点（即流量需求）遵循泊松过程（请注意，数据包到达中间节点可能不遵循泊松过程），</strong><u>其平均值均匀地分布在一个20Mbps大小的窗口内</u><strong>。 在我们的实验中，我们最初将窗口设置为[0，20] Mbps，然后通过以每次运行5Mbps的步长滑动窗口来增加流量需求。 我们为效用函数设置</strong>α：= 1<strong>和</strong>σ：= 1**以平衡吞吐量，延迟和公平性，即</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/05/005550-301559.png" alt="image-20201105005550050"></p></li></ul><ul><li><p><strong>Baselines</strong></p><ul><li><p>最短路径（SP）：每个通信会话都使用最短路径来传递其所有数据包。</p></li><li><p>负载平衡（LB）：每个通信会话均将其流量负载平均分配给所有候选路径。</p></li><li><p>网络实用程序最大化（NUM）：它通过解决凸编程问题Ⅳ中给出的NUM-TE来获得TE解决方案。</p></li><li><p>DDPG：为公平起见，我们在保持其他设置（例如状态，动作，奖励和DNN）相同的情况下，用DDPG算法[16]替换为DRL-TE算法（算法1）。</p></li></ul></li></ul><ul><li><p><strong>Evaluation指标</strong> &amp; 图释说明</p><ul><li>我们将总的端到端吞吐量，端到端平均数据包延迟和网络（即总）效用值用作比较的性能指标。 </li><li>我们在图5和6中显示了相应的仿真结果。图1-3每个对应于一个网络拓扑。 <ul><li>注意，x轴上的数字是相应交通需求窗口（如上所述）的中心值。 </li></ul></li><li>根据奖励显示了在在线学习过程中三种网络拓扑上两种DRL方法（DDPG和DRL-TE）的性能。 <ul><li>为了便于说明和比较，我们使用常用方法（r-rmin）/（rmax-rmin）归一化和平滑了奖励值（其中r是实际奖励，rmin和rmax是在线学习期间的最小和最大奖励）和著名的**<u>前后过滤算法[11]</u><strong>。 我们在</strong><u>图4</u>**中给出了相应的仿真结果。</li><li>请注意，对于这些结果，使用窗口[10，30] Mbps生成了相应的流量需求。</li></ul></li></ul></li></ul><ul><li><p><strong>结论</strong>    </p><ul><li><p>端到端时延</p><ul><li><p>从图1a，2a和3a中可以看出，与所有四种基线方法相比，DRL-TE显着降低了所有三种拓扑的端到端延迟。 例如，在NSF拓扑上，当流量负载为中等时（即流量需求窗口为[10，30] Mbps），DRL-TE可以将端到端延迟显着降低51.6％，28.6％，74.6％ 与SP，LB，NUM和DDPG相比分别为50.0％和50.0％。 总体而言，DRL-TE分别平均降低了55.4％，47.1％，70.5％和44.2％。 </p></li><li><p>与吞吐量相比，端到端延迟更难处理，因为如上所述，它缺乏能够很好地捕捉其特性和运行时动态的精确数学模型。 看到NUM导致性能相当差是不足为奇的，因为NUM无法明确解决端到端延迟，并且其设计基于网络状态相当稳定或变化缓慢的假设，这可能不是事实。 尽管诸如SP和LB之类的简单解决方案凭直觉可以提供预期的性能，但最短的路径和负载平衡（可以避免拥塞）可以帮助减少延迟。  DRL-TE毫无疑问在端到端延迟方面提供了卓越的性能，因为它不断学习运行时动态，并在DNN的帮助下做出明智的决策以使其达到最佳状态。</p></li></ul></li><li><p>吞吐量</p><p>即使DRLTE的目的（奖励功能）不是简单地最大化端到端吞吐量，它仍然提供令人满意的性能，如图1和2所示。  1b，2b和3b。 与所有其他方法相比，DRL-TE可以持续提高NSFNST拓扑的吞吐量。 在ARPANET和随机拓扑上，DRL-TE给出的吞吐量值可与LB给出的吞吐量值相媲美（负载均衡在整个过程中应产生很高的收益），但仍高于SP和NUM提供的吞吐量值。  </p></li><li><p>效用函数</p><p>如预期的那样，我们可以从图2和3中看到。 从图1c，2c和3c可以看出，DRL-TE在总效用方面胜过所有其他方法，因为其奖励功能已设置为最大化。 平均而言，DRL-TE分别胜过SP，LB，NUM和DDPG 7.7％，9.1％，26.4％和12.6％。 </p></li><li><p>使用并且无论选择哪种网络拓扑，吞吐量和延迟都基本上与流量需求有关（无论什么方法，什么拓扑，throughpout和delay就是会随着流量需求增大而上升，the total utility 通常会下降）。 这很容易理解，因为流量负载越高，通常吞吐量就越高，但是由于等待时间更长甚至拥塞而导致的延迟也就越大，从而降低了总实用性。 此外，吞吐量不会单调增加，当网络变得饱和时，由于拥塞和数据包丢失，更高的流量需求甚至可能导致吞吐量变差。 我们还注意到DRL-TE在流量负载和网络拓扑的变化方面具有鲁棒性，因为在所有流量需求设置和所有拓扑中，DRL-TE的性能始终优于所有其他方法。</p></li><li><p>另外，我们还可以从图1和图2中观察到。  1-3指出DDPG在这些拓扑上效果不佳。 例如，与SP和LB相比，就总效用而言，它通常表现较差，即使它提供了稍微更好的端到端延迟。 为了进一步说明DRL-TE为什么比DDPG更好的原因，我们还显示了图4中三种网络拓扑在在线学习过程中奖励价值的变化。显然，在所有这些网络拓扑中，DRL-TE很快（仅在几个范围内） 数以千计的决策时代）达到了很好的解决方案（给予了很高的回报）； 而DDPG似乎停留在具有较低奖励价值的局部最优解决方案上。 特别是，在随机拓扑上，我们只能看到前几百个世代的微小改进，然后它无法找到更好的解决方案（动作）来提高奖励。 这些结果清楚地证明了所提出的新技术的有效性，包括TE感知探索和基于行为者批评的优先体验重播。</p><blockquote><p>==??==问题就来了，DDPG不能加优先级体验重播么…</p></blockquote></li></ul></li></ul><h1 id="5-Related-Work"><a href="#5-Related-Work" class="headerlink" title="5. Related Work"></a>5. Related Work</h1><p>==关于网络的这一部分要好好看下==</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p><input checked="" disabled="" type="checkbox">  我觉得第四节中 一定概率选择$a_{base}$而不是$a_{random}$ 会不会造成随机性的丢失? </p><blockquote><p>不会！ 因为有噪声！而且a<del>base</del>设计的好，是可以覆盖全网的信息的。</p></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  NUM到底是什么模型？？这里指的应该是 以网络链路利用率最大化 （Network utility maxmization）</p><ul><li>attention！ 这里的U不是utilization，而是utility！e.g. utility function = - utilization</li></ul><blockquote><p>NUM就是一个满足网络状况的线性规划模型，which also includes MCF</p></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  路由和TE的区别到底是什么</p><blockquote><p>路由就是保持包可达性的；TE的话，正如本文所说，是有一个优化目标的</p></blockquote></li></ul><h3 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h3><ul><li><p>VLB和ECMP的区别</p></li><li><p>标红的句子根本是看不懂。。问下飞哥</p></li><li><p>Caida数据集</p></li><li><p>看看人家代码里面的split ratio</p></li><li><p>还是那个问题。。这里reward的设立是不是有问题….看下Pensive，人家比较有建模经验</p><blockquote><p>其实我感觉没太大问题了</p></blockquote></li><li><p>evaluation </p><ul><li>结论部分讲端到端时延的其实我没有很懂</li></ul></li></ul><ul><li><p>APRANET</p></li><li><p>经常看到的empirical research/study 是什么意思</p></li></ul><h1 id="inspiration"><a href="#inspiration" class="headerlink" title="inspiration"></a>inspiration</h1><ul><li>不是直接套state-of-art就行</li></ul>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQR&amp;DLWR|Evaluating and Boosting Reinforcement Learning for Intra-domain Routing</title>
      <link href="/ExtensiveReading/Route/SQR-DLWR/"/>
      <url>/ExtensiveReading/Route/SQR-DLWR/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li><strong>在所有路由方案中，一个解决方案都不可能成为“最佳”解决方案并胜过其他解决方案</strong></li></ul><blockquote><p>原来路由也是分场景的！</p></blockquote><ul><li>评价RL相关、域内路由的工作，且自己做了两套方案及逆行比较，which是集中式的</li></ul><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​    机器学习在计算机视觉和计算机游戏等领域的成功引发了人们对在计算机网络中应用机器学习的兴趣激增。 本文试图回答一个广泛争论的问题：我们能否通过强化学习（RL）来提高域内路由的性能，域内路由是Internet上最基本的模块之一？ 由于复杂的网络流量条件和较大的路由选择空间，很难为现有的基于RL的路由解决方案给出确切的答案。 为了深入了解基于RL的路由的挑战，我们系统地对不同的基于RL的路由解决方案进行了分类，并从可扩展性，稳定性，鲁棒性和收敛性方面研究了几种代表性方法的性能。 结合评估各种基于RL的路由解决方案的经验教训，我们提出了两种方法，称为监督Q网络路由（supervised Q-network routing (SQR)）和基于离散链路权重的路由（discrete link weight-based routing，DLWR），它们可以提高基于RL的路由的性能，并提高性能。 形成事实上的最短路径域内路由。</p><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><p>​    路由是一种网络功能，可将数据包从给定的源传递到给定的目的地。 可以说，它是Internet中最基本的构建块，在服务质量（QoS）保证中起着至关重要的作用。 传统的路由策略，例如开放式最短路径优先（OSPF）路由[1]，可能会导致网络拥塞和链路利用率低，并且与<strong>最佳路由方法相比，性能可能会差5000倍[2]**。 在动态业务量变化的情况下，已经致力于优化路由路径。 例如，反压路由[3]最初是为无线网络提出的，也可以应用在有线网络中，它基于相邻节点之间的拥塞梯度来动态转发流量。 但是，它在路由路径中的收敛速度可能会很长，</strong>并且不一定会导致良好的小队列性能，如[4]<strong>中所证明的。 将机器学习应用于网络路由以获得更好的性能可以追溯到1994年，</strong>当时提出了Q路由的概念[5]。** 由于机器学习在其他领域（例如计算机视觉，游戏和自然语言处理）的巨大成功，最近对Q路由的兴趣再<strong>次兴起[6] [7]**。 另外，最近的一些研究通过在路由中应用深度（强化）学习，证明了令人鼓舞的结</strong>果[8] – [10]<strong>。 这些研究讨论了潜在的基于学习的路由方法，并使用一些典型的机器学习方法进行了评估，例如深度信念架构，深度神经网络（DNN）和信任区域策略优化（TRPO）。 **但是，Internet路由的性能在很大程度上取决于流量动态和各种网络状况</strong>。<strong>例如，现有的Q路由及其变体会在数据包级别更新路由表，即，他们了解环境并估算单个数据包的数据包交付时间</strong>。显然，它们的性能在高速网络中会受到影响，在高速网络中，数据包需要以微秒为单位转发。 <strong>在所有路由方案中，一个解决方案都不可能成为“最佳”解决方案并胜过其他解决方案</strong>。 根据这一观察，我们因此有动机去研究Internet路由中不同机器学习算法的利弊，并清除一些（虽然不太可能是全部）在路由中实际采用机器学习的障碍。 我们的研究并非不切实际地针对设计最有效的路由解决方案。 相反，我们提供了lessons(这里我觉得翻译成经验比较好)，在此基础上，我们展示了如何进一步改进现有方法。 </p><p>​    为此，我们研究了基于不同强化学习（RL）的路由策略对域内Internet路由性能的影响。 由于以下三个原因，我们缩小了关注点到RL和域内路由的: (1)<strong>基于RL的路由[8]不需要标记的数据</strong>，由于操作数据的规模大和网络的规模大，这是禁止的并且难以获得 状态;（2）在路由器处于同一自治系统（AS）域内的域内路由中，可以获得所有路由信息；（3）软件定义网络（SDN）的发展使通过全局网络视图通过中央控制平面实现智能路由算法变得容易了[11]。</p><p>​    <strong>我们在以下方面评估基于RL的路由：</strong></p><blockquote><p>(1) <strong>可扩展性</strong>：在高速，大规模网络中是否可以保持良好的性能？(2) <strong>稳定性</strong>：路由方法是否对各种流量模式和网络条件具有弹性？(3) <strong>健壮性</strong>：路由方法是否可以有效避免“不良”路由状态?（例如，congested,long-delay links）？(4) <strong>Convergence</strong>：是否可以快速达到新的路由策略以适应动态网络变化？ 我们对强化学习的研究基于两种主要方法，即基于价值的优化方法和基于策略的优化方法。 图1总结了每种方法的架构及其相应的算法。在我们的研究中，对图1中标有*的算法（它们是强化学习的代表算法）进行了评估。 </p></blockquote><p>​    <strong>本文的贡献可以总结如下：</strong></p><blockquote><p>• 我们根据不同的时间尺度将基于RL的路由解决方案系统地分为两类，以更新路由决策：packet-controlled智能路由和epoch-controlled智能路由。在每个类别中，我们将路由问题都视为RL问题。 总体而言，我们的分类为将来基于RL的路由研究提供了一个全面的视图。<br>• 在第一类中，我们分析经典Q路由的适用性，并评估其在实际网络设备上的性能。<br>• 在第二类中，我们介绍了用于确定路由路径的不同方法：基于显式路径的路由和基于隐式链路权重的路由。 然后，我们彻底评估典型RL算法的性能，并讨论其优缺点。<br>• 利用从Q路由和将现有RL算法应用于时代控制路由中获得的见识，我们提出了两种方法，监督Q网络路由（SQR）和基于离散链路权重的路由（DLWR），可提高性能 基于RL的路由，性能优于事实上的最短路径路由。</p></blockquote><p>​    </p><p>​    <strong>本文的其余部分的结构如下。</strong></p><blockquote><p>第二节介绍智能路由问题的背景，并通过强化学习来阐述路由问题。</p><p>第三节分析了分组控制的智能路由的适用性。</p><p>然后，我们分别在第IV节和第V节中分别分析和改进基于显式的基于路径的路由和基于隐式链路权重的路由。</p><p>第六节总结了从RL路由方法获得的见解。</p><p>第七节介绍相关工作。</p><p>最后，第八节总结了论文</p></blockquote><h1 id="II-BACKGROUND-ROUTING-AS-REINFORCEMENT-LEARNING"><a href="#II-BACKGROUND-ROUTING-AS-REINFORCEMENT-LEARNING" class="headerlink" title="II. BACKGROUND:ROUTING AS REINFORCEMENT LEARNING"></a>II. BACKGROUND:ROUTING AS REINFORCEMENT LEARNING</h1><h2 id="A-Network-and-Traffic-Models"><a href="#A-Network-and-Traffic-Models" class="headerlink" title="A. Network and Traffic Models"></a>A. Network and Traffic Models</h2><p>​    假设网络是网络的有向图G =（V，E），并且E = {e（v1，v2），e（v2，v1），…}表示其中V = {v1，  v2，…，vn}表示路由器之间的节点（路由器）链接。 每个链接e（vi，vj）具有容量C（vi，vj），表示可以从节点vi传递到vj的流量。 将网络的流量需求表示为流量矩阵M = [m<del>ij</del>]<del>n×n</del>，其中mij是从源节点vi到目标vj的流量。 当源－目的地对之间没有流量时，相应的流量将设置为零。  RL适用于无法获取标签数据或难以获取标签数据的情况。 在这种情况下，假定未知环境中的agent2通过接收有关环境当前状态的信息，采取措施并接收奖励或惩罚信号来找到最佳的行为策略，这反映了该agent过去的行为是否适当 。 代理商的目标是找到可以最大化长期回报的政策。  RL的简要介绍和彻底处理可以分别在[12]和[13]中找到。 路由问题的制定者是路由决策者。 在RL框架中，代理的动作是更新路由路径。 当前，代理采取行动有两种不同的时间尺度：（1）对每个数据包采取行动，（2）假设时间划分为多个纪元，则每个纪元都采取行动。 前者称为分组控制的智能路由，后者称为历元控制的智能路由。</p><h2 id="B-Packet-Controlled-Intelligent-Routing"><a href="#B-Packet-Controlled-Intelligent-Routing" class="headerlink" title="B. Packet-Controlled Intelligent Routing"></a>B. Packet-Controlled Intelligent Routing</h2><blockquote><p>Q路由及其变体是典型的数据包控制的智能路由。  Q路由是由Boyan和Littman [5]基于Bellman-Ford最短路径算法[14]和Q学习框架[15]提出的。 使用Q路由，网络中的每个节点都可以充当代理，以决定转发当前数据包的下一跳。 之所以称为Q路由，是因为每个节点在转发数据包之前都使用Q值来估计从当前节点经过不同的邻居到目的地的延迟。 对于节点vi处的每个数据包，代理选择具有最小Qvi（vj，d）的相邻节点vj作为数据包的下一跳，其中，如果节点vi通过以下方式转发数据包，则Qvi（vj，d）表示Q值。 它的邻近节点vj到目的地d。 在将数据包发送到vj时，vi立即从vj接收行程中剩余时间的反馈，表示为Qvj（d），即Qvj（d）= min Qvj（vz，d）（1）vz∈n  vj用以下学习函数更新节点vi的Q值：？Qvi（vj，d）=η（r + minQvj（d）-Qvi（vj，d））（2）其中，η是学习率，  r是数据包从节点vi到节点vj花费的时间，包括排队时间和传输时间。 基于Bellman-Ford最短路径算法，公式（2）的公式为：使用最佳策略从节点vi到目的地d所需的时间等于节点vi到节点vj的最短时间以及从节点vj所需的时间 以最佳策略到达目的地。 证明该算法在n节点网络中最多经过n-1次迭代后收敛</p></blockquote><h2 id="C-Epoch-controlled-Intelligent-Routing"><a href="#C-Epoch-controlled-Intelligent-Routing" class="headerlink" title="C. Epoch-controlled Intelligent Routing"></a>C. Epoch-controlled Intelligent Routing</h2><h3 id="1-Objective-of-epoch-controlled-routing"><a href="#1-Objective-of-epoch-controlled-routing" class="headerlink" title="1) Objective of epoch-controlled routing"></a>1) Objective of epoch-controlled routing</h3><p>​    optimal routing有不同的目标。 在本文中，我们考虑以下最优路由的特殊形式。 将在时期t末尾的链接e（vi，vj）上等待传输的数据包数量表示为ut ij。 最佳路由的目标是最小化所有t上所有链路的队列长度，即最小</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/25/215424-353121.png" alt="image-20201125215423618"></p><h3 id="2-Reinforcement-Learning-for-Routing"><a href="#2-Reinforcement-Learning-for-Routing" class="headerlink" title="2) Reinforcement Learning for Routing"></a>2) Reinforcement Learning for Routing</h3><blockquote><p>​    在RL框架中投放上述路由问题，我们将做出路由决策的网络控制器称为代理，将与控制器交互的网络称为环境。 <u>环境状态由流量矩阵M捕获</u>。动作根据观察到的状态将动作空间作为A.组成路由选择决策。 将状态空间表示为S，并在每个时间点t，代理接收环境状态St∈S，然后确定一个动作At∈A，该动作根据观察到的状态构成路由决策。 在下一个时间段，环境Rt + 1和新状态St + 1的反馈将发送到代理。 为了符合路由目标，我们将环境Rt + 1的反馈设置为：</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/25/215604-43857.png" alt="image-20201125215548761"></p><blockquote><p>​    在一系列时间t = 0、1、2，…的情况下，交互过程可以表示为S0，A0，R1，S1，A1，R2，S2，A2，…，可以用数学公式表示为 马尔可夫决策过程（MDP）[12]。 换句话说，奖励Rt + 1和下一状态St + 1仅取决于当前状态St和关联的动作At，概率为P（St + 1，Rt + 1 | St，At）。 因此，路由策略是从状态到选择每个动作的概率的映射，表示为S∈S和A∈A的π（A | S）。 如果代理在策略π下在状态S下采取动作A，则表示为Qπ（S，A）的动作值函数是来自环境的反馈值。 传统的强化学习问题通常是游戏问题，将在有限的范围内终止</p></blockquote><p>动作值通常定义为折现的未来奖励的期望Qπ（S，A）= E [Rt + 1 +γRt+ 2 +γ2Rt+ 3 + … +γTRT+ 1 | S，A]，其中γ为 奖励的折扣因子。 最佳Q值应遵循Bellman方程Q ∗，右侧是目标。i + 1（S，A）= E（r +γmaxA？Qi（S？，A？）| S，A）.</p><p>​    尽管如此，应根据路由问题量身定制传统的设置操作值的方法 。 由于未转发的数据包将在队列中进行缓冲，因此队列长度反映了一段时间内的累积结果。 因此，将本地时间段内所有链路上的最大队列大小最小化也是一个合理的目标^3^。</p><h3 id="3-Learning-Output"><a href="#3-Learning-Output" class="headerlink" title="3) Learning Output"></a>3) Learning Output</h3><blockquote><p>​    在以上基于RL的路由框架上，我们可能有不同的方式来呈现学习输出。 在本文中，我们研究了两种类型的学习输出：（1）基于显式路径的路由，以及（2）基于隐式链路权重的路由。 在基于显式路径的路由中，学习的输出包括一组路径，每个路径对应于应用于将数据包从给定源传递到给定目的地的路径。 在基于隐式链接权重的路由中，学习的输出包括所有链接上的权重值，我们根据这些值通过Dijkstra的最短路径算法找到路由路径</p></blockquote><h3 id="4-System-Architecture-for-RL-based-Routing"><a href="#4-System-Architecture-for-RL-based-Routing" class="headerlink" title="4) System Architecture for RL-based Routing:"></a>4) System Architecture for RL-based Routing:</h3><blockquote><p>​    由于我们只关注域内路由，因此我们可以通过具有全局网络视图的中央控制平面实现基于RL的智能路由[11]。 该代理在中央控制器中实现。 在每个时期，可编程路由器将环境信息（即流信息和队列大小）发送给代理； 代理学习环境并使用RL算法制定路由决策，然后将其发送到路由器以指导其数据包转发。</p></blockquote><h1 id="III-EVALUATING-PACKET-CONTROLLED-INTELLIGENT-ROUTING"><a href="#III-EVALUATING-PACKET-CONTROLLED-INTELLIGENT-ROUTING" class="headerlink" title="III. EVALUATING PACKET-CONTROLLED INTELLIGENT ROUTING"></a>III. EVALUATING PACKET-CONTROLLED INTELLIGENT ROUTING</h1><p>​    智能路由的代表性方法是Q路由及其变体。 在本节中，我们测试可编程交换机上Q路由的可扩展性。 <u>特别是，我们检查高速交换机是否能够负担一个包的处理时间内检查其缓冲区并更新路由表的开销</u>。 </p><p>​    在Q路由中，交换机需要（1）检查每个以太网端口上缓冲区的队列大小，（2）如II-B节所述更新Q表，并且（3）将收到的数据包转发到 具有每个数据包时间的最小估计延迟的下一跳。 实际上，Q路由需要下一跳开关才能将有关最小估计延迟的反馈返回给目的地。<u>尽管如此，我们真正关心的是交换机能够以多快的速度更新其路由表并转发数据包。</u>从本地交换机的观点来看，导致更新的原因（即，来自下一跳交换机的反馈信息）对于交换机的分组转发性能实际上并不重要。 基于此观察，我们可以模拟Q路由的行为并评估其数据包转发速度，而无需实际接收和使用下一跳的反馈信息。 <strong><u>换句话说，Q路由的实际性能甚至会比我们在此处公开的还要差。</u></strong>==？== 我们在一个简单的测试平台上实施和测试Q路由。 该测试平台内置有两台通过可编程交换机连接的台式计算机。 两台计算机被分配到不同的以太网段。 一台计算机用于流量生成器，以通过交换机将目的地为另一台计算机的数据包发送到另一台计算机。 交换机收到报文后，检查路由表，将报文转发到目的地址。 目标计算机还用于监视性能，即延迟和吞吐量。 <strong>可编程交换机具有2个3.1 GHz的Intel Core i5-3450 CPU，6 MB高速缓存和16 GB内存。 它还配备了7个以太网Intel i350千兆接口</strong>，而我们在实验中仅使用2个接口。 台式计算机是配备相同以太网接口的Dell poweredge T620。</p><p>​    **<u>Q路由算法是在可编程交换机中实现的，无需使用来自目的地的任何反馈信息</u>**，但是，交换机需要按照Q路由的要求，在传输每个数据包后使用相同的路由条目来“更新”其路由表。 相比之下，基准测试方法使用固定路由，该路由简单地使用固定转发表将接收到的数据包转发到目标，而没有任何“更新”。 这等效于具有稳定网络拓扑的网络中的最短路径路由。 我们分别测量了Q路由和最短路径路由的吞吐量和延迟。 为了评估吞吐量，我们让流量生成器以全速（1.5 Gbps）将大小为1024字节的数据包注入到交换机中。 我们评估监视器收到的数据包数量。 为了进行延迟评估，我们分别以450 Mbps，700 Mbps和965 Mbps的速率发送数据包。 表I显示了Q路由和最短路径路由的比较。从结果可以看出，转发速度越高，Q路由的等待时间就越长。 这是因为更高的转发速度意味着每秒发送更多的数据包，从而每秒发送更多的路由表更新。  Q路由中的此类更新减慢了交换机转发速度的近一半，并可能导致高速网络严重拥塞。</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p>introduction中说到Q路由的事情</p><ul><li><p>在数据包级别更新路由表 ，能保证收敛么…</p></li><li><p>需要调研这些文章</p></li><li><p><strong>在所有路由方案中，一个解决方案都不可能成为“最佳”解决方案并胜过其他解决方案</strong></p><blockquote><p>原来路由也是分场景的！</p></blockquote></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ExtensiveReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Routing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UDT</title>
      <link href="/Codes/UDT/"/>
      <url>/Codes/UDT/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="收集的、待整理的文章"><a href="#收集的、待整理的文章" class="headerlink" title="收集的、待整理的文章"></a>收集的、待整理的文章</h1><p>先不看架构了，直接看Aurora了</p><ul><li>wolfcs大佬的博客优先看，在reference那一节里面说了</li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vdWtlcm5lbC9wLzg5NzY5ODQuaHRtbA==">https://www.cnblogs.com/ukernel/p/8976984.html<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc2xpZGVzdGFsay5jb20vdTQyL3Q4ZWZqaw==">https://www.slidestalk.com/u42/t8efjk<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2t0bGlmZW5nL2FydGljbGUvZGV0YWlscy83ODUzMzM1NQ==">https://blog.csdn.net/ktlifeng/article/details/78533355<i class="fa fa-external-link-alt"></i></span></li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly91ZHQuc291cmNlZm9yZ2UuaW8v">sourceforge官网<i class="fa fa-external-link-alt"></i></span> 【05年出的，更新到09年】</p><blockquote><p>ppt 、poster、documention、discussion/help 版块(including Chinese)</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzZGZnaGprbDE5OTMvYXJ0aWNsZS9kZXRhaWxzLzU3NDE3MDc0">udt初步介绍<i class="fa fa-external-link-alt"></i></span> 里面有UDT的架构图，可惜没有再出后续了…</p><blockquote><img src="https://img-blog.csdn.net/20170226170700588?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYXNkZmdoamtsMTk5Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom: 33%;" /><img src="https://img-blog.csdn.net/20170226170750116?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYXNkZmdoamtsMTk5Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom:33%;" /></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  大佬系列博客：<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vY2F0ZWdvcmllcy8lRTclQkQlOTElRTclQkIlOUMlRTUlOEQlOEYlRTglQUUlQUUvcGFnZS81Lw==">udt源码分析<i class="fa fa-external-link-alt"></i></span> 后续想要读源码的话可以==再仔细看一下==（目前只是大概浏览了下）,which我觉得讲得真的不错</p><ul><li><p><input disabled="" type="checkbox">  大佬还有系列在<span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC93b2xmY3M=">oschina的平台上<i class="fa fa-external-link-alt"></i></span></p><blockquote><ul><li><input disabled="" type="checkbox"> 发送窗口大小及发送速率的调整</li><li><input checked="" disabled="" type="checkbox"> 实现分析总结</li></ul></blockquote></li></ul><blockquote><ul><li><p>UDT::startup()的调用过程为：UDT::startup()-&gt; CUDT::startup() -&gt; CUDTUnited::startup()。</p><p>从这里也可以看出UDT、CUDT、CUDTUnited之间的关系</p></li><li><p>UDT的命名规则有些讲究，前缀代表着数据类型</p></li><li><p><strong>设计架构</strong></p><ul><li><p>socket创建那一章说的：UDT的使用者在调用UDT API时，UDT API会直接调用CUDT类对应的static API函数，在CUDT类的这些static API函数中会将做实际事情的工作委托给s_UDTUnited的相应函数，但这个委托调用会被包在一个try-catch block中。s_UDTUnited的函数在遇到异常情况时抛出异常，CUDT类的static API函数捕获异常，根据捕获到的异常的具体类型，创建不同的CUDTException对象设置给s_UDTUnited的线程局部存储变量m_TLSError中并向UDT API调用者返回错误码，UDT API的调用者检测到错误码后，通过UDT::getlasterror()获取存储在m_TLSError中的异常。</p></li><li><p>bind( )函数<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vMjAxNS8wOS8wOS9VRFQlRTUlOEQlOEYlRTglQUUlQUUlRTUlQUUlOUUlRTclOEUlQjAlRTUlODglODYlRTYlOUUlOTAlRTIlODAlOTQlRTIlODAlOTRiaW5kJUUzJTgwJTgxbGlzdGVuJUU0JUI4JThFYWNjZXB0Lw==">那一章<i class="fa fa-external-link-alt"></i></span>说的: 和socket创建时一样是==分为3层==：UDT命名空间中提供了给应用程序调用的接口，可称为<strong>UDT API或User API</strong>；User API调用CUDT API，这一层主要用来做错误处理，也就是捕获动作实际执行过程中抛出的异常并保存起来，然后给应用程序使用；CUDT API调用CUDTUnited中API的实现。</p><blockquote><p>“此处可以看到，CUDT提供的这一层API，一个比较重要的作用大概就是做异常处理了。”</p><p>其实这里没有很懂UDT的==设计艺术==，为什么要分三个层次的类，中间那个特别像个中间件，为什么异常处理要单独拎出来。</p></blockquote></li><li><p>bind( )函数<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vMjAxNS8wOS8wOS9VRFQlRTUlOEQlOEYlRTglQUUlQUUlRTUlQUUlOUUlRTclOEUlQjAlRTUlODglODYlRTYlOUUlOTAlRTIlODAlOTQlRTIlODAlOTRiaW5kJUUzJTgwJTgxbGlzdGVuJUU0JUI4JThFYWNjZXB0Lw==">那一章<i class="fa fa-external-link-alt"></i></span>还介绍了UDT的多路复用器CMultiplexer、通道CChannel、发送队列CSndQueue和接收队列CRcvQueue的含义</p><ul><li><p><strong>CChannel</strong></p><blockquote><p>系统UDP socket的一个封装，它主要封装了系统UDP socket handle，IP版本号，socket地址的长度，发送缓冲区的大小及接收缓冲区的大小等信息，并提供了用于操作 系统UDP socket进行数据收发或属性设置等动作的函数。</p></blockquote></li><li><p><input disabled="" type="checkbox">  其实没有很懂多路复用器(Multiplexer)和socket之间的关系 ( 监听端口到底是什么操作？我理解的目前是socketchannel可以实现在一个线程里面监听多个某个端口的状况 ( 是否接收了数据等等 ) 并将更新的情况跟selector ( 也就是多路复用器 ) 交流 ,which会选择让哪个socket去处理这件事情) 、</p></li><li><p>CRcvQueue</p><blockquote><p>在接收队列CRcvQueue的worker线程中，接收到一条消息之后，它会根据消息的目标SocketID，及发送端的地址等信息，将消息以不同的方式进行dispatch</p></blockquote></li></ul></li></ul></li></ul></blockquote></li><li><p><input disabled="" type="checkbox">  这个<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vdWtlcm5lbC9wLzg5NzY5ODQuaHRtbA==">UDT源码剖析<i class="fa fa-external-link-alt"></i></span>系列博客讲得很详细，相当于每个头文件在讲解了</p></li><li><p><span class="exturl" data-url="aHR0cDovL3d3dy53aXNlc3R1ZHkuY24vb3BlbnRlY2gvdWR0LWNvbmdlc3Rpb25Db250cm9sQWxnb3JpdGhtLmh0bWw=">这个博客<i class="fa fa-external-link-alt"></i></span>相当于翻译了udt的论文</p></li><li><p><input disabled="" type="checkbox">  ==CS 224==的那个project是怎么整的 还得看下</p></li><li><p>udt思路及代码分析</p><ul><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cDovL3d3dy53aXNlc3R1ZHkuY24vb3BlbnRlY2gvdWR0LWNvbmdlc3Rpb25Db250cm9sQWxnb3JpdGhtLmh0bWw=">这个<i class="fa fa-external-link-alt"></i></span>里面有代码架构分析</li><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9uZXR3b3JrLjUxY3RvLmNvbS9hcnQvMjAxNDA5LzQ1MTEzOS5odG0=">这个<i class="fa fa-external-link-alt"></i></span>里面有伪代码</li></ul></li><li><p><span class="exturl" data-url="aHR0cHM6Ly91ZHQuc291cmNlZm9yZ2UuaW8vdWR0NC8=">官方提供的reference<i class="fa fa-external-link-alt"></i></span>里面就有api手册  [代码的doc文件里面也可以离线查看]</p></li></ul><h1 id="代码架构"><a href="#代码架构" class="headerlink" title="代码架构"></a>代码架构</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./src:     UDT <span class="built_in">source</span> code </span><br><span class="line">./app:     Example programs </span><br><span class="line">./doc:     UDT documentation (HTML)</span><br><span class="line">./win:     Visual C++ project files <span class="keyword">for</span> the Windows version of UDT </span><br></pre></td></tr></table></figure><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>refer@WolfCS的<span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC93b2xmY3MvYmxvZy81MTIwNjE=">UDT实现分析总结<i class="fa fa-external-link-alt"></i></span></p><ul><li><p><strong>UDT Socket</strong>是UDT中的核心，同时它也是一座桥梁，它将UDT的使用者应用程序与内部实现部分对于数据结构的管理、网络数据的传输连接起来。</p></li><li><p><strong>应用程序通过它</strong>将数据放进发送缓冲待发送，或者借由它来获取从网络接收数据。而与网络进行交互的部分，则从它那里拿到要发送的数据进行发送，或者在收到packet时将packet dispatch给它。</p></li></ul><h3 id="数据接收部分框架"><a href="#数据接收部分框架" class="headerlink" title="数据接收部分框架"></a>数据接收部分框架</h3><img src="http://static.oschina.net/uploads/space/2015/0928/110552_YTa3_919237.jpg" alt="110552_YTa3_919237.jpg" style="zoom: 67%;" /><h3 id="数据发送部分框架"><a href="#数据发送部分框架" class="headerlink" title="数据发送部分框架"></a>数据发送部分框架</h3><img src="http://static.oschina.net/uploads/space/2015/0928/135751_Ftye_919237.jpg" alt="img" style="zoom:67%;" /><h2 id="UDT-socket-structures"><a href="#UDT-socket-structures" class="headerlink" title="UDT socket structures"></a>UDT socket structures</h2><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/25/141253-492288.png" alt="image-20200923200351000" style="zoom: 80%;" /><ul><li><p>socket文件描述符 +  错误码 + UDT socket集合 + TraceInfo ()</p><ul><li><p>TraceInfo , performance的一些数据</p><ul><li><p><strong>aggregate</strong> values</p><ul><li>pktSndLossTotal 和 pktRcvLossTotal的区别？？这个RcvLoss怎么测试呢==？？==</li></ul></li><li><p><strong>local</strong> values since last recorded time</p><blockquote><p>目前理解是一段时间的period算出来的值  ==??不是很确定==</p></blockquote></li><li><p><strong>instant</strong> values at the time they are observed</p></li></ul></li></ul></li></ul><h2 id="UDT-socket-functions"><a href="#UDT-socket-functions" class="headerlink" title="UDT socket functions"></a>UDT socket functions</h2><ul><li>perfmon</li><li>其他的大部i分都跟传统的socket编程的api一致</li></ul><h2 id="CC-Base-Class"><a href="#CC-Base-Class" class="headerlink" title="CC Base Class"></a>CC Base Class</h2><ul><li><p>ccc.h文件定义了父类</p></li><li><p>app/cc.h里面定义了一个基于CCC的拥塞控制方法，是一个good tutorial</p></li><li><p>注意事项</p><ul><li>不要在CCC内部或者它的继承类中调用regular UDT API, 会有未知错误发生</li><li>CCCFactory&lt;…&gt;  是一个C++模板，不需要用类去继承他</li><li>UDT不会立马释放CCCFactory&lt;…&gt;的实例，应该在application类里面释放，只要是在setsockopt（）后就可以</li></ul></li></ul><h1 id="一些中途冒出来的想法"><a href="#一些中途冒出来的想法" class="headerlink" title="一些中途冒出来的想法"></a>一些中途冒出来的想法</h1><p>正如Sigcomm‘2020所示，我们的主机开销也算是延迟的一部分，那么我们的算法的耗时会不会影响整个delay的状况呢 ? </p><h1 id="代码梳理"><a href="#代码梳理" class="headerlink" title="代码梳理"></a>代码梳理</h1><h2 id="UDT部分"><a href="#UDT部分" class="headerlink" title="UDT部分"></a>UDT部分</h2><ul><li><p>跟UDTv4相比，src/core内改动比较大的是</p><ul><li><input disabled="" type="checkbox"> api.cpp</li><li><input disabled="" type="checkbox"> buffer.cpp </li><li><input disabled="" type="checkbox"> core.cpp  改动相当大 ，不仅添加了一些属性，还添加了不少功能</li></ul><blockquote><p> ccc.cpp虽然改动大， 但是本身就是要被继承的，which means没关系</p></blockquote></li></ul><h2 id="PCC"><a href="#PCC" class="headerlink" title="PCC"></a>PCC</h2><h3 id="pcc-sender"><a href="#pcc-sender" class="headerlink" title="pcc_sender"></a>pcc_sender</h3><p>主要是PccSender类，which</p><ul><li><p><strong>functions</strong></p><ul><li><p>触发型</p><ul><li>void OnCongestionEvent (  )</li><li>void OnPacketSent (  )</li></ul></li><li><p>调整型</p><ul><li>QuicBandwidth PacingRate (  )</li><li>QuicTime ComputeMonitorDuration (  )</li><li>QuicTime GetCurrentRttEstimate (  )</li><li>-void UpdateCurrentRttEstimate( )</li><li>-bool ShouldCreateNewMonitorInterval(  )</li><li>-QuicBandwidth UpdateSendingRate</li></ul></li><li><p>总结</p><ul><li>在事件（发包和ack (==目前不确定==这个CongestionEvent是不是ack获得的) ）发生的时候采取一些操作（比如信息统计( RTT估计值 )、调整结构信息）</li><li>调整结构信息<ul><li>sending rate (pacing) 的计算和调整</li><li>MI大小调整 以及 ==创建(??)==新的MI</li><li>RTT</li></ul></li></ul></li></ul></li></ul><ul><li><p><strong>member</strong> </p><ul><li><p>观测值</p><ul><li>avg_rtt_</li><li>sending_rate_</li></ul></li><li><p>工具</p><ul><li>utility_calculator_  （PccUtilityCalculator</li><li>rate_controller_  ( PccRateController<ul><li>rate_control_lock_  (mutex</li></ul></li><li>interval_queue_   （PccMonitorIntervalQueue</li><li>interval_analysis_group_    （PccMonitorIntervalAnalysisGroup、</li></ul></li></ul></li></ul><h3 id="rate-control"><a href="#rate-control" class="headerlink" title="rate-control"></a>rate-control</h3><ul><li><p>在这里面发现了好几个Options的参数</p><ul><li>pypath </li><li>pyhelper ( default : pcc_rate_controller )</li></ul></li><li><p>利用了Python3.5进行了混编</p><ul><li><p><input checked="" disabled="" type="checkbox">  先尝试下能不能换成3.6</p><blockquote><p>坑太多，试到一半放弃了，不然其实是可以的</p></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  不然就开始配环境（对…换了台g8就可以</p></li></ul></li></ul><h1 id="代码疑惑"><a href="#代码疑惑" class="headerlink" title="代码疑惑"></a>代码疑惑</h1><ul><li><p><input disabled="" type="checkbox">  为什么可以不提前声明，也不include。虽然queue.h确实是在之前被编译的，但是这个就不需要指明依赖关系么</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926102437531.png" alt="image-20200926102437531" style="zoom: 50%;" /></li><li><p><input disabled="" type="checkbox">  又用到工厂模式了，可惜我还是不会（ 不过也不是重点，回头看下</p></li><li><p><input disabled="" type="checkbox">  之前master说TCP buffer不需要很大，不停poll就行？？ why ?没有很理解</p></li><li><p><input disabled="" type="checkbox">  用sourceCode整理一下代码结构</p></li></ul><blockquote><p>from aurora test</p></blockquote><hr><ul><li><p><input disabled="" type="checkbox">  sourceCodes 如何处理这么多宏定义的事情…. 一下子理清代码结构还是很重要的（lxg</p></li><li><p>C++特性</p><ul><li><p><input disabled="" type="checkbox">  chrome的Base库对于[]的使用方法  –》 跨平台开发</p><p>zyh给的<span class="exturl" data-url="aHR0cHM6Ly9jaHJvbWl1bS5nb29nbGVzb3VyY2UuY29tL2Nocm9taXVtL3NyYy8rL3JlZnMvaGVhZHMvbWFzdGVyL2Jhc2UvZXhwb3J0X3RlbXBsYXRlLmgjNDA=">link<i class="fa fa-external-link-alt"></i></span>,针对QUIC_EXPORT_PRIVATE，有空学一手</p></li><li><p><input disabled="" type="checkbox">  哪些需要mutex的lock，哪些不需要，比如说为啥RTT更新就不需要</p><p>pcc_sender.cpp里面</p></li><li><p><input disabled="" type="checkbox">  类的explicit到底有什么作用来着…还有=delete之类，还有GCC扩展之类</p></li><li><p><input disabled="" type="checkbox">  这种单独的匿名的namespace意义何在？在pcc_lin_ucalc.cpp</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"><span class="comment">// Coefficeint of the loss rate term in utility function.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">float</span> kLossCoefficient = <span class="number">5.0f</span>;</span><br><span class="line"><span class="comment">// Coefficient of RTT term in utility function.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">float</span> kRttCoefficient = <span class="number">1.0</span>/<span class="number">30000.0f</span>;</span><br><span class="line">&#125;  <span class="comment">// namespace</span></span><br></pre></td></tr></table></figure><p>后面的都不在这个namespace里面，所以是文件里面的可以看到，文件外面的看不到 ?</p></li></ul></li></ul><h1 id="待整理"><a href="#待整理" class="headerlink" title="待整理"></a>待整理</h1><ul><li><input disabled="" type="checkbox"> 函数名的mangle过程<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbGFuZF9TdW4vYXJ0aWNsZS9kZXRhaWxzLzQzMjMzNTY1">这儿<i class="fa fa-external-link-alt"></i></span>讲得特别好 </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ByteComparator.obj : error LNK2019: unresolved external symbol <span class="string">&quot;int __cdecl does_not_exist(void)&quot;</span> (?does_not_exist@@YAHXZ) referenced <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">&quot;void __cdecl TextScan(struct FileTextStats &amp;,char const *,char const *,bool,bool,__int64)&quot;</span> (?TextScan@@YAXAAUFileTextStats@@PBD1_N2_J@Z)</span><br></pre></td></tr></table></figure><ul><li><input disabled="" type="checkbox"> 利用了Python.h进行了混编</li><li>BBR的研究<ul><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvZzI1MC9hcnRpY2xlL2RldGFpbHMvNzIwNDI1MTY=">dog大佬<i class="fa fa-external-link-alt"></i></span>关于BBR的问题剖析，我觉得挺好的，等当前这个demo做完，就看看这个，然后基于BBR改进</li><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cDovL3d3dy5qZWVweGllLm5ldC9hcnRpY2xlLzUxMzQxNy5odG1s">这个<i class="fa fa-external-link-alt"></i></span>讲了BBR ProbeMore的两阶段探测，里面的idea我确实也没有很理解。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>socket编程</title>
      <link href="/Codes/socket%E7%BC%96%E7%A8%8B/"/>
      <url>/Codes/socket%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p>《Linux系统编程、网络编程》第10章 网络编程视频课程 ,which is in my Baidu Cloud</p><blockquote><p>目前看到12了，其他的组会上听吧</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVJKNDExQjc2MS8/c3BtX2lkX2Zyb209MzMzLjc4OC52aWRlb2NhcmQuMQ==">这个b站视频<i class="fa fa-external-link-alt"></i></span>似乎是专门讲Unix网络编程这本书的</p></li><li><p><input disabled="" type="checkbox">  百度云里面存了一个系列视频，我觉得也不错</p></li></ul><blockquote><p> socket通信基础知识</p></blockquote><h1 id="网络编程基础概念"><a href="#网络编程基础概念" class="headerlink" title="网络编程基础概念"></a>网络编程基础概念</h1><ul><li><p>AF_INET ， PF_INET  ， AF_UNIX</p><blockquote><p>AF: address family </p><p>PF: protocol family</p><p>INET指的就是internet ，在网上传输的</p><p>AF_INET（又称 PF_INET）是 IPv4 网络协议的套接字类型，AF_INET6 则是 IPv6 的；而 AF_UNIX 则是 Unix 系统本地通信。</p><p>AF_INET 相比 AF_UNIX 更具通用性，因为 Windows 上有 AF_INET 而没有 AF_UNIX。</p></blockquote></li><li><p>网络编程中的<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9mODExYmZmMTVkZTk=">基本数据结构<i class="fa fa-external-link-alt"></i></span></p><p>都是结构体</p><ul><li><p>sockaddr （旧版本为ipv4设置的</p></li><li><p>sockaddr_storage   // 为了兼容ipv6的 升级版本</p><blockquote><p>用到sockaddr的地方都可以用sockaddr_storage来替代。</p></blockquote></li><li><p>addrinfo //存储地址信息的</p></li><li><p>sockaddr_in &amp; sockaddr_in6</p></li><li><p>sockaddr_in和sockaddr使用上的区别</p><blockquote><p>sockaddr和sockaddr_in包含的数据都是一样的，但他们在使用上有区别：</p><ol><li><p>程序员不应操作sockaddr，sockaddr是给操作系统用的</p><p>程序员应使用sockaddr_in来表示地址，sockaddr_in区分了地址和端口，使用更方便。</p></li><li><p>一般用法是：程序员把类型、ip地址、端口填充sockaddr_in结构体，然后强制转换成sockaddr，作为参数传递给系统调用函数</p></li></ol></blockquote></li></ul></li></ul><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><ul><li>socket就是一个文件描述符，但是没有文件名（Linux有七种文件描述符）</li></ul><h2 id="bind"><a href="#bind" class="headerlink" title="bind( )"></a>bind( )</h2><ul><li>bind ( int sockfd ,  const struct sockaddr *addr , socklen_t addrlen  )</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span>  <span class="keyword">short</span>  sa_family;     <span class="comment">/* address family, AF_xxx */</span></span><br><span class="line">    <span class="keyword">char</span>  sa_data[<span class="number">14</span>];                 <span class="comment">/* 14 bytes of protocol address */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span>  <span class="title">sockaddr_in</span> &#123;</span></span><br><span class="line">    <span class="keyword">short</span> <span class="keyword">int</span> sin_family;              <span class="comment">/* Address family */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">short</span> <span class="keyword">int</span> sin_port;       <span class="comment">/* Port number */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">in_addr</span> <span class="title">sin_addr</span>;</span>           <span class="comment">/* Internet address */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> sin_zero[<span class="number">8</span>];    <span class="comment">/*padding to be the same size as struct sockaddr*/</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>因为sockaddr中直接在char[] 里面写端口和ip比较麻烦，所以用了sockaddr_in, which是分开来记录的</p><blockquote><p>这里sin的意思就是：s代表sockaddr ， in就是sockaddr_in后缀的in的意思</p><p>sin_addr存储的是ipv4的地址 ，acutually就只有32位的 unsigned int ，s_addr 【这个起名真是绕人啊…】</p><p>姑且认为，这里sockaddr_in里面的in代表着是包含在sockaddr内部的</p></blockquote><p>将sockaddr_in强制转换成sockaddr，看到有人这么写：(struct sockaddr*) &amp;sockaddr_in , ==感觉很神奇？不知道理由是什么==</p></li></ul><h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll( )"></a>epoll( )</h2><ul><li><p><strong>epoll的过程</strong></p><ul><li><p>创建红黑树    <strong>epoll_create</strong>( int size)</p><blockquote><p>现在内核已经优化到size写一个大于0的数即可</p></blockquote></li><li><p>向树上增加要监听的文件描述符（已经上树了的就不用再上树了）</p><p><strong>epoll_ctl</strong> ( int epfd,  int op, int fd, struct epoll_event* event )</p><blockquote><p><strong>epfd</strong>  红黑树的根节点</p><p><strong>op</strong> 对红黑树的修改操作</p><pre><code>* EPOLL_CTL_ADD  上树 * EPOLL_CTL_MOD  修改* EPOLL_CTL_DEL 下树 </code></pre><p><strong>fd</strong> 要上树的文件描述符</p><p><strong>event</strong>  要监听该文件描述符的什么操作</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">   <span class="keyword">void</span>    *ptr;</span><br><span class="line">   <span class="keyword">int</span>      fd;</span><br><span class="line">   <span class="keyword">uint32_t</span> u32;</span><br><span class="line">   <span class="keyword">uint64_t</span> u64;</span><br><span class="line">&#125; <span class="keyword">epoll_data_t</span>;  <span class="comment">// 一般就用上面两个</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">   <span class="keyword">uint32_t</span> events; <span class="comment">/*Epoll events,e.g.EPOLLIN,EPOLLOUT(也主要是这两个事件)*/</span></span><br><span class="line">   <span class="keyword">epoll_data_t</span> data;      <span class="comment">/* User data variable */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>细节</strong>：在上树的时候，每个节点既包含了文件描述符fd的信息，又包含了event的信息</p></blockquote></li><li><p>监听节点  <strong>epoll_wait</strong>( int epfd, struct epoll_event *events,int maxevents, int timeout )</p><ul><li>events提供了一个用于存放返回值的数组</li><li>maxevents提供了数组的大小</li><li>返回值是 返回的事件的个数</li></ul></li></ul></li></ul><ul><li><input disabled="" type="checkbox"> epoll反应堆</li></ul><h2 id="setsockopt"><a href="#setsockopt" class="headerlink" title="setsockopt( )"></a>setsockopt( )</h2><ul><li>在创建socket之后，bind之前设定（比如说SO_REUSEADDR）<ul><li>SO_REUSEADDR 端口复用，为何可以端口复用？可以参考下<span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vZW50cnkvNjg0NDkwMzUwOTYyNDY1MTc5MA==">这篇博客<i class="fa fa-external-link-alt"></i></span>提出的理由</li></ul></li></ul><h2 id="tl-dr"><a href="#tl-dr" class="headerlink" title="tl;dr"></a>tl;dr</h2><ul><li><input disabled="" type="checkbox"> ==看完了<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVJKNDExQjc2MT9wPTU2">P56 epoll反应堆<i class="fa fa-external-link-alt"></i></span>==，觉得这个系列视频讲得蛮好的，有空要接着看。</li></ul><h1 id="字节序转换"><a href="#字节序转换" class="headerlink" title="字节序转换"></a>字节序转换</h1><ul><li><p>主机字节序  无论是大端还是小端  本机的字节序就叫主机字节序</p></li><li><p>htonl  这里的l 是long ，32位 ; htons 这里的s是 short ，16位。无论是long还是short ，都是大端的</p><p><strong>htonl</strong> 用于转换ip地址（4个字节）  –》 attention 这里的ip地址是数值形式的（而非点分十进制）</p><p><strong>htons</strong> 用于转换端口号（2个字节）</p><blockquote><p>host to numerical long , host to numerical short</p></blockquote></li><li><p><strong>inet_pton</strong></p><p>将ip地址从点分十进制( point )转换为大端的数值( numerical )形式</p><p><strong>inet_ntop</strong></p></li><li><p>网络编程中尽量都用无符号的 ，不然一不小心出现负值</p></li></ul><h1 id="五大IO模型"><a href="#五大IO模型" class="headerlink" title="五大IO模型"></a>五大IO模型</h1><h2 id="阻塞IO-BIO"><a href="#阻塞IO-BIO" class="headerlink" title="阻塞IO BIO"></a>阻塞IO BIO</h2><p>应用层accept( ) –&gt;  内核recvFrom( <strong>Block</strong>，…  ) 取一个socket</p><p>​            |</p><p>​            V</p><p>应用层read( ) –&gt;内核 recvFrom( <strong>Block</strong>，… ) 取字节流</p><p>​            |</p><p>​            V</p><p>​            ….</p><ul><li>如果accept的时候没有客户端连接上来，那么就卡在这一步，不会往下行进了</li><li>另一方面，如果此时有别的连接进来了，也不会搭理，因为线程阻塞在其中某个步骤中了‘<ul><li>没有办法处理多个客户端连接的情况</li></ul></li></ul><h2 id="非阻塞IO-基于线程驱动模型"><a href="#非阻塞IO-基于线程驱动模型" class="headerlink" title="非阻塞IO   基于线程驱动模型"></a>非阻塞IO   基于线程驱动模型</h2><p>应用层accept( ) –&gt; 内核recvFrom( <strong>nonBlock</strong>，… ) 取一个socket</p><p>​            |</p><p>​            V</p><p>应用层read( ) –&gt; 内核recvFrom( <strong>nonBlock</strong>，… ) 取字节流</p><p>​            |</p><p>​            V</p><p>​            ….</p><ul><li>如果有客户端进来，我可以都处理–&gt;实际上是利用非阻塞的性质，一个函数没有获得结果，我还是可以往下走，keep循环走这个流程</li></ul><h2 id="IO多路复用-NIO-new-IO-基于事件驱动模型"><a href="#IO多路复用-NIO-new-IO-基于事件驱动模型" class="headerlink" title="IO多路复用 NIO new IO   基于事件驱动模型"></a>IO多路复用 NIO new IO   基于事件驱动模型</h2><blockquote><p>New IO是java的一个包，which includes socketChannel,ByteBuffer，Nonblocking IO是Linux操作系统的非阻塞IO</p></blockquote><ul><li>多路复用器 应用层select( ) –&gt; 内核epoll( )</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/26/145842-614824.png" alt="image-20200926145841363"></p><pre><code>* epoll的过程是非阻塞的，但是处理数据的过程是阻塞的（当然还是得遍历，一个一个去处理）* 此外，epoll做了优化，不用把数据从内核空间拷贝到用户空间了，采用内存地址的方式，实现了“零拷贝”</code></pre><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><ul><li><p><strong>channel</strong></p><ul><li><p>BIO读写都是单向的</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926150226860.png" alt="image-20200926150226860" style="zoom:67%;" /><p>但是NIO是双向的（利用channel）</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926151233132.png" alt="image-20200926151233132" style="zoom:67%;" /><p>且在byte数组基础上还包装成了bytebuffer</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY2hlbnBpL3AvNTM3Mjc4Ni5odG1s">bytebuffer与channel的交互<i class="fa fa-external-link-alt"></i></span></p></blockquote></li></ul></li><li><p><strong>selector</strong></p></li></ul><h2 id="NIO-reactor模型-反应堆模型"><a href="#NIO-reactor模型-反应堆模型" class="headerlink" title="NIO reactor模型  反应堆模型"></a>NIO reactor模型  反应堆模型</h2><ul><li>单线程</li><li>多线程</li><li>主从模型</li></ul>]]></content>
      
      
      <categories>
          
          <category> Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gcc链接梳理</title>
      <link href="/Summary/LinkDebug/"/>
      <url>/Summary/LinkDebug/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5MzUwNzYvYXJ0aWNsZS9kZXRhaWxzLzUxMzc0Mzg4">这个博客<i class="fa fa-external-link-alt"></i></span>写的很全</p></li><li><p>程序员的自我修养</p><blockquote><p>相关内容，自己的博客上有总结其中几章</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTAxMTA1NTcz">chapeter 6 可执行文件(.o)及动态链接(.a)的装载与进程<i class="fa fa-external-link-alt"></i></span></p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTAxMTE5Njk2">chapeter 8 Linux共享库(.so)的组织<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>主要讲了一些补充的、正交的 加载相关的环境变量，方便debug编译和链接过程</p></blockquote></li></ul></blockquote></li></ul><h2 id="nm命令-–-查看二进制和符号表的利器"><a href="#nm命令-–-查看二进制和符号表的利器" class="headerlink" title="nm命令  –  查看二进制和符号表的利器"></a>nm命令  –  查看二进制和符号表的利器</h2><blockquote><p>其实还有很多常用的用来读库文件的命令，比如objdump ， readelf ,  这里不过是因为nm比较通用，所以重点介绍一下（其实觉得objdump可以出更多的信息的） </p></blockquote><ul><li><p>nm -g –defined-only libxxx.a # -g 查看外部符号表 ，也是–extern-only</p><blockquote><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/18/224322-528256.png" alt="image-20200918224319703" style="zoom: 67%;" /></blockquote><p>  会把.a文件是从<strong>哪些.o文件</strong>中打包过来以及<strong>对应吸收了哪些符号</strong>都标清楚。</p></li></ul><h2 id="a-libxxxx-a-archive-和-so-libxxxx-so-major-minor-shared-object-的区别"><a href="#a-libxxxx-a-archive-和-so-libxxxx-so-major-minor-shared-object-的区别" class="headerlink" title=".a(libxxxx.a)[archive]和 .so(libxxxx.so.major.minor) [shared object]的区别"></a>.a(libxxxx.a)[archive]和 .so(libxxxx.so.major.minor) [shared object]的区别</h2><h3 id="生成"><a href="#生成" class="headerlink" title="生成"></a><strong>生成</strong></h3><ol><li><p>生成<strong>静态库</strong>使用ar工具，其实ar是archive的意思</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ar cqs libhello.a hello.o</span><br></pre></td></tr></table></figure><p>​    静态库与汇编生成的目标文件一起链接为可执行文件，那么静态库必定跟.o文件格式相似。其实一个静态库可以简单看成是<strong>一组目标文件</strong>（.o/.obj文件）的集合，即很多目标文件经过压缩打包后形成的一个文件。（这里cqs是静态库的名称，别搞混了）</p></li><li><p>生成<strong>动态库</strong>用gcc来完成，由于可能存在多个版本，因此通常指定版本号：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步</span></span><br><span class="line">g++ -fPIC -o DynamicMath.o DynamicMath.cpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步</span></span><br><span class="line">g++ -shared -o libhello.so.1.0 DynamicMath.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合起来就是</span></span><br><span class="line">g++ -fPIC -shared -o libhello.so.1.0 DynamicMath.o.cpp</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>-shared: 表示生成的是动态链接库</p><p>-fPIC: 生成位置独立的代码，用于编译共享库。在任意内存空间都可以被加载</p><p>-Wall: 生成所有警告信息</p><p>前两个是必加的参数，最后一个有时候会加</p></li></ul><h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a><strong>查看</strong></h3><ul><li><p><strong>查看静态库包含了哪些.o文件也很简单</strong>：</p><ul><li><p>nm -g 命令 （上文） 还会列出符号表 </p></li><li><p>ar -t llibxx.a  ( display a <u>table</u> listing contents of the archive )</p><blockquote><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/18/230631-588422.png" alt="image-20200918230630480" style="zoom:67%;" /></blockquote></li></ul></li><li><p>查看<strong>动态库</strong>包含了哪些文件</p><ul><li><p>目前没有找到办法查看，只能使用<strong>nm -D xx.so</strong>的方式去查看动态库的动态符号表</p><ul><li>注意，nm的-D参数只对动态库有效</li></ul></li></ul></li></ul><h3 id="调用-–》被载入的时刻不同-最主要的区别在于此"><a href="#调用-–》被载入的时刻不同-最主要的区别在于此" class="headerlink" title="调用 –》被载入的时刻不同 [最主要的区别在于此]"></a><strong>调用</strong> –》被载入的时刻不同 [<strong>最主要的区别</strong>在于此]</h3><ul><li><p>静态库的代码在编译过程中已经被载入可执行程序，因此体积较大</p></li><li><p>共享库(动态库)的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此代码体积较小。</p></li><li><p>共享库(动态库)的好处是，不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例。【这就是共享库诞生的原因之一，另一点就是静态库需要全量更新，但是动态库只需要增量更新】</p></li></ul><ul><li><p><strong>调用命令</strong> 都是一致的</p><p>gcc -L紧跟目录名字 -l紧跟库名字, e.g. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -o hello main.c -L. -lmyhello</span><br></pre></td></tr></table></figure><blockquote><p>-L表示搜寻库的目录，-I表示依赖库的名称（这里是L的小写，表示lib）。这个应该都知道把…</p><p>-I（这里是i的大写）（inlcude的意思） 这里用不到，但是也经常用，就直接补充下把，是头文件(.h)所在的路径  </p></blockquote><ul><li><p>请注意，==-lxx一定要写在最后面==，因为gcc的命令是从左到右执行的，被依赖项得放在右边，因为是先解析main.c然后看到里面有一些外部的符号，which是在myhello这个库里面的，然后就往右边解析去寻找这个符号</p><ul><li><p>为什么这么做就很明了， 按需取你需要的符号，which means 没必要把整个myhello库都加载进内存或者集成到最终的hello可执行文件中</p></li><li><p>如果有循环依赖( libA.a&lt;–&gt;libB.so )，那么也要反复写依赖库， which means要写成gcc -IA -IB -IA</p></li></ul></li><li><blockquote><p>gcc -lmath -c test.cc -o test.o  <strong>[ x ]</strong><br>gcc -c test.cc -o test.o -lmath  <strong>[ √ ]</strong></p></blockquote></li><li><p>动态静态库都存在的时候，优先使用.so文件（毕竟动态库开销小、跨平台）</p><blockquote><p>如果想链接的就是动态库的话，就用如下参数：-WI,-Bstatic</p><p>关于WI参数和Bstatic的用法，可以参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzIyOTQwMDQ4">这个回答<i class="fa fa-external-link-alt"></i></span></p><p>进一步，使用WI指定链接的soname可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmdfaHVmZW5nL2FydGljbGUvZGV0YWlscy81Mzg5OTEyMA==">这个<i class="fa fa-external-link-alt"></i></span></p></blockquote></li><li><p>动态库链接和运行时加载的过程是分开的，所以有时候链接的时候成功了，但是运行起来还是会报找不到符号表的错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-LsoLibPath  <span class="comment"># 链接时的路径</span></span><br><span class="line">-WI,rpath=soLibPath  <span class="comment"># 链接时指定的参数，用于运行时加载的路径</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="链接时的默认搜索顺序、搜索路径"><a href="#链接时的默认搜索顺序、搜索路径" class="headerlink" title="链接时的默认搜索顺序、搜索路径"></a>链接时的默认搜索顺序、搜索路径</h3><h4 id="静态库"><a href="#静态库" class="headerlink" title="静态库"></a>静态库</h4><p>搜索顺序：</p><ol><li><p>GCC命令中的参数 -L</p><ol start="2"><li>gcc的环境变量LIBRARY_PATH</li><li>内定目录 /lib /usr/lib /usr/local/lib 这是当初compile gcc时写在程序内的</li></ol></li></ol><h4 id="动态库"><a href="#动态库" class="headerlink" title="动态库"></a>动态库</h4><ol><li><p>GCC命令中的参数 -L</p></li><li><p>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</p></li><li><p>配置文件/etc/ld.so.conf中指定的动态库搜索路径</p></li><li><p>默认的动态库搜索路径 /lib 和 /usr/lib</p><blockquote><p>/lib 或 /usr/lib（64位系统下为/lib64 /usr/lib64）路径下的共享库比较特殊。 </p><p>a) 它是默认的共享库的搜索路径。 </p><p>b) 它没有放到/etc/ld.so.conf 文件中。但是在/etc/ld.so.cache 的缓存中有它。 </p><p>c) 其路径下的共享库的变动<strong>即时生效</strong>，不用执行ldconfig。就算缓存ldconfig -p 中没有，新加入的动态库也可以执行。</p></blockquote></li></ol><h3 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h3><ul><li>其实会发现，路径的配置都是遵循着一个从小到大，从内到外的顺序（就跟局部变量和全局变量一样）</li></ul><h2 id="ldconfig"><a href="#ldconfig" class="headerlink" title="ldconfig"></a>ldconfig</h2><p>==注意，这是针对<strong>动态库</strong>的<strong>加载时路径</strong>的配置，<strong>和编译的路径无关</strong>==</p><ul><li><p>/etc/ld.so.conf 是指定动态库搜索路径的一个配置文件</p><blockquote><p>一般cat出来，里面的内容就是：<code>include /etc/ld.so.conf.d/*.conf</code></p><p>这意味着，具体的动态库搜索路径还是由/etc/ld.so.conf.d里面的conf文件决定，简单看下这个文件夹里面有些什么：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/24/172716-465653.png" alt="image-20200924172715424"></p></blockquote></li><li><p>/etc/ld.so.conf.d</p><p>简单看下这个文件夹里面有些什么：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/24/172716-465653.png" alt="image-20200924172715424"></p><p>实际上这是各个安装文件在安装时会自带的config文件，所有的配置集合最终会在ldconfig.so.cache里面存放</p><p>所以<strong>一般安装完一个文件</strong>，都会在ldconfig.so.conf.d文件夹里面更新相应的xx.config文件，这时候<strong>要使用ldconfig命令进行对ldconfig.so.cache文件的更新</strong>，which work according to ldconfig.so.conf , which will traverse ldconfig.so.d recursively to get the *.so/*.a files and record into teh cache file.</p></li><li><p>程序运行时加载库的时候，最终就是从<strong>ldconfig.so.cache</strong>这个文件里面去找</p><blockquote><p>这是一个二进制文件，没法直接查看，但是可以通过ldconfig -p去查看</p></blockquote></li><li><p><strong>ldconfig</strong></p><ul><li><p>当把库安装在/lib或者/usr/lib等默认的搜索路径以后，需要手动修改ld.so.conf文件添加对应路径，然后再调用ldconfig去更新cache文件</p><ul><li>注意，有root权限才可以修改ld.so.conf以及调用ldconfig进行对/etc/ldconfig.so.cache的更新</li></ul></li><li><p>没有root权限的时候就是采用修改环境变量LD_LIBRARY_PATH的方式 或者 编译时候添加参数( -WI,rpath=xxx )  </p><blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rpath</span> <span class="string">-- running path</span></span><br><span class="line"><span class="attr">Wl</span> <span class="string">的l 代表的是把后面的数传递给链接器(ld) </span></span><br></pre></td></tr></table></figure></blockquote><ul><li>注意，添加-L编译参数的方法属于链接路径，ldconfig管的是加载时路径，这两个不要混肴了</li><li>-WI参数和-Xlinker参数的区别可以看<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcmlja3lrL3AvNDE4NjkwMi5odG1s">这个博客<i class="fa fa-external-link-alt"></i></span></li></ul></li><li><p>其他参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ldconfig -p 查看共享库的缓存内容 ( <span class="built_in">print</span> ld.config.cache )</span><br><span class="line">ldconfig -n 在当前文件夹下创建软链接，后面编译链接的时候还得加个-L路径参数指向这个文件夹</span><br><span class="line">ldconfig主要的作用是根据/etc/ld.so.conf 的内容，查找内容中所包含目录下实际的动态库文件，生成搜索共享库的缓存文件/etc/ld.so.cache</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="小心得"><a href="#小心得" class="headerlink" title="小心得"></a>小心得</h3><ul><li><p>安装完新的库之后，不管三七二十一，ldconfig一下</p></li><li><p>一开始我很好奇为什么要引入一个/etc/ld.so.cache，搞得那么麻烦。看到有资料是这么说的：</p><blockquote><p>linux下的共享库机制采用了类似于高速缓存的机制，将库信息保存在/etc/ld.so.cache里边</p></blockquote></li></ul><h2 id="ldd-ld-dependency"><a href="#ldd-ld-dependency" class="headerlink" title="ldd (ld dependency)"></a>ldd (ld dependency)</h2><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2RkYWkvcC8xMDM5NzUxMC5odG1s">ldd原理介绍<i class="fa fa-external-link-alt"></i></span> （最下方） </li></ul><p>例子：</p><p>ldd /usr/bin/passwd  得到返回：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NTP-slave:/usr/<span class="built_in">local</span>/openssl/lib </span><br><span class="line">linux-vdso.so.1 =&gt;  (0x00007fff15dff000)</span><br><span class="line">libpam.so.0 =&gt; /lib64/libpam.so.0 (0x00007fce5eb4b000)</span><br><span class="line">libldap-2.4.so.2 =&gt; /usr/lib64/libldap-2.4.so.2 (0x00007fce5e901000)</span><br><span class="line">        ...省略...</span><br><span class="line">libcrypto.so.0.9.8 =&gt; /usr/lib64/libcrypto.so.0.9.8 (0x00007fce5cefc000)</span><br><span class="line">/lib64/ld-linux-x86-64.so.2 (0x00007fce5f1a3000)</span><br><span class="line">libz.so.1 =&gt; /lib64/libz.so.1 (0x00007fce5cce5000)</span><br></pre></td></tr></table></figure><p>第一列：程序需要依赖什么库<br>第二列: 系统提供的与程序需要的库所对应的库<br>第三列：库加载的开始地址</p><p>通过上面的信息，我们可以得到以下几个信息：<br>1.通过对比第一列和第二列，我们可以分析程序需要依赖的库和系统实际提供的，是否相匹配<br>2.通过观察第三列，我们可以知道在当前的库中的符号在对应的进程的地址空间中的开始位置<br>如果依赖的某个库找不到，通过这个命令可以迅速定位问题所在</p><ul><li>是一个脚本而不是程序</li></ul><h1 id="待整理"><a href="#待整理" class="headerlink" title="待整理"></a>待整理</h1><ul><li><p><span class="exturl" data-url="aHR0cDovL3d3dy5qZWVweGllLm5ldC9hcnRpY2xlLzg4NDU2MC5odG1s">符号表的含义<i class="fa fa-external-link-alt"></i></span>  &amp; <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbGl1eWFueWd6L3AvNTUzNjYwNy5odG1s">还有这个<i class="fa fa-external-link-alt"></i></span></p><ul><li><p>mangle</p><blockquote><p>恢复mangle后的函数名称使用<strong>c++filt</strong>命令即可,e.g.</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200925114818204.png" alt="image-20200925114818204" style="zoom: 80%;" /></blockquote></li><li><p>U是未定义，which means 是调用外界的函数（在其它库中定义的），T(位于text section)表示函数是当前库中定义的，W(weak)类是当前库中定义，被其它库中的函数覆盖），B(位于bss section)</p></li><li><p>nm -n 按照地址排列符号 （–numeric sort )</p></li><li><p>nm -u 打印未定义符号 （ldd -r xx.so 也可以）</p></li></ul></li><li><p><input checked="" disabled="" type="checkbox">  终于明白了为什么makefile里面有的地方不需要.h，有的地方需要了</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/14ac540fae3bfde3bbaa6b7025ac4d365650fa7f/image4typora/202010/05/000501-970705.png"/><p>​    写在依赖里面是为了及时的更新，是makefile的特性，跟gcc和g++的命令无关。本身cc -E 里面就会处理头文件的事情，which means 头文件不需要我们手动去指定依赖，其实代码里面写的很清楚了，编译器是知道的，而且结果很明显，确实是知道的（详见阮一峰的博客：<span class="exturl" data-url="aHR0cDovL3d3dy5ydWFueWlmZW5nLmNvbS9ibG9nLzIwMTQvMTEvY29tcGlsZXIuaHRtbA==">编译器的工作过程<i class="fa fa-external-link-alt"></i></span>中的“第五步 预处理”的剖析）</p></li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input disabled="" type="checkbox">  静态链接和动态链接都是ld么</p><blockquote><p>目前我的理解是：</p><p>ld是静态链接器，动态链接器实际上是ld-linux.so（ 具体看机子</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Compilation and Link </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Summary of makefile</title>
      <link href="/Summary/makeFileSummary/"/>
      <url>/Summary/makeFileSummary/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvaW50cm9kdWN0aW9uLmh0bWw=">陈皓：跟我一起写makefile<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="others-拓展"><a href="#others-拓展" class="headerlink" title="others[拓展]"></a>others[拓展]</h2><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9jb29sc2hlbGwuY24vYXJ0aWNsZXMvMzc5MC5odG1s">陈皓：如何调试MAKEFILE变量<i class="fa fa-external-link-alt"></i></span><ul><li>makefile中的origin函数 等等， 在这里又介绍了几个自带的函数</li><li>陈皓自己写了个用于debug的mk</li><li>make的f参数，指定特定名称的文件，多个参数一起用，会连接起来传递给程序一起执行</li><li>还附上了一个remake tool的教程，which tl;dr ，以后再说吧</li></ul></li></ul><h1 id="basis"><a href="#basis" class="headerlink" title="basis"></a>basis</h1><ul><li><p>Makefile里主要包含了五个东西：显式规则、隐晦规则(自动推导)、变量定义、文件指示(makefile里面包含别的makefile 以及 其他一些规则)和注释(#)</p></li><li><p>Makefile最灵魂的东西就是：</p></li><li><p>如果目标(<target>)不存在 <strong>或者</strong> prerequisites的日期新于目标，就执行相应的command</p></li><li><p>make的<strong>工作方式</strong></p>  <figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GNU的make工作时的执行步骤如下：（想来其它的make也是类似）</span><br><span class="line"><span class="number">1.</span> 读入所有的Makefile。</span><br><span class="line"><span class="number">2.</span> 读入被include的其它Makefile。</span><br><span class="line"><span class="number">3.</span> 初始化文件中的变量。</span><br><span class="line"><span class="number">4.</span> 推导隐晦规则，并分析所有规则。</span><br><span class="line"><span class="number">5.</span> 为所有的目标文件创建依赖关系链。</span><br><span class="line"><span class="number">6.</span> 根据依赖关系，决定哪些目标要重新生成。</span><br><span class="line"><span class="number">7.</span> 执行生成命令。</span><br></pre></td></tr></table></figure><ul><li>两个阶段<ul><li>lazy展开（有点python的意思</li></ul></li></ul></li></ul><h2 id="trivial-points"><a href="#trivial-points" class="headerlink" title="trivial points"></a>trivial points</h2><ul><li>.PHONY 伪目标<ul><li>clean命令放最后，因为最前的是默认的总目标</li><li><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvcnVsZXMuaHRtbA==">伪目标的巧用<i class="fa fa-external-link-alt"></i></span> –》 [ 单独一个make可以work的原理 ]</li></ul></li><li>命令前的小减号 , 出现错误只会弹警告，然后继续运行，不会退出  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-include &lt;filename&gt;   <span class="comment"># 找不到就不用找了</span></span><br><span class="line">-rm edit $(objects)   <span class="comment"># 删除失败就就继续执行吧</span></span><br></pre></td></tr></table></figure></li><li><strong>自动推导</strong> [隐晦规则]<br>  在生成xx.o的过程中可以省去gcc -c xx.c的命令</li><li><strong>另类风格</strong><br>  文件依赖关系会显得有点凌乱，但是会让makefile变得简单<br>  简而言之，就是一个xx.o可以在多行的左边出现</li><li>make -f / make –file 指定除了makefile 和Makefile以外的别的命名方式</li><li>寻找别的makefile的目录<ul><li>系统缺省的目录</li><li>-I / –include-dir 指定的目录</li><li>VPATH变量 &amp; 更灵活的vpath （in whose pattern我们应该用%而不是*的通配符），目录之间使用冒号(:)分隔</li><li>环境变量MAKEFILES<ul><li>不建议使用</li></ul></li></ul></li></ul><h2 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h2><ul><li>一般来说，make会以UNIX的标准Shell，也就是 /bin/sh 来执行命令。</li><li>命令要缩进(tab)</li></ul><h1 id="书写命令"><a href="#书写命令" class="headerlink" title="书写命令"></a>书写命令</h1><blockquote><p>每条规则中的命令和操作系统Shell的命令行是一致的。make会<strong>按顺序一条一条的执行命令会</strong>，每条命令的开头必须以 Tab 键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。</p></blockquote><ul><li><p>注意点！</p><ul><li>如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就<strong>不能把这两条命令写在两行上</strong>，而应该把这两条命令写在一行上，用分号分隔</li></ul></li><li><p>全局参数</p><ul><li>debug<ul><li>–just-print / -n</li><li>-s / –silent / –quiet</li></ul></li><li>-i / –ignore-errors<ul><li>.IGNORE为目标的规则 是另一种级别的防止命令出错的方式</li></ul></li><li>-k / –keep-going</li><li>-w / –print-directory<ul><li>-C 的时候自动打开-w</li><li>-s的时候-w总是失效的</li></ul></li></ul></li></ul><h2 id="嵌套执行make"><a href="#嵌套执行make" class="headerlink" title="嵌套执行make"></a>嵌套执行make</h2><ul><li>总控Makefile , subsystem</li><li>变量传递<ul><li>传递变量到下层用export<ul><li>后面什么都不跟，表示传递所有的变量</li></ul></li><li>SHELL 和 MAKEFLAGS 不管你是否export，其总是要传递到下层 Makefile中<ul><li>MAKEFLAGS如果是自己定义的，得确保其中的选项是大家都会用到的。如果其中有 -t , -n 和 -q 参数，容易出现让人意想不到的结果</li></ul></li><li>make命令中的有几个参数并不往下传递</li><li>不想往下层传递参数的话：<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">subsystem:</span></span><br><span class="line">cd subdir &amp;&amp; <span class="variable">$(MAKE)</span> MAKEFLAGS=</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="命令包"><a href="#命令包" class="headerlink" title="命令包"></a>命令包</h2><ul><li>调用的时候和调用变量一样的方式  </li></ul><h1 id="条件判断和函数"><a href="#条件判断和函数" class="headerlink" title="条件判断和函数"></a>条件判断和函数</h1><h2 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h2><ul><li><p>格式</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;conditional-directive&gt;</span><br><span class="line">&lt;text-if-true&gt;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&lt;text-if-false&gt;</span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><ul><li><p>ifeq &amp; ifneq</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ifeq</span> (&lt;arg1&gt;, &lt;arg2&gt;)</span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> <span class="string">&quot;&lt;arg2&gt;&quot;</span></span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; <span class="string">&quot;&lt;arg2&gt;&quot;</span>        </span><br></pre></td></tr></table></figure></li><li><p>ifdef &amp; ifndef</p><ul><li>ifdef只是测试一个变量是否有值，其并不会把变量扩展到当前位置。*</li></ul></li></ul></li><li><p>注意点<br>  <strong>make是在读取Makefile时就计算条件表达式的值</strong>，并根据条件表达式的值来选择语句，所以，不要把自动化变量（如 $@ 等）放入条件表达式中，因为<strong>自动化变量是在运行时才有的</strong>。</p></li></ul><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(&lt;function&gt; &lt;arguments&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>$(subst <from>,<to>,<text>)</p></li><li><p>$(patsubst <pattern>,<replacement>,<text>)</p><ul><li>顾名思义，不是text上的substitution了，而是pattern上的substitution</li><li>和变量替换的作用一样<blockquote><p>$(objects:.o=.c) 和 $(patsubst %.o,%.c,$(objects)) 是一样的。</p></blockquote></li></ul></li><li><p>$(strip <string>)</p></li><li><p>$(findstring <find>,<in>)</p></li><li><p>$(filter &lt;pattern…&gt;,<text>)</p></li><li><p>$(filter-out &lt;pattern…&gt;,<text>)</p></li><li><p>$(sort <list>)</p></li><li><p>$(word <n>,<text>)</p></li><li><p>$(wildcard PATTERN…) </p><ul><li><strong>在Makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。这种情况下如果需要通配符有效，就需要使用函数“wildcard”</strong>。<blockquote><p>在Makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。需要注意的是：这种情况下规则中通配符的展开和上一小节匹配通配符的区别。</p></blockquote></li></ul></li><li><p>循环 $(foreach <var>,<list>,<text>)</p></li><li><p>判断 $(if <condition>,<then-part>)   /  $(if <condition>,<then-part>,<else-part>)</p></li><li><p>shell函数</p><blockquote><p>注意，这个函数会新生成一个Shell程序来执行命令，所以你要注意其运行性能，如果你的Makefile中有一些比较复杂的规则，并大量使用了这个函数，那么对于你的系统性能是有害的。特别是Makefile的隐晦的规则可能会让你的shell函数执行的次数比你想像的多得多。<br>… <span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvcnVsZXMuaHRtbA==">tl;dr<i class="fa fa-external-link-alt"></i></span></p></blockquote></li></ul><h1 id="书写规则"><a href="#书写规则" class="headerlink" title="书写规则"></a>书写规则</h1><ul><li>最重要的是 依赖关系 &amp; 生成目标的方法</li><li>通配符<ul><li>~ , * , ?</li><li>在目标和命令中都可以用</li></ul></li><li>多目标</li><li>静态模式语法  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;targets ...&gt; : &lt;target-pattern&gt; : &lt;prereq-patterns ...&gt;</span><br><span class="line">    &lt;commands&gt;</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><ul><li>e.g.  <target-pattern> like %.o , <prereq-pattern> like %.c</li><li>注意，这里<target-pattern> 和<prereq-pattern> 都是一个集合，所以后面的 $&lt; 表示第一个依赖文件，会<strong>依次</strong>取出这个集合里面的所有文件</li><li>example<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">objects = foo.o bar.o</span><br><span class="line"><span class="section">all: <span class="variable">$(objects)</span></span></span><br><span class="line"><span class="variable">$(objects)</span>: %.o: %.c</span><br><span class="line">    <span class="variable">$(CC)</span> -c <span class="variable">$(CFLAGS)</span> <span class="variable">$&lt;</span> -o <span class="variable">$@</span> </span><br></pre></td></tr></table></figure></li></ul></li><li>自动生换成依赖性  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cc -M xx.cc </span><br><span class="line">cc -MM xx.cc </span><br></pre></td></tr></table></figure><ul><li>与源代码解耦合的方法  <ul><li>.d文件包含.c文件的依赖</li><li>makefile配置生成.d文件，然后再包含这些.d文件</li></ul></li></ul></li></ul><h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><ul><li><p>命名规则</p><blockquote><p>传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。<br>可以是数字开头的</p></blockquote></li><li><p>调用</p><ul><li>${} 与 $() </li><li>也可以不加括号，但是加上比较安全</li></ul></li><li><p>定义 &amp; 赋值</p><ul><li><p>= </p><ul><li>右边可以是目前未定义变量</li><li>小心递归定义</li><li>避免在变量中使用函数,whcih 比较增大开</li></ul></li><li><p>:=</p><ul><li>只可以用前面定义好了的 ，所以比较安全</li></ul></li><li><p>#的用法：表示变量定义的中止</p><ul><li><p>正例</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nullstring :=</span><br><span class="line">space := <span class="variable">$(nullstring)</span> <span class="comment"># end of the line</span></span><br></pre></td></tr></table></figure><blockquote><p>nullstring是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。</p></blockquote></li><li><p>反例</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dir := /foo/bar    <span class="comment"># directory to put the frobs in</span></span><br></pre></td></tr></table></figure><blockquote><p>dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这样变量来指定别的目录——“$(dir)/file”那么就完蛋了。</p></blockquote></li><li><p>个人想法<br>  何必呢。直接回车换行，也不用#不是很好。不过也可能一方面是为了方便阅读，另一方面也是显式定义，防止不小心打了空格啥的没有看见</p></li><li><p>?=<br>  如果之前没定义过，就赋值，否则就omit</p></li></ul></li></ul></li></ul><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><h3 id="变量值替换"><a href="#变量值替换" class="headerlink" title="变量值替换"></a>变量值替换</h3><ul><li>$(var:a=b) 或 ${var:a=b}<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:.o=.c)</span><br></pre></td></tr></table></figure>另一种也能完成变量替换的级数就是 “静态模式”<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:%.o=%.c)</span><br></pre></td></tr></table></figure></li></ul><h3 id="变量值再当作变量"><a href="#变量值再当作变量" class="headerlink" title="变量值再当作变量"></a>变量值再当作变量</h3><ul><li><p>用法</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = y</span><br><span class="line">y = z</span><br><span class="line">a := $(<span class="variable">$(x)</span>)</span><br></pre></td></tr></table></figure><ul><li>这个知识点主要要明确的就是，是“x=y”，而不是“x=$(y)”,如果没有$,关于y的值不会自动解开来赋值给x的</li></ul></li><li><p>使用多个变量来组成一个变量的名字，然后再取其值</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">first_second = Hello</span><br><span class="line">a = first</span><br><span class="line">b = second</span><br><span class="line">all = $($a_$b)</span><br></pre></td></tr></table></figure><blockquote><p>这个例子中，如果 $(a1) 的值是“a”的话，那么， $(sources) 的值就是“a.c b.c c.c”；如果 $(a1) 的值是“1”，那么 $(sources) 的值是“1.c 2.c 3.c”。<br>所以配合条件句使用特别好</p></blockquote></li><li><p>也可以放在左值中</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(dir)</span>_sources := <span class="variable">$(<span class="built_in">wildcard</span> <span class="variable">$(dir)</span>/*.c)</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="多行变量"><a href="#多行变量" class="headerlink" title="多行变量"></a>多行变量</h3><ul><li><p>利用原理：因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以 Tab 键开头，那么make 就不会把其认为是命令。</p></li><li><p>格式</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">define</span> two-lines</span><br><span class="line">echo foo</span><br><span class="line">echo <span class="variable">$(bar)</span></span><br><span class="line"><span class="keyword">endef</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="overridd"><a href="#overridd" class="headerlink" title="overridd"></a>overridd</h3><p>如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 覆盖外部命令行的定义</span></span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; = &lt;value&gt;;</span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; := &lt;value&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 追加覆盖方式</span></span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; += &lt;more text&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多行变量的覆盖</span></span><br><span class="line"><span class="keyword">override</span> <span class="keyword">define</span> foo</span><br><span class="line">bar</span><br><span class="line"><span class="keyword">endef</span></span><br></pre></td></tr></table></figure><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><ul><li>优先考虑文件中的，但是如果有make -e的参数，就优先考虑e(nvironment)的变量</li></ul><h2 id="目标变量-Target-specific-Variable"><a href="#目标变量-Target-specific-Variable" class="headerlink" title="目标变量 Target-specific Variable"></a>目标变量 Target-specific Variable</h2><ul><li><p>变量分类</p><ul><li>全局变量<br>  整个文件，我们都可以访问这些变量</li><li>自动化变量<br>  如 $&lt; 等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义</li><li>目标变量<br>  可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值</li></ul></li><li><p>这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">prog : CFLAGS = -g</span><br><span class="line">prog : prog.o foo.o bar.o</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.o foo.o bar.o</span><br><span class="line"></span><br><span class="line">prog.o : prog.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.c</span><br><span class="line"></span><br><span class="line">foo.o : foo.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> foo.c</span><br><span class="line"></span><br><span class="line">bar.o : bar.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> bar.c</span><br></pre></td></tr></table></figure><p>在这个示例中，不管全局的 $(CFLAGS) 的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则）， $(CFLAGS) 的值都是 -g</p></li><li><p>语法</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;target ...&gt; : &lt;variable-assignment&gt;;</span><br><span class="line">&lt;target ...&gt; : overide &lt;variable-assignment&gt;</span><br></pre></td></tr></table></figure><p><variable-assignment>;可以是前面讲过的各种赋值表达式，如 = 、 := 、 += <code>或是</code>?= 。第二个语法是针对于make命令行带入的变量，或是系统环境变量。</p></li></ul><h2 id="模式变量-Pattern-specific-Variable"><a href="#模式变量-Pattern-specific-Variable" class="headerlink" title="模式变量 Pattern-specific Variable"></a>模式变量 Pattern-specific Variable</h2><ul><li>其实没有很懂 如何 定义到<strong>模式</strong>上，还要<span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvdmFyaWFibGVzLmh0bWw=">回来<i class="fa fa-external-link-alt"></i></span>再看下</li></ul><h2 id="自动化变量"><a href="#自动化变量" class="headerlink" title="自动化变量"></a>自动化变量</h2><h2 id="特殊变量"><a href="#特殊变量" class="headerlink" title="特殊变量"></a>特殊变量</h2><ul><li>${MAKELEVEL}</li><li>${MAKE}<ul><li>代替make命令本身，在递归调用子文件中的makefile的时候，不能出现make本身(否则会陷入无穷的递归)，应该使用${MAKE}</li><li><span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjIwNjEyOC9ob3ctdG8tY2FsbC1tYWtlZmlsZS1mcm9tLWFub3RoZXItbWFrZWZpbGU=">refer<i class="fa fa-external-link-alt"></i></span></li><li>经常和-C参数一起使用，代表进入一个目录后使用make命令<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    cd subdir &amp;&amp; <span class="variable">$(MAKE)</span> <span class="comment"># 注意，这两行命令不能分开写</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  与上面的作用是一致的</span></span><br><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C subdir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更进一步，我想要执行特定的命令(比如clean)</span></span><br><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C subdir clean</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="关于各种赋值符号的小总结"><a href="#关于各种赋值符号的小总结" class="headerlink" title="关于各种赋值符号的小总结"></a>关于各种赋值符号的小总结</h2><ul><li>=</li><li>:=</li><li>?=</li><li>+=</li></ul><h1 id="隐含规则"><a href="#隐含规则" class="headerlink" title="隐含规则"></a>隐含规则</h1><h2 id="basis-1"><a href="#basis-1" class="headerlink" title="basis"></a>basis</h2><ul><li>如果没有写.o文件的生成规则，默认就会调用如下规则:把 .o 的目标的依赖文件置成 .c ，并使用C的编译命令 cc –c $(CFLAGS)  foo.c 来生成 foo.o 的目标</li><li>隐含规则可能优先于别的规则被使用，因为隐含规则也有分优先级</li><li>模式的隐含规则，只不过是规则中要有 % 罢了</li></ul><h2 id="自动化变量-1"><a href="#自动化变量-1" class="headerlink" title="自动化变量"></a>自动化变量</h2><ul><li><p>扩展时会一个个文件取出</p><ul><li><p>$@</p></li><li><p>$%</p></li><li><p>$&lt;</p></li><li><p>$*</p><blockquote><p>$* 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$* 就表示 f1。</p><p>这里陈皓的一起来写makefile里面写错了</p></blockquote></li></ul></li><li><p>返回文件列表</p><ul><li><p>$?<br>  <strong>比较有用</strong></p><blockquote><p>所有比目标新的依赖目标的集合。以空格分隔。</p></blockquote></li><li><p>$^</p><blockquote><p>所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。</p></blockquote></li><li><p>$+</p><blockquote><p>所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。</p></blockquote></li></ul></li></ul><h2 id="本章节尾部tl-dr"><a href="#本章节尾部tl-dr" class="headerlink" title="本章节尾部tl;dr"></a><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvaW1wbGljaXRfcnVsZXMuaHRtbCM=">本章节尾部<i class="fa fa-external-link-alt"></i></span>tl;dr</h2><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input checked="" disabled="" type="checkbox">  手写makefile不是很麻烦？没有自动的么？like cmake</p><blockquote><p>autotools（常见的./configure文件就是autotools生成的）和 cmake （cmakelist） 都是用于自动生成makefile的</p></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  := 和 = 的区别</p><blockquote><p>后者可以使用未定义(但是后文定义了的)变量，但是前者不可以（所以更安全）</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vd2FycmVuLXdvbmcvcC8zOTc5MjcwLmh0bWw=">Makefile中*和%的区别<i class="fa fa-external-link-alt"></i></span></p></li><li><p><input checked="" disabled="" type="checkbox">  CPPFLAGS 和 CXXFLAGS 的区别</p><blockquote><p>前者是C预处理器的参数（PP代表preprocessing），后者是C++的语言编译器</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Compilation and Link </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic TCP Initial Windows and Congestion Control Schemes through Reinforcement Learning(JSAC&#39;19)</title>
      <link href="/PaperReading/TCP-RL/"/>
      <url>/PaperReading/TCP-RL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li><p>三个challenge（①如何仅在web服务器侧上测response time②如何建模③如何在大规模的解空间中求解）</p></li><li><p>建模reward的时候的两个目标（①体现IW对网络的影响②保障公平性）</p></li><li><p>虽然是个Non-stationary的环境（这篇文章指出且承认了），但是已有现有算法能比较好地去解决这个问题。</p></li></ul><blockquote><p>==我觉得non-stationary可以做一篇，stationary又可以做一篇2333==</p></blockquote><ul><li>其实我觉得这篇文章建模已经很好且优美了，但还是得跳出来想想缺点在哪儿，如何改进或者做出改变.</li></ul><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><ul><li><p>三个challenge对应三个contribution    </p><ul><li><p>【实际可部署性】测量</p><ul><li>不需要<strong>客户端</strong>或者中间件做任何改动 [ 惊了 ]</li></ul><blockquote><p>为了解决挑战一，TCP-RL 修改了前端服务器的 Linux 内核代码和 Web Server 应用 Nginx的代码，使得服务器能够测量并且实时输出每条用户请求的 TCP 流信息(比如网络传输延迟、丢包率、RTT 等)。整个过程在服务器端完 成，不需要客户端或者中间件做任何改动。该数据采集和测量的工具不仅仅可以用于初始窗口的调整，也可用于 Web 服务的网络性能指标管理、监控、 故障诊断。</p></blockquote></li><li><p>【建模】建模的问题（网络是个环境高度变化的场景，且我们的短流场景，是一个非连续的网络条件。另一方面，如果以一条流为一个对象，我们的训练数据也不够）</p><blockquote><p>==我觉得这段分析得特别好==</p></blockquote></li><li><p>【求解】问题求解的复杂度上</p><p>滑动窗口从大规模的决策空间中快速收敛</p><blockquote><p>==但没有给出为什么或者一个比较intuitive的解释…==</p></blockquote></li></ul></li></ul><h1 id="2-background"><a href="#2-background" class="headerlink" title="2 background"></a>2 background</h1><ul><li><p>web services中什么是TCP response time</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/215205-808235.png" alt="image-20201208215203516" style="zoom:67%;" /><p>用T<del>4</del>去estimateT<del>1</del>, 两个都是小的ack数据包</p><p>T2主要是web service provider的情况，所以我们重点考虑的是T<del>1</del>+T<del>3</del> –&gt; TCP response time, which 在计算中就是T4+T5, 也就是用T<del>end</del> - T<del>start</del></p></li><li><p>然后给出了具体场景，where IW 大也不好，小也不好</p></li></ul><h1 id="3-core-Ideas-and-system-overview"><a href="#3-core-Ideas-and-system-overview" class="headerlink" title="3 core Ideas and system overview"></a>3 core Ideas and system overview</h1><blockquote><p>如§I所述，最佳的IW由客户端服务器端到端链接的网络条件（例如，可用带宽和RTT）确定，但是网络条件在时间和空间上都高度可变。 为了应对网络条件的可变性，我们提出了一种自下而上的方法来对来自具有相同网络功能的用户（例如，子网，ISP，省）的流量进行分组，以找到最细粒度的用户组，它们都具有足够的样本 并满足RL上下文连续性要求。</p><p>一方面，使用RL方法自然可以应对网络条件的时间变化。 即RL的目的是为特定用户组的每个给定网络条件找到最佳的IW，并动态适应该用户组的最新网络条件。</p><p>另一方面，用户分组用于处理网络条件的空间变异性。 我们的直觉是，对于给定时间的给定服务器，用户的网络功能（即子网，ISP，省）在很大程度上决定了客户端-服务器端到端链接的网络状况。 如果我们为网络条件相似的每个用户组运行RL，则可以提高每个组的性能。</p></blockquote><h2 id="A-why-RL"><a href="#A-why-RL" class="headerlink" title="A. why RL"></a>A. why RL</h2><blockquote><p>为TCP流选择适当的IW并非易事。<br>使用数据驱动的方法是一个有前途的方向，但是即使我们已详细记录了网络状况，仍然很难确定合适的IW，因为它与多个复杂因素（例如网络带宽，RTT，路由器缓冲区大小， 用户和服务器之间的端到端路径上的流量大小等。 而且，所有这些因素都可能随时间频繁变化，**<u>这意味着适当的IW随时间变化</u>**。</p><p>==我感觉这句暗指了non-stationary environment的本质== ==》 <strong><u>对于其他的RL来说，无法很好解决。但是对于MAB来说，可以通过折扣函数去解决non-stationary的问题</u></strong></p><p> 增强学习（RL）受人类行为主义心理学的启发[8]，是机器学习社区中的一种流行技术，非常适合应对上述情况。 基本上，它会根据环境反馈不断做出决策。 一旦正确定义了优化目标（在RL中称为奖励函数），RL就可以通过尝试次优决策与利用当前最佳决策之间的动态平衡，基于试错法逐渐找到最佳决策。 而且，其探索和开发算法可以对环境变化做出快速反应。 因此，RL自然适合动态设置IW的任务。 借助正确定义的奖励功能，RL算法可以帮助自动找到良好的IW，而无需担心复杂的网络因素及其变化。</p></blockquote><h2 id="B-How-to-define-the-reward-function"><a href="#B-How-to-define-the-reward-function" class="headerlink" title="B. How to define the reward function"></a>B. How to define the reward function</h2><ul><li><p>直接用我们的目标的绝对值作为reward不合适，因为不同环境下，我们的目标的取值范围也是在变化的</p><blockquote><p>一个简单的方法是直接使用TCP响应时间，这是我们在本文中的优化目标。 但是，对于不同的请求，Web响应的大小可能会有很大差异，因此无法直接比较其网络传输时间。我们注意到，RL方法需要将TCP流数据聚合在一起以学习历史并通过比较不同决策的收益来选择IW。 <u><strong>因此，我们需要一个奖励函数，无论response size如何，它都能准确反映IW对TCP响应时间的影响。</strong></u></p></blockquote></li><li><p>吞吐量（单位时间传输的字节数）是满足上述要求的良好候选者。 增加IW以获取部署我们方法的流（称为SmartIW流）的最佳收益可能会损害与SmartIW流共享某些网络资源的非SmartIW流的性能。因此，为了保持公平性，我们将RL优化目标限制为为SmartIW流获得尽可能高的吞吐量，同时尽力不损害非SmartIW流。 因此，我们在奖励函数中同时考虑了吞吐量和RTT，其中RTT是影响非SmartIW流性能的网络拥塞的良好指标[14]。 **<u>这里我们没有在奖励函数中增加损失，因为许多基于RTT的拥塞控制算法[15，16]在不考虑损失的情况下都能很好地工作</u>**。【这里引文是Vegas和Timely，后者是知道的，说的是RTT这一个指标就enough了】</p></li></ul><ul><li><p>hesy summary: 目标有两个</p><ul><li>降低响应时间( increase goodput ) ==其实这个逻辑还是没有很懂==</li><li>保证非smartIW流之间的公平性</li></ul></li></ul><h2 id="C-Overview-of-SmartIW"><a href="#C-Overview-of-SmartIW" class="headerlink" title="C. Overview of SmartIW"></a>C. Overview of SmartIW</h2><blockquote><p>​    如图3所示，当SmartIW前端服务器接收到来自用户的HTTP请求时，前端服务器与该用户建立会话并识别其属于哪个用户组。 然后，前端服务器从每组RL的结果中获取IW的最新决策，并在将响应发送给用户之前迅速为会话设置此IW。 响应的传输完成后，前端服务器输出TCP性能数据，并将其报告给服务器群集，该服务器群集使用新的测量数据按组RL运行，并充当学习每个用户组IW的大脑。 此外，大脑会根据历史数据运行用户分组算法。 大脑以分钟为单位的时间连续地将每个用户组的IW决策发送到前端服务器。 这样，它可以控制所有会话的行为。 请注意，所有过程都是在服务器端完成的，无需任何客户端或中间件（例如，路由器，交换机，链接）的修改或协助，并且我们的方法仅更改IW，而无需修改TCP拥塞控制算法。</p></blockquote><h1 id="4-CORE-ALGORITHMS"><a href="#4-CORE-ALGORITHMS" class="headerlink" title="4 CORE ALGORITHMS"></a>4 CORE ALGORITHMS</h1><blockquote><p>在本节中，我们介绍SmartIW的两种核心算法：用于在给定用户组（§IV-A）的情况下学习每组IW的RL算法和用户分组算法（§IV-B）。</p></blockquote><p>hesy：我觉得主要是引入了折扣的概念</p><h2 id="A-Reinforcement-Learning"><a href="#A-Reinforcement-Learning" class="headerlink" title="A. Reinforcement Learning"></a>A. Reinforcement Learning</h2><p>采用折现的UCB算法[12]来解决非平稳土匪问题</p><blockquote><p>对于平稳多臂匪徒问题，基本的UCB算法[17]已被证明是最优的[12]。 它的假设是上下文的未知分布不会随时间变化。 但是，在我们的方案中，网络条件可能会随时间而变化，从而使我们的RL问题成为非平稳的土匪问题。 在本文中，我们采用折现的UCB算法[12]来解决非平稳土匪问题。 基本过程如算法1所示。</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/221525-355237.png" alt="image-20201208221524818"></p><p>ct（γ，i）是公式3中定义的discounted padding function，其中B是奖励的上限，而ξ&gt; 0是控制探索概率的适当常数方差。 请注意，如果历史上经常使用一只手臂，则其ct（γ，i）小于另一只手臂，因此可以将次优手臂用于勘探。 这样，该算法可以在探索和开发之间取得平衡。</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/221603-648108.png" alt="image-20201208221601756"></p><p>“最小填充函数值意味着该手臂比其他手臂被更频繁地利用“</p><blockquote><p>传统的UCB算法</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/221715-425521.png" alt="image-20201208221653974" style="zoom:67%;" /></blockquote><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/222015-372992.png" alt="image-20201208222014171" style="zoom: 80%;" /><blockquote><p>为了在IW学习中使用折扣UCB，关键是奖励功能和臂的定义。 </p></blockquote><ul><li><p>Reward function definition</p><p>我们的目标是设置理想的IW，以充分利用客户端-服务器端到端链接的带宽而不会引起拥塞。 如§III-B所述，我们将RTT视为网络拥塞的信号。 公式4中的奖励反映了我们的目标，即最大化产量并最小化RTT。  Goodputs（i）是我在时间s的即时吞吐量，RTTs（i）是我在时间s的即时回报。  Goodputmax是历史记录测量中的最大吞吐量，RTTmin是历史记录测量中的最小RTT。  α是达到产量和RTT之间平衡的参数。 小α有利于降低RTT，这可能会使算法在IW小的情况下显得比较保守。 大α有利于高吞吐量，这可能会使算法在IW大的情况下具有攻击性。</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/222044-670705.png" alt="image-20201208222042659"></p><pre><code>&gt; hesy: 其实是体现了归一化的思想在内的</code></pre></li></ul><ul><li><p>Arms definition</p><blockquote><p>折扣UCB中的武器清单是具有一些离散值的决策空间。 但是，IW具有连续且较大的价值空间。 我们的目标是在大型决策空间中快速找到最佳的IW。 残酷地搜索整个决策空间效率低下，因为太多的武器会浪费探索过程中的时间。<u>为了解决这个问题，我们基于关于TCP性能和IW之间关系的常识（在II-B节中提到）提出了一种滑动决策空间方法。</u></p></blockquote><p>首先，我们从一小段IW作为武器开始，武器列表中的值根据武器的性能是动态的。 基本过程如图4所示。我们使用n个IW作为初始武器清单（例如，n = 4，IW = [15、20、25、30]）。 在更新决策时，我们将首先检查是否要更新清单。 基本思想是检查最大的臂IWlarge或最小的臂IWsmall当前是否是最佳臂。 如果是，我们将更新清单。 否则手臂列表保持不变。 最好的手臂是等式3中具有最大奖励和最小填充函数值的手臂。<u>最小填充函数值意味着该手臂比其他手臂被更频繁地利用</u>。 根据对IW的普遍理解（第II-B节），IW太大和太小都是次优的。 如果当前的最佳分支是IWlarge，则将新的IW（IWlarge +？）添加到分支列表并删除IWsmall。 如果当前的最佳分支是IWsmall，则将新的IW（IWsmall-？）添加到分支列表并删除IWlarge。  ？ 是用于搜索IW空间的恒定步长。 如果当前最佳IW不是最大或最小，则机械臂列表保持不变。</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/222406-576492.png" alt="image-20201208222312140"></p><blockquote><p>==这么做的原因是什么？？ 似乎没有就上面那句话”根据常识“，是没有办法很好解释的==</p><p>或者说 没有给收敛性的一个比较intuitive的解释</p></blockquote><h2 id="B-User-grouping"><a href="#B-User-grouping" class="headerlink" title="B. User grouping"></a>B. User grouping</h2><p><u>hesy: 这么分，是为了保障在context差不多的情况下，一个类型的训练数据尽量多</u></p><blockquote><p>实际上，由于用户具有不同的网络功能（例如，子网，ISP，省），因此用户的网络状况具有很大的多样性。 对于来自不同省（例如北京，上海）和ISP（例如CHINANET，CMNET，UNICOM）的用户，他们的网络条件（例如带宽和RTT）可能不同。 要将RL应用在空间变化很大的网络条件下，应对具有不同网络条件的用户进行不同对待。 流的IW由其端到端链接的网络条件（即带宽和RTT）确定。 </p><p><u>理想的解决方案是为每个链接学习IW</u>。但是，每个链接几乎没有足够的样本供RL学习IW。 </p><p>因此，我们认为将具有相似网络功能的用户分组以共享其样本是一种很有前途的解决方案。 但是，由于以下难题，<u>对用户进行分组具有挑战性</u>。  1）粒度太细的用户组（例如IP）通常缺乏足够的样本来连续监视其网络性能，这无法满足RL的要求;  2）用户组的粒度太粗（例如所有流）会导致性能欠佳。 </p></blockquote><blockquote><p>为了解决上述问题，我们提出了一种新的用户分组方法。 用户分组的目的是找到可以满足RL要求（即在网络条件下保持连续性）的最细粒度的用户组。 <strong><u>基本思想是使用自下而上（因此最细到最粗）的搜索技术来找到最佳用户组，每个用户组都有足够的样本并保持网络状况的连续性。</u></strong> 我们使用§IV-A中的奖励函数来量化网络条件，该函数同时考虑了吞吐量和RTT。</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/08/222833-304334.png" alt="image-20201208222832909"></p><blockquote><p>更具体地说，在数据传输之前，**<u>IP是最细粒度的用户组</u>**，因为当时的服务器只能获取IP作为用户的网络功能。 通过使用IP查找B公司的地理位置数据库，该数据库类似于地理位置数据库[18]，我们可以推断出其他网络功能，例如子网，ISP，省等。表II显示了该地理位置数据库的示例。 请注意，IP仅属于表中功能的一条记录，并且所有记录在IP空间中都是互斥的。 因此，用户分组结果的结构形成了4层（子网，ISP，省，全部）树。 图5示出了一个例子。 </p></blockquote><p><u>我们说一个用户组在一个长度为t的time bin中至少有S<del>min</del>个样本时，具有足够的样本。</u></p><blockquote><p>对于每个time bin，我们计算奖励的分布，并使用平均奖励来量化此时间仓的网络状况。 这样，我们获得了平均回报的时间序列，以表征网络状况的变化。 然后，我们定义一个等式5中所示的称为网络抖动 J 的度量，以捕获网络条件的连续性。  n表示时间段的数量，X<del>s</del>是时间段s的奖励。 </p></blockquote><p>​    由于IW影响奖励，因此在计算 J 时，IW在每个时间段中应保持相同。 请注意，较小的 J 表示网络状况的变化较小。 要将RL方法应用于给定的用户组，J 越小越好。 这里我们选择一个阈值T，如果用户组 J ≤ T，则满足RL的要求。</p><blockquote><p>==hesy的理解是== : 一开始是有个训练过程，刻意去尝试某个IW值（不一定是最优），但多个时间段内要保持动作一致，去check</p></blockquote><p>​        <img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/09/004907-711586.png" alt="image-20201209004906245" style="zoom:80%;" /></p><blockquote><p>​    在此示例中，假设最佳用户的网络功能是 <em>subnet</em>，而最coarse的特征就是<em>All</em>。 北京有3个ISP：CMNET，UNICOM和CHINANET，它们有8个子网S1-S8。 用户分组算法包括4个步骤：</p><p>• 步骤1：我们检查所有叶节点是否都满足RL的要求（等式5）。 该示例的结果是，S1，S3，S6（绿色）满足RL的要求，而S2，S4，S5，S7，S8（蓝色）不满足RL的要求，因此S1，S3，S6是三个可以 使用RL学习IW。</p><p>• 步骤2：无法满足RL要求的兄弟叶子节点被合并到一个名为“其他”的新叶子节点中，这是其原始父节点的新子节点。 在此示例中，S<del>2</del>变成了Other，是CMNET的新子节点。  S<del>4</del>和S<del>5</del>合并到UNICOM的新子节点Others中。  S7和S8合并到CHINANET的新子节点Others中。</p><p>• 步骤3：我们检查“其他”节点是否满足RL的要求。 如果“其他”节点不符合要求，则需要将其与父级（ISP）的兄弟“其他”节点合并，并形成其原始祖父母（省）的新子级“其他”节点。 在该示例中，CMNET的其他节点和CHINANET的其他节点合并为北京的新子节点其他。  UNICOM的Others节点满足要求，因为在合并S4和S5之后，它有足够的样本来测量其网络状况。</p><p>• 步骤4：算法将继续检查“其他叶子”节点，直到所有叶子节点（根的子“其他其他”节点除外）都满足RL的要求。 最后，如果“其他所有人”不符合要求，我们将使用标准IW [6]作为流程。 在此示例中，除“其他所有节点”之外的叶节点是可以使用RL学习IW的用户组。</p></blockquote><h1 id="5-Design-and-Implementation"><a href="#5-Design-and-Implementation" class="headerlink" title="5. Design and Implementation"></a>5. Design and Implementation</h1><p>tl；dr</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/09/005911-917455.png" alt="image-20201209005910544"></p><h1 id="inspiration-of-hesy"><a href="#inspiration-of-hesy" class="headerlink" title="inspiration of hesy"></a>inspiration of hesy</h1><ul><li><p>要会用这个词: <strong>data-driven</strong> 代替 ML-based 或者RL-based。高大上！</p></li><li><p>contribution绝对不能写自己是首先用DRL做这个的，因为还有些水会也是做这个的，所以我们也要credit他们并且讲清楚区别。</p></li><li><p>写作的时候要注意层次感，不能一上来就说这个feature适合用RL做，应该先给出一个也比较适合但是naive的solution，再说RL可以解决这个naive的defects</p></li><li><p>目标函数或者奖励函数的形式  需要找人背书，不能自己随便造一个</p><ul><li>目标函数没有想好要不要让清空队列，因为延迟梯度也能包含这个目标。（或许可以做一个实验来证明这两个的相关性，看下Timely怎么做ECN和延迟的相关性的，记得这两个并不是很大程度上的相关鸭）</li></ul></li><li><p>对于问题的建模做的很好，而且作为了一个challenge</p><p>hesy:The long flow switch like this, the cold start process should not be ignored–”Use SmartIW</p></li></ul><ul><li>实验细节还得要好好看下</li></ul>]]></content>
      
      
      <categories>
          
          <category> PaperReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>questions in paperreading</title>
      <link href="/Summary/questions/"/>
      <url>/Summary/questions/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="TIMELY"><a href="#TIMELY" class="headerlink" title="TIMELY"></a>TIMELY</h1><p><span class="exturl" data-url="aHR0cHM6Ly9taXFpYW5taW1pLmdpdGh1Yi5pby8yMDE5LzAxLzIwL1RJTUVMWS8=">mamaqi的TIMELY笔记<i class="fa fa-external-link-alt"></i></span> (sigcomm’15)</p><ul><li><p><del>正反向的传输会相互影响么？? 正反向共享链路 ？</del> <img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/09/202622-45397.png" alt="image-20200809202217447"></p><blockquote><p>会的会的2333，因为RTT是往返嘛</p></blockquote></li></ul><h1 id="mamaqi-待读文章"><a href="#mamaqi-待读文章" class="headerlink" title="mamaqi 待读文章"></a>mamaqi 待读文章</h1><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9taXFpYW5taW1pLmdpdGh1Yi5pby8yMDE5LzAyLzE2L3F1aWMv">QUIC<i class="fa fa-external-link-alt"></i></span></p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9taXFpYW5taW1pLmdpdGh1Yi5pby8yMDE5LzAyLzExL0RlZXBSTS8=">Hongzi Mao:Deep RM<i class="fa fa-external-link-alt"></i></span></p></li></ul><h1 id="RL"><a href="#RL" class="headerlink" title="RL"></a>RL</h1><h2 id="285"><a href="#285" class="headerlink" title="285"></a>285</h2><h3 id="lec-5"><a href="#lec-5" class="headerlink" title="lec 5"></a>lec 5</h3><ul><li>PG和POMDP的关系</li></ul><h3 id="lec-6"><a href="#lec-6" class="headerlink" title="lec 6"></a>lec 6</h3><ul><li><p>AC和PG的区别是不是这个：AC引入了TD去估计Q value ,which means我们可以online learning , 一步一学习。    </p><blockquote><p>==感觉PG和AC的区别主要还是用MC还是TD去拟合critic，到后来的GAE，说到底，还是采样的事情？==</p></blockquote></li></ul><h3 id="lec-7"><a href="#lec-7" class="headerlink" title="lec 7"></a>lec 7</h3>]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Research on Transport Control and Flow Scheduling in Low-latency Datacenter Networks</title>
      <link href="/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/"/>
      <url>/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="第一章-引言"><a href="#第一章-引言" class="headerlink" title="第一章 引言"></a>第一章 引言</h1><ul><li>数据中心应用类型</li><li>数据中心流量特性</li><li>仍存在的问题</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/08/214444-685710.png" alt="image-20200808214442717"></p><p>说实话感觉这里讲的不是很清楚，回头再来仔细梳理下把。</p><h1 id="第二章-背景和相关综述"><a href="#第二章-背景和相关综述" class="headerlink" title="第二章 背景和相关综述"></a>第二章 背景和相关综述</h1><ul><li>传统TCP及研究进展<ul><li>调整AIMD参数 –》good idea ==但是还是那个问题，为什么要搞pacing，而放弃窗口==</li><li>==incast 难道是数据中心特有的问题?== 其实只要BDP足够小就可以把？RTT不够小，但是我bandwidth够小总可以吧？TCP incast不就是拥塞么?<ul><li>我感觉只要是低延迟链路，就会有这种情况 （一旦有超时发生， 网络中会出现长时间的链路闲置状态）</li><li>如果要在数据中心做，得考虑放弃短流的调度，只调度长流？看看iroko怎么做的？</li></ul></li><li>DCTCP是解决TCP incast的？？</li></ul></li></ul><ul><li><p>TCP incast</p><ul><li><p>以前的解决方案</p><blockquote><p>第一类的主要方法是修改TCP配置参数，将RTO设置为微秒级 别，从而减小超时重传所需的等待时间; 第二类为修改TCP的拥塞控制算法，提高 缓存利用率，进而避免丢包；第三类是通过修改QCN算法来提高协议公平性；第 四类摒弃 TCP 方案采用 UDP 方案彻底避免超时重传的问题。</p></blockquote></li></ul></li><li><p>多种流量共存</p><ul><li><p>长流(重视高吞吐) &amp; 短流(重视低延迟) –》 目标不同</p></li><li><p>相互作用：长流容易造成短流的饥饿</p></li><li><p>还有部分应用存在截止时间需求 ，whose 主要性能指标是截止时间错过率</p></li><li><p>应对措施</p><blockquote><p>非截止时间流调度机制和传输协议研究，截止时间流调度机制 和传输协议研究和混合流调度机制和传输协议研</p></blockquote></li></ul></li><li><p>任务调度</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/09/154827-641523.png" alt="image-20200809154826511"></p><h1 id="第三章-支持选择性反馈的编码传输协议研究研究"><a href="#第三章-支持选择性反馈的编码传输协议研究研究" class="headerlink" title="第三章 支持选择性反馈的编码传输协议研究研究"></a>第三章 支持选择性反馈的编码传输协议研究研究</h1><ul><li>关于发送速率，on friendliness ，需要做的是：找论文背书，基于别人的公式进行建模</li></ul><h1 id="第四章-数据中心网络的混合流调度机制SMF"><a href="#第四章-数据中心网络的混合流调度机制SMF" class="headerlink" title="第四章 数据中心网络的混合流调度机制SMF"></a>第四章 数据中心网络的混合流调度机制SMF</h1><blockquote><p>这一部分讲的比较详细</p></blockquote><h2 id="miscelleneous"><a href="#miscelleneous" class="headerlink" title="miscelleneous"></a>miscelleneous</h2><ul><li>如何判断截止时间流还有非截止时间流本身也是个很大的问题啊！</li><li>传统解决方案中，基于速率的控制协议（RCP）到底是什么呢？Karuna采用的MCP又是什么呢?</li></ul><h2 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h2><ul><li><p>SMF</p><ul><li>对于非截止事件流，采用SJF</li><li>对于截止事件流，采用MLFQ</li><li>是满足多重目标的分布式拥塞控制协议，旨在调度混合流以改善流完成率和流完成时间</li><li>也对初始窗口大小做了改进，where也很重要。裴丹的，实际上是根据具体的业务进行改进了的。看看SMF采取了哪些feature，怎么做的，或许也是一个点？</li></ul></li><li><p>NP-hard问题证明</p><ul><li>截止时间流</li><li>非截止时间流（ 感觉讲得也很粗糙</li><li>所以使用启发式</li></ul></li><li><p>对于不能在截止时间前完成的流，<strong>“早丢弃”</strong>方式提前丢弃以节省网络带宽</p><ul><li>==自己的机制里面如果太简单，也可以加一些“早丢弃”等手工的规则==</li></ul></li><li><p>考察指标</p></li></ul><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200809171054378.png" alt="image-20200809171054378" style="zoom: 80%;" /><h1 id="第五章-任务级别的截止时间感知流调度机制研究TAPS"><a href="#第五章-任务级别的截止时间感知流调度机制研究TAPS" class="headerlink" title="第五章 任务级别的截止时间感知流调度机制研究TAPS"></a>第五章 任务级别的截止时间感知流调度机制研究TAPS</h1><h2 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h2><ul><li><p>如果某任务没有在截止事件前完成，那么该任务已经成功传输完成的所有数据都是无用数据。非常不幸的是，数据中心网络中采用的大部分传输协议，都是基于竞争的传输协议，如 TCP，RCP[35]，ICTCP[10]，DCTCP[2]，采用平均分配带宽的原则为网络中互相竞争的每条流分配链路以及可用带宽。这些方案固然可以有效将数据流从源端传输到目的端，但是他们忽略了数据流或是任务的截止时间，同时也没有意识到不同流之间的区别，无法做到最小化网络流完成时间。</p></li><li><p>统计数据表明，对于 web 应用，每个任务至少包括 88 条流[2]，对于 MapReduce 搜索工作每个任务包含 30 到 50000 条流[6]，对于 Cosmos 每个任务约包含 30 到 70 条流[97]。这些统计数据表明在数据中心内，很多应用对于每个任务会产生相应的多条数据流来完成，因此任务才是处理的单位。</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>使用SDN</p>]]></content>
      
      
      <categories>
          
          <category> PaperReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python总结</title>
      <link href="/Summary/python/"/>
      <url>/Summary/python/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="深浅拷贝"><a href="#深浅拷贝" class="headerlink" title="深浅拷贝"></a>深浅拷贝</h1><ul><li><p>说千道万，不如<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWNjNDExaDdoZD9mcm9tPXNlYXJjaCZzZWlkPTE3OTE4NDE2ODkwNDkxMDIzMzY=">画图实在<i class="fa fa-external-link-alt"></i></span></p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbG9sZWluYS9wLzUyNzY5MTguaHRtbA==">函数传参，传的是引用<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个<strong>可变对象（比如字典或者列表）</strong>的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个<strong>不可变对象（比如int、str或者tuple</strong>）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。 </p><blockquote><p> 注意，tuple本身不可变，但是tuple里面的元素可变</p></blockquote></blockquote></li><li><p><input disabled="" type="checkbox">  一些常用的基本操作哪些是深/浅拷贝？tf里面呢？</p></li></ul><h1 id="闭包-amp-nonlocal"><a href="#闭包-amp-nonlocal" class="headerlink" title="闭包 &amp; nonlocal"></a>闭包 &amp; nonlocal</h1><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80MTAzMDE1Mw==">nonlocal和global区别<i class="fa fa-external-link-alt"></i></span></p><p>global的作用对象是全局变量，nonlocal的作用对象是外层变量（很显然就是闭包的情况）。</p><p>注意，只有函数内的函数才是闭包，函数内的语句块，不算是闭包。</p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAwNDQ2MTQwNA==">闭包<i class="fa fa-external-link-alt"></i></span></p><ul><li>其中几个作用：节省开销，将函数与某个参数绑定</li><li>装饰器就是一种闭包</li></ul></li></ul><h1 id="python-numpy-pandas-切片-amp-索引"><a href="#python-numpy-pandas-切片-amp-索引" class="headerlink" title="python,numpy,pandas 切片&amp;索引"></a>python,numpy,pandas 切片&amp;索引</h1><h2 id="python-list-amp-numpy的索引-异同"><a href="#python-list-amp-numpy的索引-异同" class="headerlink" title="python list &amp; numpy的索引 异同"></a>python list &amp; numpy的索引 异同</h2><ul><li><p>python ( list ) 支持的索引 和 np数组支持索引的区别</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; a[1][1]    <span class="comment"># 索引</span></span><br><span class="line">5</span><br><span class="line">&gt;&gt; a[1]</span><br><span class="line">[4,5,6]</span><br><span class="line">&gt;&gt; a[1][:]    <span class="comment"># 也支持切片</span></span><br><span class="line">[4,5,6]</span><br><span class="line">&gt;&gt; a[1,1]<span class="string">&quot;&quot;</span><span class="string">&quot;相当于a[1,1]被认为是a[(1,1)],不支持元组索引&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: list indices must be integers, not tuple</span><br><span class="line">&gt;&gt; a[:,1]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: list indices must be integers, not tuple</span><br></pre></td></tr></table></figure><p><strong><u>只支持 listData[ Idx_in_x ][ Idx_in_y ][ Idx_in_z ]的索引操作</u></strong> –》 先取出第一个维度的元素，然后再取出内部一个元素，再再再取出其中一个元素，像拆包一样。</p><p>numpy不仅支持上述操作，更支持多维度上更便捷的索引方式</p><p>我的理解是，索引就是select出到单个元素，切片是给出一个数组的子集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">listData=[ [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] ]</span><br><span class="line">npData = np.array( listData )</span><br><span class="line"></span><br><span class="line">listData[<span class="number">1</span>][<span class="number">2</span>]  <span class="comment"># 索引操作，select出单独的元素</span></span><br><span class="line">listData[<span class="number">1</span>][:]  <span class="comment"># 索引+切片</span></span><br><span class="line">listData[<span class="number">1</span>,<span class="number">2</span>]    <span class="comment"># list不支持这种索引方式</span></span><br><span class="line"></span><br><span class="line">npData[<span class="number">1</span>][<span class="number">2</span>]    <span class="comment"># list能支持的我也能！</span></span><br><span class="line">npData[<span class="number">1</span>][:]    <span class="comment"># list能支持的我也能！</span></span><br><span class="line">npData[<span class="number">1</span>,<span class="number">2</span>]    <span class="comment"># 我还能！在多维的索引上，np更方便!</span></span><br><span class="line">npData[<span class="number">1</span>,:]    <span class="comment"># 我还能！在多维的索引上，np更方便!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当维度一旦多起来，少打几个中括号还是很可观的</span></span><br><span class="line"><span class="comment"># 而且，还有这种情况：我想要1、3列的第2个元素</span></span><br><span class="line">listData[<span class="number">0</span>,<span class="number">2</span>][<span class="number">1</span>]    <span class="comment"># 当然错误，listData[1,3]都无法支持更别说listData[1,3][2]了</span></span><br><span class="line">true<span class="comment"># 但是np可以这样&quot;稀疏检索&quot;(我自己发明的词汇)</span></span><br><span class="line">npData[<span class="number">0</span>,<span class="number">2</span>][<span class="number">1</span>]    <span class="comment"># 但是这样是错误的，因为npData[1,3]是一个具体的元素</span></span><br><span class="line">npData[ [<span class="number">0</span>,<span class="number">2</span>],<span class="number">1</span> ] <span class="comment"># 这样才是对的，但就是这样，listData也不支持</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="numpy-amp-pandas的索引-异同"><a href="#numpy-amp-pandas的索引-异同" class="headerlink" title="numpy &amp; pandas的索引 异同"></a>numpy &amp; pandas的索引 异同</h2><blockquote><p>reference：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1Nfb19sX29fbi9hcnRpY2xlL2RldGFpbHMvODA4NzU4MDQ=">ndarray对象和pandas中DataFrame对象的索引方法及对比<i class="fa fa-external-link-alt"></i></span></p><p>目前能得到的结论就是 pandas的DataFrame尽量用iloc的方式去索引</p></blockquote><h3 id="先说结论"><a href="#先说结论" class="headerlink" title="先说结论"></a>先说结论</h3><p><u>为了更好的记忆和统一索引方式</u>，pandas使用的时候请一律使用**<u> df.iloc</u>** ,这个时候就跟numpy的习惯用法一致了。</p><h3 id="再说原因-和-细节"><a href="#再说原因-和-细节" class="headerlink" title="再说原因 和 细节"></a>再说原因 和 细节</h3><ul><li>pds 是基于 numpy构建起来的数据    结构</li><li>没有 df[ i , j ] 的索引方法，df[ i ][ j ] 也和list/numpy不一样，是先索引列，再索引行（numpy实际上是从外向内索引，对于二维的来说就是先索引行再索引列了） 。<ul><li>注意，df[ i ][ j ]索引的时候，第一个维度一定要使用 标签，有（大多数）时候标签不一定是一个int，是一个str</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>listData=[ [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] ]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData = pd.DataFrame(listData,columns = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],index=[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData[<span class="string">&#x27;c&#x27;</span>][<span class="string">&#x27;f&#x27;</span>]    <span class="comment"># 正确</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData[<span class="string">&#x27;c&#x27;</span>][<span class="number">2</span>]    <span class="comment"># 正确，第二个索引不一定要使用标签(因为pdData[&#x27;c&#x27;]实际上是一个Series了,Series的索引是int还是str没所谓)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData[<span class="number">2</span>][<span class="number">2</span>]  <span class="comment"># 错误，第一个索引还是要对应于columns的标签的，除非使用iloc</span></span><br></pre></td></tr></table></figure><p>​        pdData  :  <img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/18/150002-412342.png" alt="image-20201218145959545"></p><ul><li>df.iloc[i][j] 和df.iloc[i,j] 就和numpy的一样了，而且 i 与 j 应该全为int，而不是str了( 就算index和columns都可能是str的情况下 )，如果贸然写columns/index对应的str标签，反而会报错</li><li>对应于iloc就是loc了，iloc要求索引下标全都是int，这里就要求严格与index/columns对应（大多数时候是string）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData.loc[<span class="string">&quot;d&quot;</span>,<span class="string">&quot;a&quot;</span>] <span class="comment"># 正确，索引就应该是string，和DataFrame的标签一致</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pdData.loc[<span class="string">&quot;d&quot;</span>][<span class="number">1</span>]    <span class="comment"># 正确，因为pdData.loc[&quot;d&quot;]实际上就是检出了Series,Series的索引是int还是str没所谓</span></span><br></pre></td></tr></table></figure><h2 id="视图与索引"><a href="#视图与索引" class="headerlink" title="视图与索引"></a>视图与索引</h2><p>**<u>np数组返回的都是视图</u>**，除非具体到某个元素，否则修改视图的内容，原内容都会变（including 切片）。</p><p><strong>list除了<u>切片</u>返回的是一份副本</strong>，其余都是返回视图。</p><pre><code>&gt; 所以python想要实现列表元素的值传递时，一个方式就是参数使用 listData[:]</code></pre>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; listData=[ [1,2,3],[1,2,3],[1,2,3] ]</span><br><span class="line">&gt;&gt;&gt; npData = np.array( listData )</span><br><span class="line">&gt;&gt;&gt; a = listData[1]    <span class="comment"># 这样是会改变的，返回的是数组对象的引用</span></span><br><span class="line">&gt;&gt;&gt; a[2]=8</span><br><span class="line">&gt;&gt;&gt; listData        </span><br><span class="line">[[1, 2, 3], [1, 2, 8], [1, 2, 3]]</span><br><span class="line">&gt;&gt;&gt; b = listData[1][:]    <span class="comment"># 这样是不会改变的</span></span><br><span class="line">&gt;&gt;&gt; b[2]=9</span><br><span class="line">&gt;&gt;&gt; listData        </span><br><span class="line">[[1, 2, 3], [1, 2, 8], [1, 2, 3]]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; c = npData[1][:]    <span class="comment"># numpy无论如何都会改变原数据的</span></span><br><span class="line">&gt;&gt;&gt; c[2]=11</span><br><span class="line">&gt;&gt;&gt; npData        </span><br><span class="line">[[1, 2, 3], [1, 2, 11], [1, 2, 3]]</span><br></pre></td></tr></table></figure><blockquote><p>注意，副本是一份浅拷贝 详情可以参考==<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDQxNjY0OS9hcnRpY2xlL2RldGFpbHMvOTI4Nzg4NDc=">这个博客<i class="fa fa-external-link-alt"></i></span>==举的例子</p><p>想要实现深拷贝，还是得调用 .deepcopy( )</p></blockquote><h2 id="切片索引、布尔索引、花式索引"><a href="#切片索引、布尔索引、花式索引" class="headerlink" title="切片索引、布尔索引、花式索引"></a>切片索引、布尔索引、花式索引</h2><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Rha2UxMy9hcnRpY2xlL2RldGFpbHMvODEzMDI0NTA=">refer : 切片索引、布尔索引、花式索引<i class="fa fa-external-link-alt"></i></span></p><ul><li>切片是快照，会改变原本元素，但是布尔和花式就不会</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">15</span>).reshape(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># 切片    </span></span><br><span class="line">b1 = a[:<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 布尔索引</span></span><br><span class="line">mask = a2&lt;<span class="number">5</span></span><br><span class="line">b2 = a2[mask]</span><br><span class="line"><span class="comment"># 花式索引</span></span><br><span class="line">b3 = a3[[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xhbnhpdXRpbmcxOTkzL2FydGljbGUvZGV0YWlscy8xMDMyNTUyOTM=">多维度的花式索引<i class="fa fa-external-link-alt"></i></span>的写法和含义</p><blockquote><ul><li><p>一维的切片和索引差不多</p></li><li><p>二维的： array[ [ Idx_in_x ],[ Idx_in_y ],[ Idx_in_z ] ]    # 当Idx不是一个集合，是单个元素的时候，就可以省略中括号  </p><blockquote><p>array[ [ 1 ] ,[ 2 ] ,[ 3 ] ]  –&gt;  array[ 1 ,2  ,3  ] </p></blockquote><ul><li>请区分array[ [ 0,1] ]  和 array[ 0, 1]   <strong># 两个方括号是代表选取行数 要跟前面的[0,1] 区分开</strong></li><li>array[[1, 3,0], [1, 2,0]]     <strong># 获取索引为(1,1)和(3,2)和(0,0)的元素</strong></li></ul></li><li><p>三维的：array[[0,0],[1,1],[2,2]]</p></li></ul></blockquote></li></ul></li></ul><h1 id="subprocess"><a href="#subprocess" class="headerlink" title="subprocess"></a>subprocess</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E0NjQwNTcyMTYvYXJ0aWNsZS9kZXRhaWxzLzQ3MzU1MjE5">这个<i class="fa fa-external-link-alt"></i></span></p><h1 id="joyful-pandas"><a href="#joyful-pandas" class="headerlink" title="joyful pandas"></a>joyful pandas</h1><blockquote><p>pandas的一些少见的注意事项，具体代码和例子来源于datawhale的<span class="exturl" data-url="aHR0cHM6Ly9uYnZpZXdlci5qdXB5dGVyLm9yZy9naXRodWIvR1lISEFIQS9Kb3lmdWwtUGFuZGFzL3RyZWUvbWFzdGVyLw==">Joyful-Pandas系列<i class="fa fa-external-link-alt"></i></span></p></blockquote><h3 id="1-基础操作"><a href="#1-基础操作" class="headerlink" title="1.基础操作"></a>1.基础操作</h3><ul><li>df.value_count()</li><li>df.unique()</li><li>df.nunique()</li><li>df.describe()的一些用法<ul><li>可以自行选择分位数 df.describe(percentiles=[.05, .25, .75, .95])</li><li>非数值型也可以用describe函数</li></ul></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/26/112845-885917.png" alt="image-20200826112844748"></p><ul><li>还有一些练习题，也可以做下</li></ul><h3 id="2-索引"><a href="#2-索引" class="headerlink" title="2. 索引"></a>2. 索引</h3><ul><li><p>函数式索引 &amp; 布尔索引</p></li><li><p><strong>loc</strong>可以接收整数或整数列表或布尔列表以及Series，而<strong>iloc</strong>中接收的参数只能为整数或整数列表或布尔列表，不能使用布尔Series，如果要用就必须使用.values()把dataframe里面的列表拿出来</p></li><li><p>索引不要用浮点数，否则在切片索引的时候，[2: ]就表示的不是索引的下标从第二个开始了，而是用比大小的方式去看哪些行的索引值比2大，都拿出来</p></li><li><p>[ ]的索引方式中，比较灵活。有几种方式：</p><ul><li><p>索引index：</p><ol><li><p>data[3:5] 数字的话，就是索引行的绝对位置，就算index也是数字，也不要混淆啊！</p><ul><li><p>这个和data.iloc[3:5]效果是一样的(Series和DataFrame都适用)</p><blockquote><p>tip: loc和iloc其实都是二维的，如果只写了一个维度，就是指的index</p></blockquote></li><li><p>对于Series来说，这个和data[data.index[3:5]]效果是一样的（但是DataFrame就会报错的）</p></li></ul></li><li><p>如果index也是数字，想要索引对应于某个数值的index怎么办？(比如索引index为33的那一行)<br> data[data.index.get_loc(33)]</p></li></ol></li><li><p>索引column：<br>  如果index是str类型，data[“label”]默认也是索引column（最标准的写法还是loc[:,”label”]）</p><blockquote><p>注意，我个人测试的时候loc对于Series也是不会报错的，但是我还是不建议。因为容易混肴，Series没必要用loc，具体的含义我也搞不清楚</p></blockquote></li></ul></li><li><p>[快速标量索引]:当只需要取一个元素时，at和iat方法能够提供更快的实现</p><blockquote><p>看到区间索引，其实目前觉得差不多了。没必要再学更多了</p></blockquote></li></ul><h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><h2 id="代码展示（主要使用axex操作）"><a href="#代码展示（主要使用axex操作）" class="headerlink" title="代码展示（主要使用axex操作）"></a>代码展示（主要使用axex操作）</h2><p><span class="exturl" data-url="aHR0cHM6Ly9uYnZpZXdlci5qdXB5dGVyLm9yZy9naXRodWIvaGV4aTUxOS9Db2Rlc1NuaXBwZXRzL2Jsb2IvbWFzdGVyL3B5dGhvbkRlbW8vbWF0cGxvdGxpYkNvbmZpZy5pcHluYg==">my codes on github<i class="fa fa-external-link-alt"></i></span></p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><blockquote><p>所有高级的api，包括seaborns在内，都是基于最基本的matplotlib开始的，那么一定都得先搞清matplotlib的基本概念（ax和fig等）</p></blockquote><img src="https://img-blog.csdnimg.cn/20200311202147484.png" alt="在这里插入图片描述" style="zoom:67%;" /><ul><li>每一次subplot动作都是独立的</li></ul><blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure(num=<span class="string">&#x27;panel&#x27;</span>, figsize=(<span class="number">8</span>,<span class="number">4</span>),facecolor=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制两个不同大小的区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>) <span class="comment"># 划分1行3列，第1个子区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 划分1行2列，第2个子区域</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>其实把每一次 <code>subplot</code> 动作看作是独立的就行了，第一次将整个画板划分为1行3列完全不影响第二次划分为1行2列，它们仅影响当前划分后子图的大小。</p><img src="https://img-blog.csdnimg.cn/20190930150818814.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxMzQ3ODY5,size_16,color_FFFFFF,t_70"  /></blockquote><ul><li><p>添加子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######## 使用figure + addsubplot ########</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">221</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">222</span>)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">212</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">######## 使用figure + subplot ########</span></span><br><span class="line">fig = plt.figure(num=<span class="string">&#x27;panel&#x27;</span>, figsize=(<span class="number">8</span>,<span class="number">4</span>),facecolor=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment"># 划分三个小区域，绘制出第一个和第三个区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)  <span class="comment"># 划分1行3列，第1个子区域  </span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)  <span class="comment"># 划分1行3列，第3个子区域</span></span><br><span class="line">plt.show()</span><br><span class="line">true<span class="comment"># 注意，这里是plt.subplot而不是fig.add_subplot，which让我感到奇怪，但是先记住吧</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">######## 使用subplots,which是最常用的 ########</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">6</span>,<span class="number">3</span>))  <span class="comment"># 不仅会出现一个新的axes对象，还会创建一个新的fig对象，which the axes belongs to</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plot data</span></span><br><span class="line">axes[<span class="number">0</span>].plot(A,B)</span><br><span class="line">axes[<span class="number">1</span>].scatter(A,C)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>用 <code>subplots</code> 创建一个画板，同时也创建了一个绘图子区域 <code>axes</code>。画板赋值给了 <code>fig</code>，绘画子区域赋值给了 <code>ax</code>。这样一来，所有 <code>fig.***</code> 都是对整个画板进行操作，所有 <code>ax.***</code> 都是对这个 Aexs 子区域进行操作。</p></blockquote></li><li><p><strong>fig.xx 如果用于处理ax内部的属性，比如轴的刻度范围之类的，其实都是对ax.xx的api的封装</strong>，所以掌握ax.xx才是王道 和 最正确的方式</p></li></ul><h1 id="整型数的大小"><a href="#整型数的大小" class="headerlink" title="整型数的大小"></a>整型数的大小</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly96eGkubXl0ZWNocm9hZC5jb20vYmxvZy9kZXNnaW4vcHl0aG9uJUU0JUI4JUFEJUU3JTlBJTg0JUU2JTk1JUI0JUU1JTlFJThCJUU1JThEJUEwJUU1JUE0JTlBJUU1JUIwJTkxJUU0JUI4JUFBJUU1JUFEJTk3JUU4JThBJTgy">refer1:最小占量<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzY1MDE0NTcy">refer2:可以无限大<i class="fa fa-external-link-alt"></i></span></li></ul><p>64位系统，至少是24个字节，每次增量是4。python取消了long类型，所以，存储的数据大小是无限大的，取决于你的内存大小</p><h1 id="collections-defaultdict和dict区别"><a href="#collections-defaultdict和dict区别" class="headerlink" title="collections.defaultdict和dict区别"></a>collections.defaultdict和dict区别</h1><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FjY3VtdWxhdGVfemhhbmcvYXJ0aWNsZS9kZXRhaWxzLzc4NzU4ODk4">refer<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="comment"># 用dict得非常小心...</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = dict()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.get(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">3</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">KeyError: <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用defaultdict就不用检查是否存在这个key    </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = defaultdict(int)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">3</span>]</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Language </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Network常识记录</title>
      <link href="/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/"/>
      <url>/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="一些默认设置"><a href="#一些默认设置" class="headerlink" title="一些默认设置"></a>一些默认设置</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc3ByaW50Lm5ldC9zbGFfcGVyZm9ybWFuY2UucGhwP25ldHdvcms9c2w=">Sprint.net中统计的网络性能参数<i class="fa fa-external-link-alt"></i></span> </li><li>rtt普通情况下也就0.1s【CUBIC论文中写的】(数据中心中就是微秒级别)<ul><li>BBR论文中表示，由于buffer是BDP的几个数量级，所以rtt从毫秒级别变成了秒级</li></ul></li><li>DC中的带宽应该是10Gbps</li></ul><h1 id="How-can-we-be-aware-of-congestion"><a href="#How-can-we-be-aware-of-congestion" class="headerlink" title="How can we be aware of congestion"></a>How can we be aware of congestion</h1><ul><li><p>the internet is a <strong><code>decentralized</code></strong> system, and as a result of that, doesn’t have any central coordinator telling senders to slow down if link queues downstream of some sender are filling up.</p></li><li><p>There are two main indicators: <strong><code>packet loss</code></strong> and increased  <strong><code>round trip times</code></strong>  for packets. </p><ul><li><p>If a sender notices packet loss, it’s a pretty good indicator that congestion is occuring. </p></li><li><p>Another consequence of queues filling up though is that if packets are spending more time in a queue before making it onto the link, the round trip time, which measures the time from when the sender sends a segment out to the time that it receives an acknowledgement, will increase.</p><blockquote><p>summary：可以通过 <strong>packet loss</strong> 和 <strong>RTT</strong> 这两个现象来观察是否有congestion</p></blockquote></li></ul></li></ul><h1 id="概念解释-辨析"><a href="#概念解释-辨析" class="headerlink" title="概念解释/辨析"></a>概念解释/辨析</h1><h2 id="sending-rate-amp-delivery-rate"><a href="#sending-rate-amp-delivery-rate" class="headerlink" title="sending rate &amp; delivery rate"></a>sending rate &amp; delivery rate</h2><ul><li>sending rate就是发送速率</li><li>delivery rate强调接收方收到的包的速率（你发出去但是人家不一定能收到不是</li></ul><h2 id="pacing"><a href="#pacing" class="headerlink" title="pacing"></a>pacing</h2><ul><li><p>TCP的流控机制，基本上是有两种的，专业一点的说法分别叫做pure rate control和windows-based这两种</p><ul><li><p>pure rate control </p><ul><li>告诉你sender一个发送速率(bottleneck bandwidth)，sender的发送速率不超过这个确定值。</li></ul></li><li><p>window-based control</p><ul><li>这个就是常见的TCP 滑动窗口的协议，就是有一个ack确认后我才能发送下面的。</li></ul></li><li><p>pacing结合了这两种</p><ul><li>uses the tcp window to determine how much to send but uses rates instead of acknowledgments to determine when to send.</li><li>为什么要这样，因为标准TCP的发包是back-to-back的,TCP的这种clumped方式会引发高延迟以及burst traffic下的丢包大大增加，同时还有ACK Compression，Multiplexing等各种问题都会导致性能受损，所以有人突出了一个机制，我们能不能不让包堆在一起发，在一个窗口里流出间隔，那我们的排队队长就会下降的。</li><li>pacing可以看作TCP的一个变体，是结合了上面的两个流控方式，他使用tcp window决定发多少,用bottleneck bandwidth决定什么时候发，它定义了一个发包的间隔</li></ul></li><li><p>paing需要优化嘛？需要。 更多的可以看这个<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMDc0MTA3Mw==">专栏<i class="fa fa-external-link-alt"></i></span>搜集的paper  </p></li></ul></li></ul><h2 id="ACK-compression"><a href="#ACK-compression" class="headerlink" title="ACK compression"></a>ACK compression</h2><ul><li>由于中间链路的缓存以及和其他TCP连接一起共享缓存等原因，可能会导致ACK报文成堆到达发送端。这种场景我们就称呼为ACK压缩。</li><li>i.e. 一个TCP发送者的 自计时取决于到来的，由接收机按照相同时间间隔生成的ACK。如果这些的ACK通过网络过境期间存在一些开销在队列中，但是，它们的间隔可能会改变。当ACK的到达间距小于它们发送的间距，发送者可能会被误导，发送比网络可以接受的更多的数据，这可能导致堵塞和效率损失。</li><li>于ACK compression场景，reno拥塞控制就是逐个处理每个ACK报文，这样就会导致拥塞窗口突然增大，发送端突然发出大量的TCP报文，这种突然发出大量数据的行为我们称呼为burst，影响网络平稳。另外一方面ACK compression还会影响RTT估计，之前我们介绍过有些拥塞控制算法基于时延来来估计网络拥塞情况，因此 ACK compresion还会影响这类基于时延的拥塞控制算法的性能。</li></ul><h2 id="数据平面-amp-控制平面"><a href="#数据平面-amp-控制平面" class="headerlink" title="数据平面&amp;控制平面"></a>数据平面&amp;控制平面</h2><p>除了控制平面(Control Plane)和数据平面(Data Plane)还有管理平面(Management Plane)。数据平面又叫转发平面(Forwarding Plane),通过查看收到流量的目的地址，按照转发表(forwarding table)来处理流量的去向。可能转发流量去一个出接口，可能丢弃流量，或者送去控制平面做进一步处理。控制平面维持数据平面操作所需的必要信息。 这些信息通过协议和算法，收集和计算得来。网络节点间的控制平面能相互交换信息。这些信息被处理之后用于建立不同的表来帮助数据平面的流量操作。除了EIGRP, OSPF, BGP，PIM, HSRP等3层协议以外，CDP,UDLD,LACP,ARP,STP,VLAN等2层协议都属于控制平面。管理平面就是处理配置和监控控制平面。比如CLI, SNMP,XML, Wireshark,NetFlow,SPAN,API,JSON，NETCONF等等都属于管理平面。   </p><h2 id="latency-V-S-delay"><a href="#latency-V-S-delay" class="headerlink" title="latency V.S. delay"></a>latency V.S. delay</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzU5MzgwNjc0">refer<i class="fa fa-external-link-alt"></i></span></p><ul><li><p><strong>latency</strong></p><p>指的是一个报文进入一台设备以致这台设备所经历的实践。实际上考验的是报文在这台设备上<strong>消耗的时间</strong>。时间越短，这台设备的性能越高。</p></li><li><p><strong>delay</strong></p><p>是指一个操作和另个一个操作之间<strong>停顿的时间</strong>。</p></li></ul><p>所以，latency是不可避免的正常开销，然而delay是额外的开销。</p><h1 id="做CC实验要注意的点"><a href="#做CC实验要注意的点" class="headerlink" title="做CC实验要注意的点"></a>做CC实验要注意的点</h1><ul><li>不仅要测拥塞程度是否改进了</li><li>还要测量收敛速度和fairness to existing congestion control protocols</li></ul><h1 id="数据中心的CC"><a href="#数据中心的CC" class="headerlink" title="数据中心的CC"></a>数据中心的CC</h1><p>数据中心的基本设置<img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202012/03/113542-587066.png" alt="image-20201203113534852"></p><h2 id="learn-from-Lili-Liu’s-paper"><a href="#learn-from-Lili-Liu’s-paper" class="headerlink" title="learn from Lili Liu’s paper"></a>learn from Lili Liu’s paper</h2><ul><li><p>一般<strong>低延迟应用</strong>的流<strong>的 SLA</strong> (Service Level Agreement)要求是 300ms 内完成</p></li><li><p><strong>研究TCP</strong>（而不是一些基于UDP协议）<strong>的重要性</strong> （ 请注意，quic只是实现的一个途径–》用户态 ）</p><ul><li><p>数据中心要求可靠性，目前实现数据中心间的可靠传输的唯一途径是TCP</p><blockquote><p>数据中心间的链路是由 ISP 提供带宽和时延保障的专用链路，但由于路由切换及一 些突发事件，这种专用链路上偶尔也会发生丢包 </p></blockquote><p>根据 ISP 与服务商的SLA，<strong>丢包率一般在 0.5% 到 5% 之间，时延一般不超过 20ms</strong>。</p></li><li><p>研究结果表明数据中心网络中99%的流量都是TCP流量[2]</p><blockquote><p>参考文献[2]是一个2010年的文章</p></blockquote></li><li><p>然而，数据中心网络的传输协议大多数都采用TCP，<strong>并使用平均分配带宽为原则</strong>，将网络资源平均分配。如此做的方案主要有**<u>TCP、RCP[35]、DCTCP和HULL[18]等</u>**</p></li></ul></li><li><p>诸多研究表明<strong>TCP RTO是导致TCP Incast</strong> 的主要原因</p><ul><li>在 TCP 中，默认超时重传计时器 $RTO_min$ 为 200ms，数据中心网络正常 RTT 通常为 200µs</li></ul></li><li><p>数据中心网络传输协议近年来<strong>主要面临的问题</strong>有：</p><ul><li>TCP Incast 问题</li><li>低延迟、高吞吐性能需求</li><li>多任务模式等（对于FCT有要求）</li></ul></li><li><p>最近发表的一个研究([3])表明，网络中由于低效的链路带宽利用率，平均<strong>有 7.25% 的数据流未能在截止时间前完成</strong>。</p></li><li><p>TCP的设计采用平<strong>均分配带宽原则</strong></p></li><li><p><strong>截止时间流和非截止时间流</strong></p><ul><li>尽管数据中心网络中<strong>有截止时间流</strong>所占比率很低，大概是所有流量的 5%。</li><li><strong>非截止时间流</strong>的应用彼此不同。有些应用像 VM 迁移或者数据备份等，在传输开始前就可以得知该流的大小，然而对于一些像数据库存取和 HTTP 分块传输的应用，这些应用在他们传输开始之前不知道流大小或者截止时间相关信息。<ul><li>因此，对于非截止时间流，较短的流完成时间和较高的吞吐率是他们的<strong>主要性能指标</strong>。</li></ul></li></ul></li></ul><h1 id="HULL"><a href="#HULL" class="headerlink" title="HULL"></a>HULL</h1><ul><li>high-performance ultra-low latency</li><li>他从三个层次来进行了设计：<ul><li>Phantom queues: Detecting and signaling congestion<ul><li>这个机制是一种为了创建剩余buffer提出的一种机制，也就是我们常说的bandwidth headroom，通过减少长流带宽来获取更高的短流效率，在端口使用仿真的虚拟队列基于链路利用率而不是利用队列的占有率来设计ECN标记。</li></ul></li><li>DCTCP: Adaptive reaction to ECN</li><li>Packet pacing<ul><li>这个在前面的文章里面也讲了Pacing的实现原理，但是我们也分析过Pacing其实不一定会带来特别好的效果，是有一定条件的，所以这篇文章用了一个硬件pacer，感觉很厉害。但是本质还是按照固定间隔发送封包。</li></ul></li></ul></li></ul><h1 id="some-resources（博客资源-and-so-on）"><a href="#some-resources（博客资源-and-so-on）" class="headerlink" title="some resources（博客资源 and so on）"></a>some resources（博客资源 and so on）</h1><p><span class="exturl" data-url="aHR0cHM6Ly9zcXVpZGFydGguY29tL3JjL3Byb2dyYW1taW5nL25ldHdvcmtpbmcvMjAxOC8wNy8xOC9pbnRyby1jb25nZXN0aW9uLmh0bWw=">squidarth:intro congestion-control<i class="fa fa-external-link-alt"></i></span></p>]]></content>
      
      
      <categories>
          
          <category> Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>建站 | Jekyll -》 mkdocs -》 hexo</title>
      <link href="/siteBuilding/"/>
      <url>/siteBuilding/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Jekyll"><a href="#Jekyll" class="headerlink" title="Jekyll"></a>Jekyll</h1><p>之前是用的jekyll，但是没找到我想要的全局搜索功能，有兴趣的还是可以看下：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA0MTg0NzIw">Jekyll建站<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="mkdocs"><a href="#mkdocs" class="headerlink" title="mkdocs"></a>mkdocs</h1><blockquote><p>其实Jekyll已经省去了很多麻烦了，但是我真的真的很烦每个md开头要写一大段乱七八糟的配置，不方便迁移，所以就转到mkdocs了，虽然模板的页面效果没有Jekyll丰富，但是对懒人还是极其友好的。</p></blockquote><blockquote><p>本来想用mkdocs的，毕竟还是挺省事儿的，文件结构也很清晰，学神点拨下我发现hexo可以全局搜索，跟mkdocs的标题搜索等级比起来，更香了！<br>简单学了下，后续可能考虑用mkdocs做一些项目文档手册，作为子网址吧，做手册挺合适的。</p></blockquote><h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cueG5jb2RpbmcuY29tLzIwMjAvMDMvMDEvdG9vbC9ta2RvY3MuaHRtbA==">蛮详细的，尤其是关于yml配置文件相关的<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d1dG9uZ3RyZWUuZ2l0aHViLmlvL2Rldm9wcy9tYW5hZ2UteW91ci1jbXMtdXNpbmctbWtkb2Nz">配置也很详细，尤其有一些关于mkdocs的冷知识<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC9menhpYW9tYW5nZS9ibG9nLzMwMTA5MjE=">列了一些注意事项，which我也觉得很重要<i class="fa fa-external-link-alt"></i></span></li><li>这个没仔细看，但是感觉很高贵的样子 <span class="exturl" data-url="aHR0cHM6Ly90b3V0aWFvLmlvL3Bvc3RzL3Q5M2E1Yy9wcmV2aWV3">将 Jupyter 自动发布到 GitHub Pages<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="配置中遇到的问题"><a href="#配置中遇到的问题" class="headerlink" title="配置中遇到的问题"></a>配置中遇到的问题</h2><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0b25lOTE1OS9hcnRpY2xlL2RldGFpbHMvNzkwNzEzMTY=">py37下字符编码遇到的问题<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h1><blockquote><p>我的两个config.xml（_config.next.xml是对应next主题的配置）都做了比较详细的注释，大家改起来也会很方便，欢迎在我的基础上修改！（虽然我本来也就是改学神的 :)</p></blockquote><h2 id="ref-1"><a href="#ref-1" class="headerlink" title="ref"></a>ref</h2><ol><li><p>环境配置请参考：<span class="exturl" data-url="aHR0cHM6Ly9scnNjeS5naXRodWIuaW8vMjAxNy8xMS8xMC9VYnVudHUtR2l0aHViLWlvLWNvbmZpZy1IZXhvLw==">linux下使用hexo建站<i class="fa fa-external-link-alt"></i></span>    </p><blockquote><ul><li>安装的时候提示8.x已经deprecated，所以我按照提示安装了12.x</li><li>在服务器上跑<code>npm install -g hexo-cli</code>等命令的时候，会遇到权限不够，根据提示给sudo就行</li></ul></blockquote></li><li><p>推送过程和基本配置网上已经很多了</p><blockquote><ul><li>next主题的仓库已经过期，我用的是学神给的这个：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0">https://github.com/theme-next/hexo-theme-next<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly90ZGluZy50b3AvYXJjaGl2ZXMvNDJjMzhiMTAuaHRtbA==">next主题的基本设置<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85NDAzODY4OA==">hexo主题进阶设置<i class="fa fa-external-link-alt"></i></span></li></ul></blockquote></li><li><p>其他trivial的可选功能</p><blockquote><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9kNjhkZTA2N2VhNzQ=">Hexo添加Disqus评论<i class="fa fa-external-link-alt"></i></span></li><li>hexo添加google-analytic功能 （ 不想做了2333累了</li></ul></blockquote></li></ol><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><p>hexo new ‘文章标题’<br>hexo new draft<br> hexo clean</p><blockquote><p>清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。</p></blockquote><p>hexo g<br>hexo s<br>hexo d</p><hr><h1 id="mkdown-图床-获取-永久链接-（-香"><a href="#mkdown-图床-获取-永久链接-（-香" class="headerlink" title="mkdown+图床 获取 永久链接 （ 香"></a>mkdown+图床 获取 永久链接 （ 香</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA3NjIyMjAy">我之前写的文章：typora+gitee图床<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h1><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC81YzQxN2RhNzUxODgyNTI1YzYzODA5Y2Q=">简单入个门<i class="fa fa-external-link-alt"></i></span></li><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC82ODU0NTczMjE4Nzc5MzgxNzcz">hexo+Actions保姆教程<i class="fa fa-external-link-alt"></i></span></li></ul><p>本来想自己写的，结果学神也用的actions，哈哈作业一抄到底 （ docker确实不太精通啊…  - -||| ）</p><hr><h1 id="miscelleous"><a href="#miscelleous" class="headerlink" title="miscelleous"></a>miscelleous</h1><ul><li><input disabled="" type="checkbox"> 添加多个部署源<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">deploy</span>:</span><br><span class="line">- <span class="attribute">type</span>: git</span><br><span class="line">  <span class="attribute">repo</span>:</span><br><span class="line">- <span class="attribute">type</span>: heroku</span><br><span class="line">  <span class="attribute">repo</span>:</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 程序员的自我修养 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN Prediction of TCP Transmission States(NCA&#39;18)</title>
      <link href="/PaperReading/RNN%20Prediction%20of%20TCP%20Transmission%20States(NCA&#39;18)/"/>
      <url>/PaperReading/RNN%20Prediction%20of%20TCP%20Transmission%20States(NCA&#39;18)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>NCA’18  @ IEEE (network computing and application)</p><h2 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h2><blockquote><p>关于序列学习和时间序列预测模型，长短期记忆（LSTM）神经网络是最先进的技术。在本文中，我们已使用基于LSTM的递归神经网络（RNN）为被动测量建立传输控制协议（TCP）连接特性的通用预测模型。据我们所知，这是尝试将LSTM应用于展示网络运营商如何识别可确定网络状况的TCP客户端最重要的系统范围TCP每连接状态（例如cwnd）的第一项工作。从网络中间节点测得的无源流量中获取，而无需访问发送方。我们发现LSTM学习者的表现优于最新的经典机器学习预测模型。通过在多种情况下进行的广泛实验评估，我们证明了该方法的可扩展性和鲁棒性，以及其从被动测量中监视与网络拥塞相关的TCP传输状态的潜力。我们基于仿真和现实环境的结果表明，深度学习是一种用于从被动测量监视系统范围TCP状态的有前途的工具，并且我们相信本文中介绍的方法可以加强计算机网络社区的未来研究工作。</p></blockquote><p>看起来是根据中间节点的信息去预测终端的拥塞窗口等属性 ?</p><h2 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h2><p>在本文中，我们对基于仿真和现实网络的RNN模型估计TCP cwnd的能力以及流中的基础TCP变体感兴趣。</p><blockquote><p>因此，我们探索了一种基于RNN的预测方法的LSTM架构，以通过与网络拥塞相关的被动测量来监视最重要的TCP每个连接状态。在我们的论文中，我们证明了LSTM可以使用其内存块和一系列门来有效地从被动测量中捕获TCP cwnd的模式。拥塞控制是计算机网络中的一个基本问题。当今广泛部署的TCP拥塞控制算法执行了与拥塞控制相关的最重要功能，例如从发送方处理cwnd。</p></blockquote><p>在本文中，我们定量地研究和探索了问题，因为这些问题适用于网络拥塞问题，其中包括：</p><ul><li>我们如何能够根据从网络的中间节点收集到的passive traffic中，很好地推断出最重要的TCP每连接传输状态，？ 【怎么建模】  <blockquote><p>?? 不知道如何翻译 infer the most important TCP per-connection transmission states that determine a network condition</p><ul><li>如何从被动测量中唯一地跟踪TCP客户端使用的underlying TCP variant？    【如何判别TCP variant】</li></ul></blockquote></li><li>为什么需要知道TCP发送者使用哪种算法是什么？ </li><li>在了解发送方的基础TCP变体的信息之后，我们是否会采取某些措施？</li><li>哪个用户负责网络中的大部分繁忙流量？等等。？<blockquote><p>(i) How well can we infer the most important TCP per-connection transmission states that determine a network condition from a passive traffic collected at an intermediate node of the network?<br>(ii) How can we uniquely track the underlying TCP variant that the TCP client is using from passive measurements?<br>(iii) What is the motivation why we need to know which algorithm the TCP sender is using? (iv) Is there some action that we would take based on knowing the information of the underlying TCP variant of the sender?<br>(v) Which user is responsible for the majority of heavy flow traffic in the network? etc.?</p></blockquote></li></ul><h3 id="前人工作"><a href="#前人工作" class="headerlink" title="前人工作"></a>前人工作</h3><blockquote><ul><li>先喷了04年的一篇文章  用状态机建模的  讲了两个缺陷  一个是可扩展性-》每个TCP variant都会需要建立一个状态机模型；另一个就是…（看文章叭）<br>然后就说没啥前人工作了。。。</li></ul></blockquote><p><code>&quot;在我们广泛地调查了现有的从被动测量监测TCP传输状态的工作之后，我们相信，对于使用基于RNN的技术的大多数广泛使用的TCP变体，在不知道发送方cwnd的情况下，对于预测cwnd和从被动通信量中唯一识别底层TCP控制算法类型的可伸缩方法，目前还没有太多的工作&quot; </code></p><blockquote><p>据我们所知，这是第一项尝试使用LSTM [14]来推断最重要的TCP每连接状态的工作，该状态根据网络中间节点收集的被动流量确定了网络状况，而没有sender的访问权限。正如我们在实验结果中所展示的，我们的预测模型比其他方法有很多好处。</p></blockquote><h3 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h3><ul><li>使用中间节点的被动测量信息和LSTM模型进行建模</li><li>方法是健壮、可扩展的</li><li>在模拟器上train，迁移到实际环境中效果不错</li><li>我们通过几个受控实验(controlled exp 不知道咋翻译..)广泛验证了我们的预测模型的鲁棒性和可扩展性方法，并在模拟，现实和组合场景设置中进行了实验验证。</li></ul><blockquote><p>• 我们演示了中间节点（例如，网络运营商）如何识别与TCP流相关的TCP客户端的传输状态，并使用LSTM递归模型根据被动测量预测发送方的拥塞窗口（cwnd）大小。<br>•我们通过提供一个健壮和可扩展的方法来唯一标识TCP客户端正在使用的广泛部署的基础TCP变量，从而探索基于LSTM的预测模型的适用性。<br>•我们证明，通过在实际场景设置中应用和转移模拟网络中的训练有素的知识，学习的预测模型可以很好地发挥作用。因此，我们的预测模型与机器学习社区中的转移学习概念大致相似[26]。<br>•我们通过几个受控实验广泛验证了我们的预测模型的鲁棒性和可扩展性方法，并在模拟，现实和组合场景设置中进行了实验验证。</p></blockquote><h2 id="2-motivation"><a href="#2-motivation" class="headerlink" title="2 motivation"></a>2 motivation</h2><p>我们的工作主要是由第一节中提出的问题引起的。拥塞控制算法在提高Internet上TCP的性能方面起着至关重要的作用[6]。但是，==当TCP算法的不同变体共存于网络中时，它们可能相互影响==。<br>==解决此问题的一种方法是通过预测cwnd并唯一标识基础TCP变量来单独控制TCP流。==</p><h3 id="Benefits"><a href="#Benefits" class="headerlink" title="Benefits"></a>Benefits</h3><p>讲了两个实际中该问题的应用背景 :</p><ul><li>可以唯一识别(identify)每个TCP连接，可以看看内容提供商有没有超额使用(TCP不公平现象检测)</li><li>从中间节点推测出更多信息，用于诊断拥塞原因</li></ul><blockquote><p>从运营的角度来看，此信息对于网络运营商(network operators)很有用，以监控主要内容提供商(content providers)（例如Google，Facebook，Netflix，Akamai等）是否正在操纵其服务器中的拥塞窗口，以实现超出其公平份额的目标带宽。运营商可能会发现此信息有用的另一种情况是，他们是否拥有一条由于客户投诉而导致其拥堵的路径，但是使用该路径的链接并没有被特别地订阅。在这种情况下，有关该路径上所有用户的拥塞窗口行为的详细信息可能有助于尝试诊断原因。从ISP的角度来看，我们认为有关端点中使用的TCP堆栈的知识对于进行大量流量工程和异常检测的大型ISP网络的运营商很有用[12]。</p></blockquote><h3 id="Methodological-Challenges"><a href="#Methodological-Challenges" class="headerlink" title="Methodological Challenges"></a>Methodological Challenges</h3><p>实践中；但是，从被动测量中预测TCP每个连接状态有许多困难。挑战之一是，例如，TCP数据包可能在发送方和中间监视器之间或监视器与接收方之间丢失。如果TCP数据包在到达中间节点之前丢失，并以某种方式重新传输，则无法确定是否发生了数据包丢失。因此，==中间监视器所看到的可能与发送方或接收方所看到的不完全相同。== 在[10]中更详细地介绍了我们确定的方法挑战，这些挑战涉及从被动测量中进行与网络拥塞相关的TCP每个连接状态的推断。在本文中，我们主张通过解决上述实际挑战，基于LSTM的方法可以从在中间节点收集的被动测量结果中提供更好的TCP发送方连接状态预测精度。</p><h3 id="Roadmap"><a href="#Roadmap" class="headerlink" title="Roadmap"></a>Roadmap</h3><blockquote><p>本文的其余部分安排如下：在第三节中，我们回顾并详细概述了被视为最新技术的TCP被动测量的紧密相关研究工作。在第四节中，我们描述了用于评估的实验装置。第五部分概述了我们的方法，重点介绍了本文中使用的机器学习技术和性能测量指标。第六节介绍了详细的实验结果以及用于验证我们的预测模型的多种方案设置。最后，第七节总结了论文并概述了未来扩展的研究方向。</p></blockquote><h2 id="3-related-work"><a href="#3-related-work" class="headerlink" title="3 related work"></a>3 related work</h2><p>本节简要讨论了有关通过被动测量来推断与网络拥塞相关的TCP每连接状态的紧密相关的研究工作。监视TCP每连接特征的技术分为两类：主动和被动测量。</p><p>主动测量</p><blockquote><p>已经提出的许多现有研究工作都依靠主动方法来测量TCP的特征。通过向至少两个端点之间的网络中注入人工流量，该技术可以主动测量Internet流的TCP行为[22，25]。它主要侧重于主动网络监视，并依赖于注入特定流量的能力，然后对其进行监视，以衡量从网络获得的服务。</p></blockquote><p>被动测量</p><blockquote><p>在被动测量中，检查被动收集的数据包迹线以测量Internet流的TCP行为[16]。</p><p>与我们的工作最密切相关的一项有趣的工作是[16]，它提供了一种被动的测量方法来推断和保持跟踪发件人变量：end-to-endRTT和cwnd的值。他们的想法是通过在发送方检测重传超时（RTO）事件并观察导致发送方更改cwnd值的ACK来模拟状态转换。这项工作[16]仅考虑了TCP的主要实现，其基本思想是为在中间节点观察到的每个TCP连接构造一个TCP发送者状态的副本。副本采用有限状态机的形式。但是，考虑到许多现有的TCP变体，无法对每个变体使用单独的状态机。我们还认为，考虑到大量数据，构造的副本[16]无法设法使转换反向或回溯。另一个限制是副本可能无法观察到与发送方相同的数据包序列，并且在中间节点处观察到的ACK也可能不会到达发送方。</p><p>==该研究的作者[27]开发了一种名为tcpflows的工具，该工具试图通过分析ACK流来检测TCP拥塞事件的发生，从而被动地估计cwnd的值并识别TCP拥塞控制算法。== 但是，使用tcpflowsis实现的状态机仅限于旧的TCP变体，因此无法唯一标识新的TCP拥塞控制算法。</p></blockquote><blockquote><p>我们的工作与以前的工作主要不同，我们的主要目标是从根本上开发一种==可扩展的基于LSTM的预测模型==，以便为使用最广泛的==基于损耗的拥塞算法==推断TCPper-connection状态。如果仅查看一个或两个TCP变体，则不同的TCP堆栈具有多种功能，这些功能将违反我们可能做出的假设。因此，在我们的工作中，为了覆盖问题的整个范围，我们考虑了使用最广泛的基于损耗的TCP算法变体，它们是==BIC [32]，CUBIC [9]和Reno [15]。==</p></blockquote><p>==这里提到了[27]A Passive State-Machine Based Approach for Reliable Estimation of TCP Losses. 2006 也是用于检测拥塞的 只不过还有局限性==</p><h2 id="EXPERIMENTAL-SETUP-AND-DISCUSSION"><a href="#EXPERIMENTAL-SETUP-AND-DISCUSSION" class="headerlink" title="EXPERIMENTAL SETUP AND DISCUSSION"></a>EXPERIMENTAL SETUP AND DISCUSSION</h2><h3 id="A-Experimental-Testbed"><a href="#A-Experimental-Testbed" class="headerlink" title="A. Experimental Testbed"></a>A. Experimental Testbed</h3><p>图2显示了本文中用于所有实验的实验设置。</p><ul><li>仿真网络+一条通信隧道以引入拥塞</li><li>iperf生成TCP流量  </li><li>单个TCP流中的参数带宽和延迟是恒定的，并且分布均匀；抖动作为平均值给出，因此其分布是正态的</li><li>我们在客户端节点上创建了相同的regular tcpdump of TCP packets，其中包括有关每个连接状态的信息，以便我们可以将tcpdump与TCP状态进行匹配。<blockquote><p>We created an identical regular tcpdump of the TCP packets on the client node including information about the per-connection states so that we can match the tcpdump with the TCP states. </p></blockquote></li><li>将测得的TCP数据当作输入，以预测TCP每个连接状态。使用Linux内核直接记录的实际TCP内核状态（仅用于培训）验证了预测的TCP状态，并为学习模型生成了新数据以进行预测。<blockquote><p>为了引入拥塞，我们首先创建了一个仿真网络，并在网络上放置了一条通信隧道，同时使用iperf流量生成器将TCP跨流量推送到网络[7]。我们通过捕获客户端和服务器发送TCP数据包时网络上的所有会话来进行实验。在我们实验的单个TCP流中，参数带宽和延迟是恒定的，并且分布均匀。但是，由于我们将抖动作为平均值给出，因此其分布是正态的。我们在客户端节点上创建了相同的常规TCP数据包tcpdump，其中包括有关每个连接状态的信息，以便我们可以将tcpdump与TCP状态进行匹配。如图2所示，我们将测得的TCP数据用作我们的方法输入，以预测TCP每个连接状态。最后，我们使用直接从Linux内核直接记录的实际TCP内核状态（仅用于培训）验证了预测的TCP状态，并为学习模型生成了新数据以进行预测。完成验证后，我们将运行学习模型并获得预测.</p></blockquote></li></ul><h3 id="B-Testbed-Hardware"><a href="#B-Testbed-Hardware" class="headerlink" title="B.Testbed Hardware"></a>B.Testbed Hardware</h3><blockquote><p>我们已经使用了一组基于GNU / Linux操作系统的HPC计算机集群进行了实验，该操作系统运行4.4.0-75-通用内核发行版的修改版。该预测模型是在具有以下特征的NVIDIA Tesla K80 GPU加速器计算上执行的：Intel（R）Xeon（R）CPU E5-2670 v3 @ 2.30GHz，64个CPU处理器，128GB RAM，在Linux 64-一点。群集中的所有节点都连接到低延迟56 Gbit / s Infiniband，千兆以太网，并可以访问600 TiB的BeeGFS并行文件系统存储。</p></blockquote><h3 id="C-Network-Emulation-and-Verification-of-the-emulator"><a href="#C-Network-Emulation-and-Verification-of-the-emulator" class="headerlink" title="C. Network Emulation and Verification of the emulator"></a>C. Network Emulation and Verification of the emulator</h3><p>==对于网络仿真，我们在单独的节点上使用了基于Linux的流行网络仿真器（NetEm）[13]，该仿真器支持带宽，延X迟，抖动，丢包和其他参数的等对cwnd赢下给比较大的参数。==</p><ul><li>另一个问题是软件仿真器不够精确  ——》 作者在此提出了一个验证方法(具体没有怎么看懂，也许并不重要??)</li></ul><blockquote><p>鉴于软件仿真器不够精确，我们是否可以信任网络仿真器来评估我们为评估而更改的所有带宽，延迟，抖动和丢包参数的变化，而不考虑我们从TCP流获得的测量结果？<br>为了在极为完善的环境中谨慎使用网络仿真器来处理所有参数的变化，我们创建了一个过滤器来设置每个数据包的参数变化。由于无法从TCP流中测量仿真器的精度，因此我们使用UDP进行了另一项实验，以评估和测量仿真器和流量生成器均会产生偏差的精度。<br>我们通过测量由接收方的流量生成器和网络仿真器创建的带宽，延迟，抖动和数据包丢失变化来验证原始性能。</p><p>Given that the software emulator is not precise, can we trust the network emulator for all the variations of bandwidth, delay, jitter and packet loss parameters that we change for our evaluation irrespective of the measurement we get from TCP stream? </p><p>In order to use the network emulator with great care in an extremely well-contained environment for all the variations of the parameters, we created a filter that sets the parameter variation of each packet. As the precision of the emulator cannot be measured from TCP streams, we set up a different experiment using UDP to evaluate and measure the precision where both the emulator and traffic generator create variations. </p><p>We verified the raw performance by measuring the bandwidth, delay, jitter and packet loss variations created by the traffic generator and network emulator at the receiver side.</p></blockquote><h3 id="D-Impact-of-Cross-traffic-Variability"><a href="#D-Impact-of-Cross-traffic-Variability" class="headerlink" title="D. Impact of Cross-traffic Variability"></a>D. Impact of Cross-traffic Variability</h3><p>结论：</p><ul><li>仿真器运行的每个变化都不会影响我们的结果–》交叉流量的可变性不会影响我们的分析</li><li>cwnd可变性取决于所使用的特定TCP拥塞控制</li><li>仿真器可能会受到其范围之外的网络元素的影响，例如CPU负载，网卡缓冲区，硬件架构因素等<blockquote><p>我们运行NetEm [13]时，客户端和服务器之间的数据速率和仿真参数有所不同。我们通过模拟其他UDP流量，仔细研究并验证了来自同一TCP拥塞协议的跨业务量变化对结果的影响，我们发现，仿真器运行的每个变化都不会影响我们的结果。我们认为，在当前设置中交叉流量的可变性不会影响我们的分析。通常，当涉及到cwnd可变性时，它将取决于所使用的特定TCP拥塞控制。我们还认为，仿真器可能会受到其范围之外的网络元素的影响，例如CPU负载，网卡缓冲区，硬件架构因素等。  </p></blockquote></li></ul><h3 id="E-Network-Traces"><a href="#E-Network-Traces" class="headerlink" title="E. Network Traces"></a>E. Network Traces</h3><h3 id="F-Network-Emulation-Parameters"><a href="#F-Network-Emulation-Parameters" class="headerlink" title="F. Network Emulation Parameters"></a>F. Network Emulation Parameters</h3><p>为了在仿真和实际网络条件下评估我们的预测模型，我们使用tcptrace [24]生成了自己的数据集。我们所有实验的数据轨迹都是使用iperf [7]流量生成器在模拟的LAN链路上生成的，在该LAN链路上，我们运行每个TCP变量，并改变了参数带宽，延迟，抖动和数据包丢失，如表I所示，其中cwnd极其受影响。==但是，内核可能会将数据包的TCP每次连接状态保留在缓冲区中，并等待足够数量的数据包，然后再将TCP状态发送到用户空间。由于用户空间进程的TCP进程缓慢，TCP的每个连接状态也可能会丢失。== </p><p>？？<br>因此，作为合理性检查(sanity check)，我们要做的第一件事就是在发送方和接收方都捕获数据包，因为它有助于我们知道数据包是丢失还是从未发送过，因为从接收方到发送方的ACK与数据包以推断数据包丢失。这样，可以验证流量捕获是否相同，并且每个连接的TCP状态都没有丢失。</p><p>为了避免丢失数据包并在发送方上和monitor上捕获完全相同数量的数据包，我们执行的第二件事是==调整缓冲区大小并将缓冲区刷新到用户空间==。通过禁用TCP分段卸载，我们在巨型帧清洁的路径上进行了实验，从而可以避免数据包大小超过常规合法大小。</p><blockquote><p>Therefore, the first thing we did as a sanity check is to capture the packets at both the sender and the receiver for it helps us to know whether a packet was lost or just never sent as the ACKs from receiver to sender are just as important as the data packets for inferring packet loss. This way, it is possible to verify if the traffic captures are identical and there are no missing per-connection TCP states. </p><p>The second thing we carried out in order to avoid missing of packets and capture exactly the same number of packets on the sender and the monitor is tuning the buffer size and flush the buffer to the userspace. We carried out our experiment over a path that is jumbo-frame clean by disabling TCP segmentation offloading so that we can avoid packet sizes way over the regular legitimate size.</p></blockquote><p>TCP拥塞控制设置为根据带宽，不同的交叉流量，RTT等的可变性进行操作。因此，为了创建现实的场景，我们在设置中模拟了网络，如图2所示，通过在一条流中向表I中列出的重要网络仿真参数添加可变性。</p><h3 id="G-Assumptions"><a href="#G-Assumptions" class="headerlink" title="G. Assumptions"></a>G. Assumptions</h3><p>在TCP中，cwnd是决定随时可以处理的字节数的主要因素之一。 因此，我们假设在存在带宽变化，延迟， 损失和RTT情况下，使用（大概理解为bytes in flight)==the observed outstanding sequence of unacknowledged bytes on the network seen at any point in time in the lifetime of the connection as an estimate of the sending TCP’s cwnd from tcptrace==是一种更好的方法来估算cwnd以及恢复速度的方法。<br>首先，由于我们是根据飞行中的字节估算cwnd的，因此我们还考虑了cwnd肯定是是发送方的限制因素的事实，以及cwnd必须小于接收方的窗口的事实。<br>其次，我们假设我们不知道网络中正在运行什么TCP变体以及该变体中的每个连接状态。<br>最后，我们在本文中给出的结果是基于如下假设的:端点具有与操作系统无关的、由底层操作系统独立设置的相同接收器窗口(receiver window)。</p><h2 id="5-METHODOLOGY"><a href="#5-METHODOLOGY" class="headerlink" title="5 METHODOLOGY"></a>5 METHODOLOGY</h2><p>本节说明了我们用于通过基于RNN的技术从被动测量中通过实验推断cwnd和唯一标识基础TCP变体的通用方法。</p><h3 id="A-Passive-Monitoring-of-bytes-in-flight"><a href="#A-Passive-Monitoring-of-bytes-in-flight" class="headerlink" title="A. Passive Monitoring of bytes in flight"></a>A. Passive Monitoring of bytes in flight</h3><p>TCP拥塞控制算法通过使用cwnd来控制TCP发送方的发送速率，该cwnd限制了在任何给定时间允许的累积未确认字节的数量。 如图2所示，在中间节点处收集的测得的被动TCP数据用于我们模型的训练实验。 在监视点看不到TCP实现的详细信息和TCP选项的使用。 TCP发送器还通过内核中的两个变量来跟踪未完成的字节：snd nxt（要发送的下一个数据包的序列号）和snd una（最小的未确认序列号）。</p><h3 id="B-Prediction-of-TCP-cwnd-from-Passive-Traffic"><a href="#B-Prediction-of-TCP-cwnd-from-Passive-Traffic" class="headerlink" title="B. Prediction of TCP cwnd from Passive Traffic"></a>B. Prediction of TCP cwnd from Passive Traffic</h3><p>cwnd是TCP每次连接状态内部变量，表示发送者可以根据发送者的网络容量和条件在任何给定时间点潜在传输的最大数据量。 TCP [15]使用cwnd来确定在任何给定时间没有被发送方独立维护以进行拥塞避免的情况下，未确认的最大字节数。图3显示了在运行神经模型和应用LSTM技术之前，来自中间节点的未完成字节数与从发送方内核跟踪的实际cwnd之间在时间方面的比较。</p><blockquote><p>考虑到TCP的本质，通过检查中间节点被动收集的端点的TCP流的每个交叉流量来准确推断发送者的cwnd是一项具有挑战性的任务，因为它不做广告。我们尝试估计cwnd的一种初始方法是处理tcpdump中流的数据包头，并根据跟踪集计算汇总的TCP交叉流量，并将其添加为asa功能。然而，我们在实验中发现对于准确的预测而言，细节不足。在本文中，我们认为利用基于RNN的算法训练分类器和预测模型来从被动测量中预测cwnd非常重要。</p></blockquote><p><strong>Learning Context</strong></p><blockquote><p>我们使用带有TensorFlow后端的Keras深度学习框架，构建了高度健壮且可扩展的基于RNN的预测模型，</p></blockquote><ul><li>cwnd批量大小为32。</li><li>在t的每个时间步长处，LSTM模型都将飞行中的未完成字节的整个数组作为输入特征向量（x），该向量由从内核获得的时间戳索引。</li><li>多层LSTM单元 + 15维隐藏状态的dense layer + ReLU激活函数(==?最后一层居然也ReLU==) –&gt; 输出 a sequence dimensional vector of predicted cwnd (y) of the same size indexed by time stamp.</li><li>经过时间截断的反向传播（TBPTT）训练算法进行训练 | Adam 默认学习速率为0.001 | RMSE 和 MAPE(Mean Absolute Percentage<br>Error) 同时作为损失函数的评价指标 (？具体怎么综合起来的待后面考查)</li></ul><h3 id="C-Prediction-of-TCP-Variants"><a href="#C-Prediction-of-TCP-Variants" class="headerlink" title="C. Prediction of TCP Variants"></a>C. Prediction of TCP Variants</h3><p>对于基本的TCP变体预测任务，仅考虑了基于丢包的TCP拥塞控制算法(loss-based)(e.g., CUBIC [9] BIC [32], and Reno [15]) 用预测出来的cwnd去判断β值(back-off parameter) &lt;– 对于AIMD的拥塞控制算法来说，β值是一个很典型的特征。</p><h2 id="6-EXPERIMENTS-AND-RESULTS"><a href="#6-EXPERIMENTS-AND-RESULTS" class="headerlink" title="6 EXPERIMENTS AND RESULTS"></a>6 EXPERIMENTS AND RESULTS</h2><blockquote><p>本节总结了几个实验结果。针对每个TCP做了36种配置，如表I所示，总共216种在实验(?咋算的..)实验评估中，给出其中一个测试方案配置并给出CUBIC [9]，BIC [32]和Reno [15]三个baseline的测试效果。</p></blockquote><p>==TCP cwnd模式预测模型是在训练和测试样本大小比率的不同配置下评估的。==</p><ul><li><p>如上图所示，==我们发现了用于预测cwnd的基于RNN的模型可以非常准确地捕获cwnd下降的比率。== </p><blockquote><p>图6（a）和（b）没有共享相同的带宽，延迟，损耗和抖动配置，这会导致在连接过程中最大段数有所不同。例如，如果我们在图6（b）上看到，它的带宽延迟乘积（BDP）[17]为700mb * 0.01s = 875,000字节（logic here:这个和1500都是configuration）。在1500个字节段中，即583个段，而我们的仿真显示cwnd的最大段数为500-600。在下面显示的所有图中，==我们可以看到，一旦发生超时，响应3个重复的ACK，所有数据包丢失都会得到快速恢复。这是因为cwnd不会低于其先前峰值的一半。== 结果是，存在一个线性增加阶段，随后是一个丢包事件，其中cwnd随着新到达的ACK而增加。这也演示了TCP拥塞控制算法如何响应拥塞事件。</p></blockquote></li><li><p>我们还可以看到，预测的cwnd的模式通常与实际的cwnd非常匹配，并且预测误差很小。我们使用从内核获得的精确时间戳来匹配锯齿模式的增加部分和减少部分。</p><blockquote><p>We can see that the pattern of the predicted cwnd generally matches the actual cwnd quite well with a small prediction error. We matched both the increasing and decreasing parts of the sawtooth pattern using the precise timestamp obtained from the kernel.</p></blockquote></li></ul><h2 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h2><ul><li>对于基本的TCP变体预测任务，仅考虑了基于丢包的TCP拥塞控制算法(loss-based)</li><li>首创性(被动测量 中间节点 LSTM) 、 可扩展性 (scalable)</li><li>使用iperf制造数据包  使用tcptrace构建数据集</li></ul><h2 id="question"><a href="#question" class="headerlink" title="question"></a>question</h2><ul><li>Network Emulation Parameters中“但是，内核可能会将数据包的TCP每次连接状态保留在缓冲区中，并等待足够数量的数据包，然后再将TCP状态发送到用户空间。由于用户空间进程的TCP进程缓慢，TCP的每个连接状态也可能会丢失”不是很明白<ul><li>对应的==调整缓冲区大小并将缓冲区刷新到用户空间==  不是很明白这是在干什么<br>这两天找yanshu问下【！！！！】</li></ul></li><li>G. Assumptions 中的一些假设不是很懂在干什么 …. 目的何在？</li><li>使用tcptrace构建数据集指的应该是将检测到的信息里面的数据特征抽取出来？</li><li>仅考虑了基于丢包的TCP拥塞控制算法(loss-based)(e.g., CUBIC [9] BIC [32], and Reno [15])  –&gt; BIC是基于loss的么？？？</li><li>针对每个TCP做了36种配置，如表I所示，总共216种在实验(?咋算的..)</li><li>FIG6为什么跌破的时候没有跌到一半 反而比一半多一点<br>  这个逻辑是什么<blockquote><p>我们可以看到，一旦发生超时，响应3个重复的ACK，所有数据包丢失都会得到快速恢复。这是因为cwnd不会低于其先前峰值的一半。<br>  是后面是前面的现象的意思么  所以快恢复难道不是设置成一半么。。。</p></blockquote></li><li>这啥意思<blockquote><p>我们还可以看到，预测的cwnd的模式通常与实际的cwnd非常匹配，并且预测误差很小。我们使用从内核获得的精确时间戳来匹配锯齿模式的增加部分和减少部分。</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> PaperReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeePCCI(SIGCOMM&#39;19)</title>
      <link href="/PaperReading/DeePCCI(SIGCOMM&#39;19)/"/>
      <url>/PaperReading/DeePCCI(SIGCOMM&#39;19)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><blockquote><p>拥塞控制（CC）[12]是当今传输协议的基本组成部分，并强烈影响数据传输的性能。 CC最初建于1980年代以应对早期Internet的拥塞崩溃[17]，但CC仍在发展，并且出现了新的变体，例如BBR [1]或Vivace [3]。</p></blockquote><blockquote><p>CC引入了一个拥塞窗口（cwnd），该窗口限制了飞行中未确认字节的数量。==每种CC算法都定义了在特定算法定义的拥塞信号下，cwnd的变化情况==。给定CC方法的数量及其对性能的影响[9]，因此研究CC的使用方法很重要。例如，如果知道新的CC通常会与哪些其他算法竞争，则为公平起见，更容易对其进行调整。</p></blockquote><h2 id="传统的缺点"><a href="#传统的缺点" class="headerlink" title="传统的缺点"></a>传统的缺点</h2><blockquote><ul><li>但是，用于识别CC变体的现有工作（例如[2、18、24]）不适用于最新的CC和传输协议。==扩展和维护这些方法很复杂，因为它需要详细的领域知识才能知道CC参数化和配置如何影响其行为。== 当CC离开内核并引入用户空间协议（例如QUIC [11]）时，这一点变得尤为重要，这些协议相当容易更改，并且已经可以大规模部署[21]。</li></ul></blockquote><blockquote><ul><li>==此外，许多识别方法都基于fragile assumptions。== 例如，当使用TCP pacing （例如，与RENO [12]或CUBIC [5]结合使用）时，它们将失败。</li><li>*令人担忧的是，我们已知的所有被动方法都基于头部信息is parsable的的假设**。完全加密的传输（例如QUIC实施方案）使这些设计无效，并且如果可能的话，将需要进行重大更改。</li></ul></blockquote><p><strong>因此，目前就推理部署CC提出挑战。</strong></p><h2 id="难点与贡献"><a href="#难点与贡献" class="headerlink" title="难点与贡献"></a>难点与贡献</h2><p>作为应对这些挑战的第一步，本文介绍了DeePCCI，这是一种基于监督的基于深度学习的被动拥塞控制识别方法。<br>==它仅根据流数据包到达时间信息识别CC变体，因此甚至可以在加密的传输头上使用。==<br>此外，它使用深度学习来学习功能-从而避免了手动的，特定于领域的功能设计。<br>因此，与相关方法不同，==DeePCCI除了流分组定时的可用性之外，不做任何假设，== <strong>除了能够收集CC变体的训练流量之外，不需要任何领域知识。</strong><br>我们认为，这种假设和免手动调整方法允许在Internet流量中进行通用且可扩展的CC标识。具体来说，我们介绍DeePCCI的设计，评估及其局限性，并做出以下贡献：</p><p>•我们描述了流量的预处理和用于识别拥塞控制变量的深度学习模型。<br>•我们介绍了如何在测试平台上生成带有标记数据的多种拥塞控制变量模型。</p><p>我们评估了CUBIC，RENO和BBR作为主要拥塞控制变量的测试平台的性能。我们展示了该方法能够在各种情况下识别流量拥塞控制变量，但同时也介绍并讨论了无法识别拥塞控制变量的情况。结构体。第2节讨论了CC识别的最新技术及其缺点。第3节介绍DeePCCI的设计，而第4节介绍我们如何生成训练数据和评估我们的方法。最后，第5节总结了论文并讨论了未来的工作。</p><h1 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h1><blockquote><p>各种工作涉及识别CC变体。这些方法主要分为两类：使用被动[2、6、13、18、20]或主动[19、24]测量的识别方法。</p></blockquote><blockquote><p>主动方法可通过主动打开并操纵CC来激发CC反应进行检测。 Padhye和Floyd提出了TBIT [19]，该协议将精心制作的TCP段发送到Web服务器以主动触发拥塞控制。它记录响应丢失的数据包发送了哪些段，因为这种反应在TBIT中所区分的CC变体之间有很大差异。<br><br><br>杨等。目前的CAAI [24]扩展了TBIT的方法。为了估计发送方的cwnd，CAAI人为地延迟了观察所有飞行段的ACK。然后，CAAI导致数据包丢失，并从变化的cwnd中提取特征。这些功能随后用于使用随机森林进行分类。虽然这两种方法都可以实现较高的识别精度，但是由于错误选择的主机，因此依靠主动测量很容易引入测量偏差。<br><br><br>被动方法（与我们一样）不与主机交互，而是依靠流量跟踪来推断使用的流量CC变体，因此，它们允许收集有关实际流量的信息，该信息取决于有利位置而不是主动选择的主机。<br><br><br>Paxson等。和Jaiswal等。使用tcpanaly [20]和tcpflows [13]重建TCP状态机，以比较接收到的数据包和预期数据包。两种方法都需要非常详细的CC甚至实施知识来重建状态机。我们的方法的不同之处在于它不需要详细的CC知识。卡萨格兰德等。 [2]将cwnd中的特征更改用作其方法TCPMoon中的特征。针对这些功能检查了不同的手工规则，以区分CC。对于cwnd估计，作者使用基于TCP时间戳的RTT估计。因此，使用TCPMoon无法识别没有TCP时间戳选项或加密了传输头的流。由于我们的方法仅观察数据包到达的行为，因此不需要任何明文传输协议字段。<br><br><br>Oshio等。 [18]提出了一种基于聚类的方法。他们根据RTT估计值提取cwnd的特征并将其聚类以区分两个竞争的CC变体。我们的方法的不同之处在于，它不仅限于两个相互竞争的变体。哈戈斯等。<br><br><br>[6]使用发送方和接收方之间的未完成字节作为粗略且嘈杂的cwnd估计。使用递归神经网络对该估计值进行细化。精简后的Cwnd的突然减少用作CUBIC，BIC和RENO之间不同的乘法减少因子的估计。尽管此方法使用深度学习是相似的，但它仍然需要手动设计的乘数递减因子，因此只能识别基于损失的CC。我们的方法使用端到端深度学习模型，还识别基于延迟的CC并避免使用手动功能。</p></blockquote><h2 id="active-measurements"><a href="#active-measurements" class="headerlink" title="active measurements"></a>active measurements</h2><ul><li>制造丢包现象（ 通过延迟ack的发送或者是发送crafted packets to senders ）获得终端的变化情况<ul><li>获取了特征数据以后使用随机森林的方法</li></ul></li></ul><h2 id="passive-measurements"><a href="#passive-measurements" class="headerlink" title="passive measurements"></a>passive measurements</h2><ul><li>gather information on real traffic on vantage points ，而不是像active measurements那样观测主动选好的hosts</li><li>rebuild TCP  state machine –》 需要detailed CC domain knowledge and implementation knowledge</li><li>建模去估计Cwnd changes –》 like 使用TCP的时间戳来估计RTT （ 加密了以后就不适用了</li></ul><p><br><br><br></p><h1 id="DeePCCI-design"><a href="#DeePCCI-design" class="headerlink" title="DeePCCI design"></a>DeePCCI design</h1><h2 id="CC-Manifestaion-in-Traffic"><a href="#CC-Manifestaion-in-Traffic" class="headerlink" title="CC Manifestaion in Traffic"></a>CC Manifestaion in Traffic</h2><ul><li>only use <strong>arrival time</strong> of a flow as input<ul><li>unlike Netflow 是什么意思 ？ Netflow没有packet timing嘛</li><li>目的 :associate packets to flow</li></ul></li></ul><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://images.weserv.nl/?url=https://img-blog.csdnimg.cn/20190924094304705.png" alt="在这里插入图片描述"></p><h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><ul><li>用于特征提取</li><li>改进了VGG net  结合了 residual network</li></ul><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>如果packet的size是固定的，就用VGGNet就够了 ，但是由于我们想看的是length-variant的packet，所以使用LSTM–》有记忆<ul><li>用的是unidirectional network     </li></ul></li></ul><p><br><br><br></p><h1 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h1><h2 id="Mininet-based-Network-Testbed"><a href="#Mininet-based-Network-Testbed" class="headerlink" title="Mininet-based Network Testbed"></a>Mininet-based Network Testbed</h2><ul><li>不同的网络环境<ul><li>TCP sender number</li><li>link latency</li><li>bottleneck link’s BDP</li></ul></li><li>选择了三个variant进行对比 ( RENO, CUBIC ,BBR ) <ul><li>每个发送60s 的fully-loaded TCP stream </li><li>观测者比发送者早2s开启     </li></ul></li></ul><h2 id="Single-Host-Network"><a href="#Single-Host-Network" class="headerlink" title="Single-Host Network"></a>Single-Host Network</h2><ul><li><strong>baseline condition</strong></li><li>哑铃状拓扑</li><li>没有背景流量</li></ul><h2 id="Multi-Host-Network"><a href="#Multi-Host-Network" class="headerlink" title="Multi-Host Network"></a>Multi-Host Network</h2><ul><li>reside on each side of the network</li></ul><h2 id="Cross-Traffic-Network"><a href="#Cross-Traffic-Network" class="headerlink" title="Cross-Traffic Network"></a>Cross-Traffic Network</h2><ul><li>side flow</li><li>main flow</li></ul><h2 id="performance"><a href="#performance" class="headerlink" title="performance"></a>performance</h2><h3 id="identifacation-by-Delay-and-Bandwidth"><a href="#identifacation-by-Delay-and-Bandwidth" class="headerlink" title="identifacation by Delay and Bandwidth"></a>identifacation by Delay and Bandwidth</h3><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>带宽越大、延迟越大、host越多越容易识别成功</li></ul><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><ul><li><p>带宽越大越成功是因为</p><ul><li>归因于拥塞窗口的整数离散化，而最大cwnd取决于瓶颈带宽。 ( 我的理解就是：允许的cc窗口的区别度高 ）</li><li>以较大的带宽采样了诸如CUBIC的cubic行为的更多步骤。 较低的带宽意味着较少的采样步骤，并且三次行为很难与例如RENO的线性行为相区别。</li></ul></li><li><p>认为延迟越大越成功</p><ul><li>与histogram的bin-size  有关<blockquote><p>我个人在这里的理解就是： bin-size 就有点像分辨率 如果延迟太小，会导致整个图被横向压扁；如果延迟大一点，整个图就会舒展开，一些特征啥的会更加清晰，容易被CNN识别、提取到<br>有点意思 :)</p></blockquote></li></ul></li><li><p>认为多主机效果更好是因为</p><ul><li>对于相同的延迟，多主机情况也能获得更好的结果。我们将此影响归因于流量竞争。当link饱和时，单主机流的速率不会随着cwnd的增加而迅速增加，<strong>但是在多主机方案中增加流的cwnd可以增加其在队列中的数据包的份额，从而增加其速率。</strong> <strong>因此，对不同拥塞控制变量的cwnd的单独更改会对速率产生更大的影响，从而更强烈地影响数据包到达</strong>，并在更长的时间内影响较小的延迟和带宽问题。</li></ul></li></ul><p><strong>【感觉这一点实际上是利用了这三种方案面对竞争时候的特性有所区别的特点，并不是说：Competing的时候会有种让CC增加cwnd的动力(只有发的多才能收的快 收的快才能滑动)  ，而应该说：面对 competing的时候有不同的特性，有的人会趋于让cwnd增大，所以对应的包发得多，到达的间隔就短了】</strong></p><blockquote><p>如我们所见，<strong>带宽和延迟会影响我们的方法</strong>，延迟/带宽过小会导致识别性能降低。<strong>为了进一步评估，我们将以50Mbps作为带宽</strong>继续进行实验，以更好地了解该方法在何处面临挑战。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> PaperReading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Congestion Control </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
