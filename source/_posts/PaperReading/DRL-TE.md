---
title: DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach
top: false
cover: false
toc: true
mathjax: true
date: 2020-10-19 10:25:51
categories: PaperReading
description: Infocom'18
tags:
    - Network
    - Reinforcement Learning
    - Routing
---



# hesy summary 

* 排队论不适合多跳排队问题的建模
  * 强假设不能满足
  * 多跳排队还是个open problem
    

# abstract

​	现代通信网络已经变得非常复杂且高度动态，这使其难以建模，预测和控制。 在本文中，我们开发了一种新颖的体验驱动方法，可以像人类学习新技能（例如驾驶，游泳等）一样，根据自身的经验而不是准确的数学模型来学习很好地控制通信网络。 具体来说，我们首次建议利用新兴的深度强化学习（DRL）在通信网络中实现无模型控制； 并针对基础网络问题：流量工程（TE），提出了一种新颖且高效的基于DRL的控制框架DRL-TE。通过共同学习网络环境及其动态性，并在强大的深度神经网络（DNN）的指导下进行决策，**所提出的框架最大程度地提高了广泛使用的效用函数**。**我们提出了两种新技术**，即TE感知探索和基于行为者批评的优先体验重播，以优化通用DRL框架，尤其是针对TE的框架。 为了验证和评估所提出的框架，我们在**ns-3**中实施了该框架，**并使用代表性和随机生成的网络拓扑进行了全面测试**。 广泛的数据包级仿真结果表明：1）与几种广泛使用的基准方法相比，DRL-TE显着<u>降低了端到端延迟</u>，并不断提高了网络实用性，<u>同时提供了更好或相当的吞吐量</u>；  2）DRL-TE对网络的变化更具有鲁棒性； 和3）DRL-TE始终优于最新的DRL方法（用于连续控制），即深度确定性策略梯度（DDPG），但是它不能提供令人满意的性能。

# introduction

​	已经进行了广泛的研究努力来开发用于通信网络的算法和协议，以有效地利用它们的资源。 传统的网络资源分配方法大多是基于模型的，它们假定可以很好地建模网络环境和用户需求。 然而，通信网络变得更加复杂且高度动态，这使其难以建模，预测和控制。 因此，我们的目标是开发一种新颖的，无需经验的无模型方法，该方法可以像人类学习技能（例如驾驶，游泳等）一样，从经验中学习很好地控制通信网络，而不是精确的数学模型。我们认为，某些新兴的联网技术，例如软件定义网络（SDN）[18]，可以很好地支持这种体验/数据驱动的方法。 例如，SDN中的**Openflow**控制器可以用作中央控制单元，用于收集数据，制定决策和部署解决方案。

​	一个基本的网络问题是流量工程（TE）：给定一组具有源节点和目标节点的网络流，请找到一种解决方案，以最大化实用功能为目标转发数据流量。 简单且广泛使用的解决方案包括：始终通过最短路径路由流量（例如，开放式最短路径优先（OSPF）[24]）； 或通过多个可用路径平均分配流量（例如，有效负载平衡**（VLB）[38]**）。 显然，它们都不是最优的。 如果存在针对网络环境，用户需求及其动态的准确且数学可解的模型，则可以开发出更好的解决方案。 <u>排队论已被用于对通信网络进行建模并协助资源分配[15]，[25]，[26]，[37]</u>。 **但是，由于以下原因，它可能不适用于涉及多跳路由和端到端性能（例如延迟）的网络问题**：1）在排队论中，queueing network（而不是单个队列）中的许多问题仍然是开放问题，而具有网状拓扑结构的通信网络则表示相当复杂的多点到多点排队网络，其中来自一个队列可以被分布到多个下游队列，并且一个队列可以从多个不同的上游队列接收分组。  2）<u>排队理论只能在一些强假设下（例如，元组到达遵循泊松分布等）提供准确的排队延迟估计，但是在复杂的通信网络中可能不成立</u>。 请注意，即使到达每个源节点的数据包都遵循泊松分布，到达中间节点的数据包也可能不会。



# 疑问

### abstract

* ns3的话 拓扑规模？
* DRL-TE怎么和DDPG对比起来了，不是两种不同的东西么...
* VLB和ECMP的区别



* 我们一定要做分布式的么？不做的话会怎么样--》无法达到全局最优 ?  Auto怎么被评论的？
* 有哪些open review的会议
* Caida数据集
* ospf最短路径的权重问题？