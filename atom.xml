<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hesy&#39;s Blog</title>
  
  <subtitle>Seek for your love</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hexi519.github.io/"/>
  <updated>2020-10-27T09:06:45.689Z</updated>
  <id>https://hexi519.github.io/</id>
  
  <author>
    <name>Hesy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>paperWriting</title>
    <link href="https://hexi519.github.io/2020/10/26/Summary/paperWriting/"/>
    <id>https://hexi519.github.io/2020/10/26/Summary/paperWriting/</id>
    <published>2020-10-26T19:02:43.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="writing-patterns"><a href="#writing-patterns" class="headerlink" title="writing patterns"></a>writing patterns</h1><blockquote><p>for RL-based networking</p></blockquote><p> ==不管是罗列前人工作，还是讲别人的缺点，还是讲我们的tool的优点，都是<strong>两个方面!!!</strong> 一个方面实在是太单薄==</p><h2 id="Auto"><a href="#Auto" class="headerlink" title="Auto"></a>Auto</h2><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="第一段-重要性及前人工作"><a href="#第一段-重要性及前人工作" class="headerlink" title="第一段 [重要性及前人工作]"></a>第一段 [重要性及前人工作]</h4><p>XXX <strong>has a significant impact</strong> on application performance. <strong>Currently</strong>, XXX is dependent on … . When …, XXX may suffer performance penalty. <strong>For example</strong>, in yyy[8],…. Under …. scenarios, performance degradation can be as much as …[8]. zzz[4] shares the same problem when …: for certain cases the …(某指标) can be reduced by over … even if … . <u>Furthermore</u>, in coflow scheduling, fixed thresholds in Aalo [18] depend on the operator’s ability to choose good values upfront, since there is no run-time adaptation.</p><ul><li>这里只说了一句，XX对application performance很重要，但并没有给出例子说明。直接用<strong>Currently</strong>总结了当前的工作的缺陷。<strong>For example</strong>进一步阐述了缺陷。</li></ul><blockquote><p>Datacenter traffic optimizations (TO, e.g. flow/coflow scheduling [1, 4, 8, 14, 18, 19, 29, 61], congestion control [3, 10], load balancing &amp;routing [2]) <strong>have significant impact on</strong> application performance. <strong>Currently</strong>, TO is dependent on hand-crafted heuristics for varying traffic load, flow size distribution, traffic concentration, etc. When parameter setting mismatches traffic, TO heuristics may suffer performance penalty. <strong>For example</strong>, in PIAS [8], thresholds are calculated based on a long term flow size distribution, and is prone to mismatch the current/true size distribution in run-time. Under mismatch scenarios, performance degradation can be as much as 38.46% [8]. pFabric [4] shares the same problem when implemented with limited switch queues: for certain cases the average FCT can be reduced by over 30% even if the thresholds are carefully optimized. <u>Furthermore</u>, in coflow scheduling, fixed thresholds in Aalo [18] depend on the operator’s ability to choose good values upfront, since there is no run-time adaptation.</p></blockquote><h4 id="第二段-继续批判前人工作的第二个缺点"><a href="#第二段-继续批判前人工作的第二个缺点" class="headerlink" title="第二段 [继续批判前人工作的第二个缺点]"></a>第二段 [继续批判前人工作的第二个缺点]</h4><p><strong>Apart from</strong> parameter-environment mismatches, the turn-around time of designing TO heuristics is long—at least weeks. <strong>Because</strong> … . </p><ul><li><strong>Apart from</strong> 承接上文的缺陷，并提出一个新的缺陷，然后用<strong>Because</strong>去支撑自己的观点。</li></ul><blockquote><p><strong>Apart from</strong> parameter-environment mismatches, the turn-around time of designing TO heuristics is long—at least weeks. <strong>Because</strong> they require operator insight, application knowledge, and traffic statistics collected over a long period of time. A typical process includes: first, deploying a monitoring system to collect end-host and/or switch statistics; second, after collecting enough data, operators analyze the data, design heuristics, and test it using simulation tools and optimization tools to find suitable parameter settings; finally tested heuristics are enforced (with application modifica- tions [19, 61], OS kernel module [8, 14], switch configurations [10], or any combinations of the above).</p></blockquote><h4 id="第三段-我们的task-amp-我们为何使用RL"><a href="#第三段-我们的task-amp-我们为何使用RL" class="headerlink" title="第三段 [我们的task &amp; 我们为何使用RL]"></a>第三段 [我们的task &amp; 我们为何使用RL]</h4><p>XX is thus appealing, and we desire an XX that can … , while achieving … goals. </p><ul><li>提出我们想做的task是什么 以及 我们想要达到的一个大概的目标</li></ul><blockquote><p>Automating the TO process is thus appealing, and we desire an automated TO agent that can adapt to voluminous, uncertain, and volatile datacenter traffic, while achieving operator-defined goals.</p></blockquote><p>In this paper, <code>we investigate reinforcement learning (RL) techniques [55], as RL is the subfield of machine learning concerned with decision making and action control. It studies how an agent can learn to achieve goals in a complex, uncertain environment. An RL agent observes previous environment states and rewards, then decides an action in order to maximize the reward. RL has achieved good results in many difficult environments in recent years with advances in deep neural networks (DNN): DeepMind’s Atari results [40] and AlphaGo [52] used deep RL (DRL) algorithms which make few assumptions about their environments, and thus can be generalized in other settings. </code></p><ul><li>讲了RL是什么 以及 RL的promising之处(在别的领域获得了极好的成果)</li></ul><p>Inspired by these results, we are motivated to enable DRL for automatic datacenter TO.</p><ul><li>所以我们考虑用RL做强化学习</li></ul><h4 id="第六段-提出了我们的系统"><a href="#第六段-提出了我们的系统" class="headerlink" title="第六段 [提出了我们的系统]"></a>第六段 [提出了我们的系统]</h4><blockquote><p>四五和具体内容太相关了，略过</p></blockquote><p><strong>We present</strong> XX , an …(<code>更多high-level的描述作为同位语:基于xx的yy系统</code>). XX <strong>is a</strong> … , … . <code>描述其中one part</code>. <code>描述另一part.</code> <code>描述两part之间的关系.</code></p><ul><li>先概述一下我们的系统，然后描述各自的part，其中part之间的关系/数据流向可以放在中间说，也可以放在两个part之间说</li></ul><blockquote><p><strong>We present</strong> AuTO, an end-to-end DRL system for datacenter-scale TO that works with commodity hardware. AuTO <strong>is a</strong> two-level DRL system, mimicking the Peripheral &amp; Central Nervous Systems in animals. Peripheral Systems (PS) run on all end-hosts, collect flow information, and make instant TO decisions locally for short flows. PS’s decisions are informed by the Central System (CS), where global traffic information are aggregated and processed. CS further makes individual TO decisions for long flows which can tolerate longer processing delays.</p></blockquote><h4 id="第七段-novelty-key-design"><a href="#第七段-novelty-key-design" class="headerlink" title="第七段 [novelty/key design]"></a>第七段 [novelty/key design]</h4><p><strong>The key of</strong> … is … . <strong>To achieve this</strong>, we adopt … . <strong>In this way</strong>, …. <strong>Furthermore</strong>, … </p><ul><li>highlight了创新点和核心技术</li></ul><blockquote><p><strong>The key of</strong> AuTO’s scalability is to detach time-consuming DRL processing from quick action-taking for short flows. <strong>To achieve this</strong>, we adopt Multi-Level Feedback Queueing (MLFQ) [8] for PS to schedule flows guided by a set of thresholds. Every new flow starts at the first queue with highest priority, and is gradually demoted to lower queues after its sent bytes pass certain thresholds. Using MLFQ, AuTO’s PS makes per-flow decisions instantly upon local information (bytes-sent and thresholds)4, while the thresholds are still optimized by a DRL algorithm in the CS over a relatively longer period of time. In this way, global TO decisions are delivered to PS in the form of MLFQ thresholds (which is more delay-tolerant), enabling AuTO to make globally informed TO decisions for the majority of flows with only local information. Furthermore, MLFQ naturally separates short and long flows: short flows complete in the first few queues, and long flows descend down to the last queue. For long flows, CS centrally processes them individually using a different DRL algorithm to determine routing, rate limiting, and priority </p></blockquote><h4 id="第八段-系统基于的软硬件"><a href="#第八段-系统基于的软硬件" class="headerlink" title="第八段 [系统基于的软硬件]"></a>第八段 [系统基于的软硬件]</h4><p><strong>We have implemented an XX prototype using</strong> Python.XX is thus compatible with popular learning frameworks, such as Keras/TensorFlow. This allows both networking and machine learning community to easily develop and test new algorithms, because software components in AuTO are reusable in other RL projects in datacenter.</p><h4 id="第九段-实验效果"><a href="#第九段-实验效果" class="headerlink" title="第九段 [实验效果]"></a>第九段 [实验效果]</h4><p><strong>We further build a testbed with</strong> …(硬件设施) to evaluate XXX. <strong>Our experiments show that</strong>, for…(<code>某种场景</code>), <strong>XXX’s performance</strong> improvement is up to … compared to … after xx hours of training. <strong>XX is also shown to</strong> … (<code>另一个优点</code>) </p><ul><li>testbed 是什么</li><li>优点还是从两方面说,还是得用数字具化</li></ul><blockquote><p><strong>We further build a testbed with</strong> 32 servers connected by 2 switches to evaluate AuTO. <strong>Our experiments show that</strong>, for traffic with stable load and flow size distribution, <strong>AuTO’s performance improvement is up to</strong> 48.14% compared to standard heuristics (shortest-job-first and least-attained-service- first) after 8 hours of training. AuTO <strong>is also shown to</strong> learn steadily and adapt across temporally and spatially heterogeneous traffic: after only 8 hours of training, AuTO achieves 8.71% (9.18%) reduction in average (tail) FCT compared to heuristics.</p></blockquote><h3 id="2-Background-and-motivation"><a href="#2-Background-and-motivation" class="headerlink" title="2 Background and motivation"></a>2 Background and motivation</h3><p>在本节中，我们首先概述RL背景。 </p><p>然后，我们描述并应用基本的RL算法（策略梯度4For）以启用TO中的流调度。 </p><p>最后，我们通过测试平台实验展示了运行PG的RL系统的问题，从而激发了AuTO。</p><h4 id="2-1-DRL【抄这个以及Wei-Li的】"><a href="#2-1-DRL【抄这个以及Wei-Li的】" class="headerlink" title="2.1 DRL【抄这个以及Wei Li的】"></a>2.1 DRL【抄这个以及Wei Li的】</h4><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/133619-827023.png" alt="image-20201026133617922"></p><p>​    如图1所示，环境是代理的周围环境，代理可以通过观察，操作和对操作的反馈（奖励）与之交互[55]。 具体来说，在每个时间步长t中，代理观察状态st，并在处选择动作。 然后，环境状态转换为st + 1，并且代理收到奖励rt。 状态转换和奖励是随机的和马尔可夫式的[36]。 学习的目的是使期望的累计折现奖励E [P∞t =0γtrt]最大化，其中γt∈（0,1]是折现因子RL主体基于策略采取行动，即概率分布 在状态s上采取动作a的过程：π（s，a）。</p><p>​    对于大多数实际问题，学习状态-动作对的所有可能组合都是不可行的，因此通常使用函数逼近[31]技术来学习该策略。 函数逼近器πθ（s，a）由θ进行参数化，其大小比所有可能的状态作用对的数目小（因此在数学上易于处理）函数逼近器可以具有多种形式，并且最近具有深层神经网络。（DNN）被证明可以解决类似于流量调度的实际的大规模动态控制问题，因此，我们也将DNN用作AuTO中的函数逼近器的表示，通过函数逼近，Agent通过更新功能参数来学习 具有状态st，acti的θ 在开启，并在每个时间段/步骤t中获得相应的回报rt。</p><p>​    我们专注于一类更新算法，该算法通过对策略参数执行梯度下降来学习。 学习涉及更新DNN的参数（链接权重），以使上述目标最大化。</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/133751-838519.png" alt="image-20201026133750664"></p><p>​    代理DNN的训练采用了众所周知的REINFORCE算法的一种变体[56]。 该变量使用等式（1）的修改版本，从而减轻了算法的缺点：收敛速度和方差。 为了减轻这种弊端，蒙特卡罗方法[28]用于计算经验奖励vt，而基线值（每台服务器的经验奖励的累积平均值）用于减小方差[51]。 结果更新规则（等式（2））被应用于策略DNN，这是由于其方差管理和保证的收敛至少是局部最小值[56]：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/133758-514716.png" alt="image-20201026133758119"></p><h4 id="2-2-Example-DRL-for-Flow-Scheduling"><a href="#2-2-Example-DRL-for-Flow-Scheduling" class="headerlink" title="2.2 Example:DRL for Flow Scheduling"></a>2.2 Example:DRL for Flow Scheduling</h4><p><strong>Furthermore, we formulate the problem of</strong>  …  <strong>as a</strong> DRL <strong>problem</strong>, <strong>and describe a solution using</strong> the xx algorithm based on Equation (2).</p><p>​    例如，我们将数据中心中的流调度问题表述为DRL问题，并使用基于等式（2）的PG算法描述解决方案。</p><blockquote><p>As an example, we formulate the problem of flow scheduling in datacenters as a DRL problem, and describe a solution using the PG algorithm based on Equation (2).</p><blockquote><p>注意，这里一定要搞清楚论文投稿的格式要求，比如有些会议，“Equation (2)” 就不让写出Equation，直接写(2)</p></blockquote></blockquote><h5 id="Flow-scheduling-problem"><a href="#Flow-scheduling-problem" class="headerlink" title="Flow scheduling problem"></a>Flow scheduling problem</h5><blockquote><p>我们考虑一个连接多个服务器的数据中心网络。 为简单起见，我们在流量调度[4，14]中采用了先前工作中的大交换机假设，其中网络是无阻塞的，具有全二分频带宽和适当的负载平衡。 按照该假设，将流调度问题简化为确定流的发送顺序的问题。 我们考虑一种实现，它可以使用严格的优先级队列来对流进行抢先调度。 我们为每个服务器中的流创建K个优先级队列[23]，并在其中强制执行严格的优先级排队。 交换机中还配置了K个优先级队列，类似于[8]。 每个流的优先级可以动态更改以启用抢占。 每个流的数据包都用其当前优先级编号标记，并将被放置在整个数据中心结构的同一队列中。</p></blockquote><h5 id="DRL-formulation"><a href="#DRL-formulation" class="headerlink" title="DRL formulation"></a>DRL formulation</h5><blockquote><p>Action space：代理提供的动作是从活动流到优先级的映射：对于每个活动流f，在时间步t处，其优先级为pt（f）∈[1，K]。 </p><p>State space：大开关假设可简化状态空间。 由于路由和负载平衡已不在我们的考虑范围之内，因此状态空间仅包含流状态。 在我们的模型中，状态表示为所有活动流的集合Ft a和所有完成的流的集合Ft网络（当前时间步长t）。 每个流在整个5元组[8，38]中用d标识：源/目标IP，源/目标端口号和传输协议。 活动流有一个附加属性，即优先级。 而完成的流还有两个附加属性：FCT和流大小5。</p><p>Rewards：奖赏是向座席反馈有关其行为良好的反馈。 奖励可以在流程完成后获得，因此仅针对时间步长t的一组最终流程Ft d计算奖励。 每个完成流f的平均吞吐量为Tputf = Sizef FCTf。 我们将奖励建模为两个连续时间步的平均吞吐量之间的比率。</p></blockquote><h5 id="DRL-algorithm"><a href="#DRL-algorithm" class="headerlink" title="DRL algorithm"></a>DRL algorithm</h5><p>​    我们使用公式（2）指定的更新规则。 驻留在代理上的DNN为每个新状态计算概率向量，并通过评估导致当前状态的动作来更新其参数。 评估步骤将先前的平均吞吐量与当前步骤的相应值进行比较。 根据比较结果，会产生一个适当的奖励（负数或正数），并添加到基线值中。 因此，我们可以确保函数逼近器随时间改进，并且可以通过在梯度方向上更新DNN权重来收敛到局部最小值。（2）之后的更新确保了将来不鼓励针对类似状态的不良流调度决策，而对于未来类似的状态，好的调度变得更可能。 当系统收敛时，该策略为服务器集群实现了足够的流量调度机制。</p><h4 id="2-3-Problem-Identified"><a href="#2-3-Problem-Identified" class="headerlink" title="2.3 Problem Identified"></a>2.3 Problem Identified</h4><p>​    以流调度的DRL问题为例，我们使用流行的机器学习框架Keras / TensorFlow，PyTorch和Ray来实现PG。 我们将DRL代理简化为只有1个隐藏层。 我们使用两台服务器：DRL代理驻留在其中一台中，另一台使用RPC接口将模拟流量信息（状态）发送到该代理。 我们将模拟服务器的发送速率设置为每秒1000个流（fps）。 我们在模拟服务器上测量不同实现的处理延迟：完成发送流信息和接收操作之间的时间。 这些服务器是运行64位Debian 8.7的华为Tecal RH1288 V2服务器，具有4核Intel E5-1410 2.8GHz CPU，NVIDIA K40 GPU和Broadcom 1Gbps NIC。</p><p>​    如图2所示，即使对于1000fps的较小流到达速率和仅1个隐藏层，所有实现的处理延迟都超过60ms，在此期间，7.5MB内的任何流都将在1Gbps链路上完成。 作为参考，使用Microsoft数据中心[3、8、26]中收集的Web搜索应用程序和数据挖掘应用程序的知名流量跟踪，分别有7.5MB的流量大于所有流量的99.99％和95.13％。 这意味着，大多数DRL动作都是无用的，因为当动作到达时，相应的流已经消失了</p><h5 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h5><p>当前的DRL系统的性能不足以对数据中心规模的流量做出在线决策。 即使对于简单的算法和较低的流量负载，它们也会遭受较长的处理延迟。</p><h3 id="3-Auto-Design"><a href="#3-Auto-Design" class="headerlink" title="3. Auto Design"></a>3. Auto Design</h3><h4 id="3-1-overview"><a href="#3-1-overview" class="headerlink" title="3.1 overview"></a>3.1 overview</h4><hr><p>这一部分实际上暗示了 design rationale ( 设计的insight )</p><blockquote><p>当前的DRL系统的关键问题是流信息的收集与动作的产生之间的长等待时间。 在链路速度≥10Gbps的现代数据中心中，要实现流级TO操作，动作的往返延迟至少应为毫秒。 如果不引入专用硬件，这是无法实现的（第2.2节）。 使用商用硬件，DRL算法的处理延迟是一个硬限制。 在这种限制下，如何为数据中心TO缩放DRL？ </p><p>最近的研究[3、11、33]显示，大多数数据中心流是短流，而大多数流量字节来自长流。 在这种长尾分布的通知下，我们的见解是将大多数短流程操作委托给最终主机，并制定DRL算法以生成长流程（亚秒级）TO决策。</p></blockquote><hr><p>各个part之间的作用 以及 他们之间的联系</p><blockquote><p>我们将AuTO设计为两级系统，模仿动物的周围和中枢神经系统。 如图3所示，外围系统（PS）在所有终端主机上运行，收集流信息，并在本地做出TO决策，对短流的延迟最小。 中央系统（CS）针对长流量做出单独的TO决策，可以容忍更长的处理延迟。 此外，CS会根据PS的决定来汇总和处理全球路况信息。</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/141814-653119.png" alt="image-20201026141813675"></p><h4 id="3-2-Peripheral-System"><a href="#3-2-Peripheral-System" class="headerlink" title="3.2 Peripheral System"></a>3.2 Peripheral System</h4><p>​    AuTO的可扩展性的关键是使PS能够仅通过本地信息就短流程做出全球知情的TO决策。  PS具有两个模块：强制模块和监视模块。</p><blockquote><p>design rationale : 可扩展性</p></blockquote><h5 id="Enforcement-module"><a href="#Enforcement-module" class="headerlink" title="Enforcement module"></a>Enforcement module</h5><blockquote><p>​    为了实现上述目标，我们采用了多级反馈排队（MLFQ，在PIAS [8]中引入）来调度流，而无需进行集中的逐流控制。 具体来说，PS在每个终端主机的IP数据包的DSCP字段中执行数据包标记，如图4所示。有K个优先级Pi，1≤i≤K，以及（K-1）降级阈值αj，  1≤j≤K-1。 我们将所有交换机配置为基于DSCP字段执行严格的优先级排队。 在终端主机上，当新流初始化时，其数据包将标记为P1，从而为它们提供网络中的最高优先级。 随着发送更多字节，此流的数据包将以优先级降低的标记Pj（2≤j≤K）进行标记，因此在网络中以降低的优先级对其进行调度。 将优先级从Pj-1降级为Pj的阈值为αj-1</p></blockquote><blockquote><pre><code>     使用MLFQ，PS具有以下属性： ​    •它只能基于本地信息（发送的字节数和阈值）做出即时的每流决策。 ​    •它可以适应全球流量变化。 为了具有可伸缩性，CS不能直接控制小流量。 相反，CS会在更长的时间内使用全局信息优化并设置MLFQ阈值。 因此，可以更新PS中的阈值以适应流量变化。 相反，PIAS [8]需要数周的流量跟踪才能更新阈值。 ​    •它自然地将短流和长流分开。 如图5所示，短流在前几个队列中完成，长流下降到最后一个队列。 因此，CS可以单独集中处理长流量，以决定路由，速率限制和优先级。</code></pre></blockquote><h5 id="Monitoring-module"><a href="#Monitoring-module" class="headerlink" title="Monitoring module"></a>Monitoring module</h5><p>​    为了让CS生成阈值，监视模块会收集所有已完成流的流量大小和完成时间，以便CS可以更新流量大小分布。 监控模块还报告持续的长流量，这些流量已降到其端主机的最低优先级，以便CS可以做出单独的决定。</p><h4 id="3-3-Central-System"><a href="#3-3-Central-System" class="headerlink" title="3.3 Central System"></a>3.3 Central System</h4><p>​    CS由两个DRL代理（RLA）组成：短流RLA（sRLA）用于优化MLFQ的阈值，长流RLA（lRLA）用于确定长流的速率，路由和优先级。  sRLA试图解决FCT最小化问题，为此我们开发了深度确定性策略梯度算法。 对于lRLA，我们使用PG算法（第2.2节）为长流程生成操作。 在下一节中，我们将介绍两个DRL问题和解决方案。</p><h3 id="4-DRL-FORMULATIONS-AND-SOLUTIONS"><a href="#4-DRL-FORMULATIONS-AND-SOLUTIONS" class="headerlink" title="4 DRL FORMULATIONS AND SOLUTIONS"></a>4 DRL FORMULATIONS AND SOLUTIONS</h3><p> In this section, we describe the two DRL algorithms in CS.</p><h4 id="4-1-Optimizing-MLFQ-thresholds"><a href="#4-1-Optimizing-MLFQ-thresholds" class="headerlink" title="4.1 Optimizing MLFQ thresholds"></a>4.1 Optimizing MLFQ thresholds</h4><hr><blockquote><p>其实这里还是在说背景 : 我们为什么要选DDPG以及DDPG是什么</p></blockquote><p>​    我们考虑一个连接多个服务器的数据中心网络。 通过在每个IP标头中设置DCSP字段，在主机和网络交换机（图4）上使用K个严格优先级队列来对流进行调度。 流越长，则通过主机优先级队列将其分配给优先级时，优先级分配的优先级就越低，以便近似最短作业优先（SJF）。 数据包的优先级会保留在整个数据中心结构中，直到到达目的地为止。  </p><p>​    MLFQ的挑战之一是计算主机上K个优先级队列的最佳降级阈值。 先前的工作[8、9、14]提供了用于优化降级阈值的数学分析和模型：{α1，α2，…，αK-1}。  Bai等。[9]还建议每周/每月重新计算阈值，并收集流量水平轨迹。  AuTO进一步采取了措施，并提出了DRL方法来优化α值。 与先前的研究将机器学习用于数据中心问题[5、36、60]不同，AuTO的独特之处在于其目标-优化连续动作空间中的实际值。 <u>我们将阈值优化问题表述为DRL问题，并尝试探索DNN建模复杂数据中心网络以计算MLFQ阈值的功能。</u></p><p>​    如第2.2节所示，PG是一种基本的DRL算法。 该代理遵循通过向量θ参数化的策略πθ（a | s），并根据经验进行改进。 但是，REINFORCE和其他常规PG算法仅考虑随机策略πθ（a | s）= P [a | s;θ]，该随机策略根据状态集s上的动作集A的概率分布选择状态s中的动作a。  θ。  PG不能用于价值优化问题，因为价值优化问题会计算实际价值。 因此，我们使用确定性策略梯度（DPG）[53]的一种变体来近似给定状态s的最优值{a0，a1，…，an}，使得i = 0时ai = µθ（s）。  。，n。 图6总结了随机策略和确定性策略之间的主要差异。  DPG是用于确定性策略的actor-critic [12]算法，该算法维护代表当前策略的参数化actor函数µθ，以及使用Bellman方程更新的评论者神经网络Q（s，a）（如Q学习[  41]）。 <u>我们用等式（4,5,6）描述该算法，如下所示</u>：参与者对环境进行采样，并根据等式（4）更新其参数θ。 等式（4）的结果来自以下事实：该策略的目标是使预期的累积折扣奖励等式（5）最大化，并且其梯度可以用以下等式（5）表示。 有关更多详细信息，请参阅[53]。<br>   θk+ 1</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/144238-170340.png" alt="image-20201026144237709"></p><p>​    深度确定性策略梯度（DDPG）[35]是DPG算法的扩展，它利用了深度学习技术[41]。 我们将DDPG用作优化问题的模型，并在下面解释其工作方式。 与DPG一样，DDPG也是一种参与者评判算法[12]，它维护四个DNN。 两个DNN，分别是评论家QθQ（s，a）和权重µQµ（s），权重为θQ和θµ，在大小为N的样本迷你批次上进行训练，其中一个项目表示一个有经验的过渡元组（si，ai，ri  si + 1），而代理与环境互动。 对DNN进行随机样本训练，这些样本存储在缓冲区中，以避免相关状态导致DNN偏离[41]。 其他两个DNN，目标演员µ0θ和目标评论家Q 0 0分别用于演员和评论家网络θQ（s，a）的平滑更新（**算法（1）[35]**）。 更新步骤稳定了对行为者批评网络的训练，并在连续的空间动作上取得了最新的成果[35]。  AuTO应用DDPG来优化阈值，以实现更好的流量调度决策。</p><h5 id="DRL-formulation-1"><a href="#DRL-formulation-1" class="headerlink" title="DRL formulation"></a>DRL formulation</h5><p>​    <strong>接下来，我们表明阈值的优化可以表述为DDPG可解决的行动者批评的DRL问题。我们首先提出了一个优化问题，即选择最佳阈值集{αi}以最小化流量的平均FCT。 然后我们将此问题转化为DRL问题，可以使用DDPG算法解决。</strong> 将流量分布的累积密度函数表示为F（x），因此F（x）是流量不大于x的概率。 令Li表示给定流为i = 1，…，K引入队列Qi的数据包数量。 因此，E [Li]≤（αi-αi-1）（1-F（αi-1））。 将流到达率表示为λ，则到达队列Qi的数据包到达率是λi=λE[Li]。 队列的服务速率取决于优先级较高的队列是否全部为空。 因此，P1（最高优先级）的容量为µ1 = µ，其中µ是链路的服务速率。  Q1的空闲率为（1-ρ1），其中ρi=λi/ µi是Qi的利用率。 因此，Q2的服务速率为µ2 =（1-ρ1）µ，因为假定P1为空，其服务速率为µ（全链路容量）。 我们有μi=Πi-1j = 0（1-ρj）μ，其中ρ0= 0。 因此，Ti ＝ 1 /（μi-λi），其是假设M / M / 1个队列的队列i的平均延迟。 对于大小为[αi-1，αi）的流，它将经历不同优先级队列直至第i个队列的延迟。 将Ti表示为在第i个队列中花费的平均时间。 令imax（x）为最小降级阈值大于x的索引。 因此，大小为x的流体的平均FCT（T（x））的上限为：Pimax（x）i = 1 Ti。 令дi= F（αi）-F（αi-1）表示大小为[αi-1，αi）的流量百分比。 因此，дi是两个连续阈值之间的差距。 使用дi等价表示αi，我们可以将FCT最小化问题表示为：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/144505-298842.png" alt="image-20201026144504717"></p><p>我们继续将问题（7）转换为DRL问题。<br>   <em>Action Space</em>：在我们的模型中，状态表示为当前时间步中整个网络中所有完成的流量Fd的集合。 每个流都由其5元组[8，38]标识：源/目标IP，源/目标端口号和传输协议。 因为我们仅报告完成的流，所以我们还将FCT和流大小记录为流属性。 总的来说，每个流程都有7个功能。</p><p>​    <em>Reward</em>：奖励是向座席延迟的反馈，该反馈是关于座席在上一个时间步中的表现如何。 我们将奖励建模为两个连续时间步的目标函数之间的比率：rt = Tt-1 Tt。 它指示先前的操作是否导致较低的平均FCT，或者是否降低了整体性能。</p><h5 id="DRL-algorithm-1"><a href="#DRL-algorithm-1" class="headerlink" title="DRL algorithm"></a>DRL algorithm</h5><blockquote><p>结合具体场景来描述数据流向</p></blockquote><p>​    我们使用公式（4）（算法1）指定的更新规则。  DNN为主机从每个新接收到的状态计算“ i”，并将元组（（st，at，rt，st + 1））存储在缓冲区中以供以后学习。 仅当下一次更新来自同一主机时，奖励rt和下一个状态st + 1才知道，因此代理将st和at缓存在直到收到所有需要的信息为止。 参数的更新是随机进行的，以稳定学习并减少发散的可能性[35，41]。 在步骤t在主机处计算回报rt，并将其与先前的平均FCT进行比较。 根据比较结果，会产生适当的奖励（负数或正数），并作为评估行动的信号发送给代理。 通过遵循算法1，系统可以改善潜在的参与者批评型DNN，并收敛为问题（7）的解决方案。</p><h3 id="5-Implementation"><a href="#5-Implementation" class="headerlink" title="5. Implementation"></a>5. Implementation</h3><p>​    在本节中，我们描述实现。 我们使用Python 2.7开发AuTO。 语言选择促进了与现代深度学习框架[17、45、57]的集成，该框架提供了出色的Python接口[45]。 当前的原型使用Keras [17]深度学习库（以TensorFlow作为后端）</p><h4 id="5-1-Peripheral-System"><a href="#5-1-Peripheral-System" class="headerlink" title="5.1 Peripheral System"></a>5.1 Peripheral System</h4><p>​    PS是在每个服务器上运行的守护进程。 它具有监视模块（MM）和执行模块（EM）。  MM线程收集有关流的信息，包括最近完成的流和当前活动的长流（在MLFQ的最后一个队列中）。 在每个周期结束时，MM会汇总收集的信息，然后发送给CS。  PS的EM线程根据当前活动流的MLFQ阈值以及长流的路由，速率限制和优先级标记执行标记。 我们为PS和CS之间的通信实现了一个远程过程调用（RPC）接口。  CS使用RPC设置MLFQ阈值并对活动的长流执行操作。<br>   5.1.1监控模块（MM）： 为了获得最大的效率，可以将MM作为PIAS [8]中的Linux内核模块来实现。 但是，对于当前的原型，由于我们使用流生成器（如[8、10、20]中所示）来产生工作负载，因此我们选择直接在流生成器内部实现MM。 这种选择使我们可以获得基本事实，并摆脱可能干扰结果的其他网络流。 对于长流（MLFQ的最后一个队列中的流），每T秒，MM将nl个活动长流（每个具有6个属性）合并，并将ml个完成的长流（每个具有7个属性）合并到一个列表中。 对于同一时期中的短流（在MLFQ的前几个队列中），MM将ms个完成的流（每个具有7个属性）收集到一个列表中。 最后，MM将两个列表连接起来，并将它们发送给CS，以观察环境。</p><p>​    AuTO的参数{nl，ml，ms}由流量负载和T决定：对于每台服务器，nl（ml）应该是T中活动（完成）长流数的上限，而ms也应该是上限 有限的空头流。 如果实际活动（完成）流量的实际数量小于{nl，ml，ms}，则将观察矢量零填充到与相应代理的DNN相同的大小。 我们之所以选择这种设计，是因为CS中DNN的输入神经元数量是固定的，因此只能采用固定大小的输入。 我们将动态DNN和递归神经网络结构留作未来的工作。 对于当前的原型和该原型上的实验，由于我们控制流发生器，因此很容易遵守此约束。我们在实验中选择{nl = 11，ml = 10，ms = 100}。</p><p>​    5.1.2执行模块（EM）：。  EM定期从CS接收操作。 这些行动包括新的MLFQ阈值以及关于本地长流量的TO决策。 对于MLFQ阈值，EM基于PIAS [8]内核模块构建，并添加降级阈值的动态配置。 对于短流量，我们利用ECMP [30]进行路由和负载平衡，而这不需要集中的每流控制，而DCTCP [3]则用于拥塞控制。 对于长流程，TO操作包括优先级，速率限制和路由。  EM利用相同的内核模块进行优先级标记。 速率限制是使用Linux流量控制（tc）中的分层令牌桶（HTB）排队规则来完成的。  EM在HTB中配置了具有出站速率限制的父类，以表示该节点上CS所管理的总出站带宽。 当流下降到MLFQ中的最后一个队列时，EM将创建一个与该流的精确5元组匹配的HTB过滤器。 当EM从CS接收到速率分配决策时，EM通过向Linux内核发送Netlink消息来更新特定流的子类：TC类的速率设置为集中式调度程序确定的速率，上限设置为 较小的原始上限和两倍于CS的费率</p><h4 id="5-2-Central-System"><a href="#5-2-Central-System" class="headerlink" title="5.2 Central System"></a>5.2 Central System</h4><p>​    CS运行RL代理（sRLA和lRLA）以做出优化的TO决策。 当处理传入更新并将操作发送到流生成服务器时，我们实现的CS遵循类似于SEDA的体系结构[58]。 该体系结构分为不同的阶段：http请求处理，深度网络学习/处理和响应发送。 每个阶段都有自己的进程，并通过队列进行通信，以将所需的信息传递到下一个阶段。 这种方法可确保CS服务器的多个核心参与处理来自主机的请求，并分散负载。 由于Python编程语言的CPython实现中的全局锁定问题[24]，已采用了多处理体系结构。 状态和动作在CS处被封装为“环境”（类似于[47]），RL代理可以与这些环境和动作直接进行编程交互。</p><ul><li><p>5.2.1 sRLA</p><p>​    如第4.1节所述，我们使用Keras通过上述DNN（演员，评论家，目标演员和目标评论家）对运行DDPG算法的sRLA进行实施。  Actor：Actor具有两个完全连接的隐藏层，分别具有600和600个神经元，其输出层具有K-1个输出单位（每个阈值一个）。 输入层采用状态（每个服务器700个功能部件（ms = 100）），并输出主机服务器在步骤t的MLFQ阈值。 评论家：评论家具有三个隐藏层，因此与参与者网络相比，网络要复杂一些。 由于批评家应该“批评”演员的错误决定，而“赞美”则是好的决定，因此批评者神经网络也将演员的输出作为输入。 但是，正如[53]所暗示的那样，演员的输出不是直接的输入，而只是在隐藏层馈入评论者的网络。 因此，评论家具有与演员相同的两个隐藏层，还有一个额外的隐藏层，它将演员的输出与其自己的第二个隐藏层的输出连接起来，从而又增加了一个隐藏层。 该隐藏层最终被馈送到由一个输出单元组成的输出层-观察/接收状态的近似值。 通过从经验缓冲区{st，at，rt，st + 1}中进行采样，定期对一批观察值进行训练。 训练过程在算法（1）中进行了描述。</p></li><li><p>5.2.2 lRLA</p><p>​    对于lRLA，我们还使用Keras通过具有300个神经元的10个隐藏层的完全连接的NN来实现PG算法。  RL代理采取状态（每服务器136个功能（nl = 11，ml = 10））并输出所有活动流的操作概率。 总结基于一些经验训练课程，选择了超参数（DNN的结构，层数，高度和宽度）。 我们的观察结果是，具有更多隐藏层和更多参数的更复杂的DNN需要花费更长的训练时间，并且其性能没有比所选拓扑好得多。 总的来说，我们发现这样的RLA配置可带来良好的系统性能，考虑到计算延迟的重要性，这是相当合理的，正如我们在评估中所揭示的。</p></li></ul><h2 id="MRTE-ICNP’20"><a href="#MRTE-ICNP’20" class="headerlink" title="==MRTE ( ICNP’20 )=="></a>==MRTE ( ICNP’20 )==</h2><blockquote><p>前三段和最后一段绝壁不错，完全是个典范</p></blockquote><h3 id="1-Introduction-1"><a href="#1-Introduction-1" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="第一段-重要性及传统工作的弊病"><a href="#第一段-重要性及传统工作的弊病" class="headerlink" title="第一段  [重要性及传统工作的弊病]"></a>第一段  [重要性及传统工作的弊病]</h4><p>XXX, which aims to optimize … for network performance and …(resource utilization), <strong><u>is fundamental to</u></strong> networking research. <strong>In practice</strong>, large networks are often divided into multiple (logical or physical) regions, <strong>e.g</strong>.<code>, to facilitate decentralized scalable management [1], to satisfy domain/enterprise requirements [2], or in accordance with geographical locations [3] and heterogeneous routing technologies [4].</code> In such multi-region networks, each region … . <strong>While</strong> significantly improving … , the use of … <u>makes it intractable to achieve … due to <u>the lack of</u> ….</p><ul><li><p>先强调这是一个重要的东西 : 使用in practise枚举传统的工作，最好找到他们的共性概括起来 ( 这里举例的前后两句都是在概括他们的共性：将大网分为很多region，每个region只关注regional network observations ) e.g.</p><blockquote><p>Traffic Engineering (TE), which aims to optimize traffic routing for network performance and resource utilization, <u>is fundamental</u> to networking research. <strong>In practice</strong>, large net- works are often divided into multiple (logical or physical) regions, e.g., to facilitate decentralized scalable management [1], to satisfy domain/enterprise requirements [2], or in accordance with geographical locations [3] and heterogeneous routing technologies [4]. In such multi-region networks, each region typically makes its own local TE decisions based on regional network observations.</p></blockquote></li><li><p>再阐述他们存在的缺陷： 利用while句子，前半句肯定，后半句批评。同时，批评的后半句承接到下一段去</p><blockquote><p><strong>While</strong> significantly improving the scalability of network management, the use of multiple regions <u>makes it difficult</u> to achieve global TE objectives due to the lack of a joint effort and coordination.</p></blockquote></li></ul><h4 id="第二段-current工作的弊病"><a href="#第二段-current工作的弊病" class="headerlink" title="第二段 [current工作的弊病]"></a>第二段 [current工作的弊病]</h4><p>XX <strong><u>is a very challenging problem</u></strong>. <strong>In contrast to classic XX **focusing on … [5]–[10], **existing approaches</strong> tend to rely on … (e.g.<code>, 稍微展开阐述下第一种方案[11]</code>) or <code>第二种方法 [1] [12] [13]</code>. <strong>In particular</strong>, iterative algorithms like [1] [12] [13] require … , <u>incurring</u> … and … . <strong>As a result</strong>, these algorithms <u>lack</u> … <strong><u>and thus suffer</u></strong> hefty performance loss under … . <strong>Another line of work</strong> develops … [3] [14], where … . Apart from <code>第一个缺陷</code>, it still <code>说出第二个缺陷</code>.</p><ul><li><p>第一句承接上一段，也引领本段。</p><blockquote><p>Distributed TE in multi-region networks is a very challenging problem. </p></blockquote></li><li><p>指出现有方法的改进，一般都要分成两方面讲，并且分别指出问题所在。【一般也要分成两个方面去讲】</p><blockquote><p><strong>In contrast to traditional</strong> TE focusing on a fully-controlled and fully-observable network (also known as intra-region TE) [5]–[10], <strong>existing approaches</strong> often rely on simple routing heuristics (e.g., directing outgoing traffic to the closest border routers in hot potato routing [11]) <strong>or</strong> leveraging distributed optimization techniques to decouple a global TE problem [1] [12] [13]. <strong>In particular</strong>, iterative algorithms like [1] [12] [13] for distributed TE require adjacent regions to share necessary information (e.g., gradients) through real-time communication, <u><strong>incurring</strong></u> communication overhead and slow convergence. <strong>As a result</strong>, <u>these algorithms <strong>lack</strong></u> the agility to adapt to changing traffic patterns and thus suffer hefty performance loss under highly dynamic traffic demands. <strong>Another line of work</strong> develops a hierarchical SDN architecture [3] [14], where a set of slave controllers are designated to different regions, and a super controller coordinates these slave controllers globally to compute routing decisions. <strong>Besides communication cost, it still requires</strong> a controller having full control over the entire network albeit in a hierarchical manner.</p></blockquote></li></ul><h4 id="第三段-我们提出的方法是什么"><a href="#第三段-我们提出的方法是什么" class="headerlink" title="第三段 [我们提出的方法是什么]"></a>第三段 [我们提出的方法是什么]</h4><p>In this paper, <strong>we propose</strong> <u>a data-driven framework based on Deep Reinforcement Learning (DRL) for</u> … . <strong>The proposed framework provides a refreshing perspective to this problem by</strong> … . </p><ul><li><p>我们提出了基于…(方法)的…  , 大致的问题解决思路是…</p><blockquote><p>In this paper, <strong>we propose</strong> a data-driven framework <u>based</u> on Deep Reinforcement Learning (Deep RL) for distributed TE in multi-region networks. The proposed framework <u>provides a refreshing perspective to this problem</u> <strong>by modeling</strong> each network region as an individual learning agent that has only local network information and interacts with other agents to make decisions on the fly for performance optimization. </p></blockquote></li></ul><p><strong>Compared with traditional</strong>… ,<code>Deep RL, as one of the leading Machine Learning (ML) techniques, has the potential of solving complex and dynamic control problems. Deep RL algorithms can automatically exploit hidden patterns in training data and continue improving its TE strategy over time. Well-trained Deep RL models can do inference efficiently even for the inputs that never appeared before.</code><strong>Besides</strong>, <code>Deep RL models can be trained by interacting with the network environment without requiring labeled data that are usually hard to obtain in real networks [15].</code> </p><hr><p>[ 其实我觉得这一段后面这部分没必要233 ]</p><ul><li>阐述了我们base的方法的优势（why we use ) </li></ul><p>Several recent proposals [15]–[17] have capitalized on these advancements to tackle the crucial and timely challenge of TE. <strong>However</strong>, We hasten to emphasize that these RL-based approaches only focus on intra-region TE problems within a single, fully-controlled region (regarded as a single agent) and thus cannot be applied to the distributed TE problem in multi-region networks.</p><ul><li>虽然也有人用了这样的方法，但是我们的方法跟别人还是有本质上的区别的</li></ul><h4 id="第四段-及-之后"><a href="#第四段-及-之后" class="headerlink" title="第四段 及 之后"></a>第四段 及 之后</h4><ul><li>第四段argue了multi-agent Deep RL在分布式TE里面的作用，which我觉得很扯淡</li><li>后面我觉得<u>借鉴意义更不大了</u></li></ul><h4 id="最后一段-实验设置以及实验效果"><a href="#最后一段-实验设置以及实验效果" class="headerlink" title="最后一段 [实验设置以及实验效果]"></a>最后一段 [实验设置以及实验效果]</h4><p>We <strong>implement</strong> our framework <strong>using</strong> TensorFlow [18] and <strong>evaluate</strong> its performance <strong>using</strong> both … and … . We use … to … . </p><ul><li><p>先概要讲一下实现及实验的基本设置（使用 xxx 在实验里面充当了…作用）</p><blockquote><p>We <strong>implement</strong> our framework using TensorFlow [18] and <strong>evaluate</strong> its performance <strong>using</strong> both real-world network topologies (Telstra and Google Cloud) and large-scale synthetic network topologies (with hundreds of nodes). <strong>We use</strong> the Gravity model [19] <strong>to</strong> generate highly dynamic traffic including burst demands.</p></blockquote></li></ul><p><strong>Simulation results show that</strong> our framework significantly <strong>outperforms</strong> … and <strong>achieves</strong> 90-percentile …(某指标) within …  times the optimal <strong>under/for</strong> …(场景). <strong>Compared with</strong> the single-agent approach [16], our framework achieves 20×-100× the learning speed of [16] <strong>and</strong> gets at most 72% of congestion reduction in random link failure scenarios.</p><ul><li><p>然后概述实验结果</p><ul><li>outperform others (一个虚而大的)</li><li>and引出具体的：大部分/全部场景下 在某指标上获得…</li><li>更具体点，我们拿出其中一个最具有代表性的算法出来比 【请注意，这里比较，还是从两方面说事情】</li></ul><blockquote><p><strong>Simulation results show</strong> that our framework significantly <strong>outperforms</strong> existing protocols and single-agent learning algorithms <strong>and achieves</strong> 90-percentile congestion within 1.2 times the optima  <strong>under/for</strong> all the simulated topologies. <strong>Compared with</strong> the single-agent approach [16], our framework achieves 20×-100× the learning speed of [16] <strong>and</strong> gets at most 72% of congestion reduction in random link failure scenarios.</p></blockquote></li></ul><h4 id="最后一段-概述后文-…-额-我完全用得上"><a href="#最后一段-概述后文-…-额-我完全用得上" class="headerlink" title="最后一段 [概述后文] … 额 我完全用得上"></a>最后一段 [概述后文] … 额 我完全用得上</h4><p>In the following, we first <strong><u>overview</u></strong> DRL and <strong><u>reveal</u></strong> why current DRL systems fail to work at large scale in §2. <strong>We <u>describe system design</u> in §3, <u>as well as the DRL formulations and solutions in §4</u></strong>. We <strong><u>implement</u></strong> AuTO in §5, and <u><strong>evaluate</strong></u> it with extensive experiments in §6 <strong>using a</strong> realistic <strong>testbed</strong>. Finally, we <strong>review related works</strong> in §7, and <strong>conclude</strong> in §8.</p><h3 id="2-related-work"><a href="#2-related-work" class="headerlink" title="2. related work"></a>2. related work</h3><h3 id="3-Problem-statement-and-solution-overview"><a href="#3-Problem-statement-and-solution-overview" class="headerlink" title="3. Problem statement and solution overview"></a>3. Problem statement and solution overview</h3><h4 id="A-problem-statement"><a href="#A-problem-statement" class="headerlink" title="A. problem statement"></a>A. problem statement</h4><p><strong>We consider XX</strong> (场景). <strong>Generally, XX can be modelled as</strong>  …（模型） , <strong>where</strong> … (阐述模型的几个要素以及他们分别都代表什么。<code>可以考虑用&quot;Each xx ...&quot; 以及&quot;Note that,...&quot;的句式来detail这些东西</code>） . <strong>We assume that</strong> … (可以给出一些公式阐述模型要素之间的关系) , and… . </p><blockquote><p> <strong>We consider</strong> a network consisting of multiple regions. Generally, the entire network can be modelled as a directed graph G(V, E), where V is the node (router/switch) set and E is the edge set. Each edge e(u, v) ∈ E has a capacity ce(u,v) denoting the maximum traffic amount that can pass the edge from node u to adjacent node v. Note that, edges e(u, v) and e(v, u) can have different capacities. Each region m can be considered as a directed sub-graph Gm(Vm, Em). We assume that (equation), and that $E_m = {e(u, v)|u \in V_m}$. There may be several peering edges connecting two adjacent regions, and the end nodes of these peering edges are border nodes of the regions.</p></blockquote><p><strong>The goal of XX is to optimize</strong> … , i.e., … . (可以加一句阐述为什么要优化这个目标，e.g.这个目标反映出了什么)</p><h4 id="B-Solution-overview"><a href="#B-Solution-overview" class="headerlink" title="B. Solution overview"></a>B. Solution overview</h4><p><strong>In our design, we take XX as **(采用的技术/工具/算法). **XX is</strong> …（解释下这个技术/工具/算法的原理、步骤、特点）.  <strong>In our framework, we propose to use</strong> … ( 结合XX和自己的场景 ) . <strong>Their definitions are given as follows:</strong></p><blockquote><p><strong>In our design, we take</strong> Deep RL agents as the decision makers of routing. Deep RL is a combination of RL and deep neural network (DNN) and is more powerful to tackle complex tasks than RL. Different from supervised learning techniques with external knowledge guidance, a Deep RL agent learns its behavior through interactions with an environment iteratively for a specific objective. [这里我觉得应该补充下step的概念] At each iteration step, the agent observes the current state of the environment and makes a decision, i.e., an action. Then, the environment evolves transforms from the current state to a new state and returns a reward value to the agent. The reward is a feedback value indicating the quality of the agent’s action. The goal of the agent is to learn a policy which is a DNN mapping state to action so as to maximize the discounted cumulative reward [25]. To find a satisfactory policy, Deep RL takes an exploration-exploitation-based method. The agent can take a large-reward action learned so far, which is called action exploitation. The agent can also try a new action for a possibly higher reward, which is called action exploration. A good trade-off between exploitation and exploration helps the agent “understand” the environment well and learn an optimized policy through enough iterations. As mentioned previously, the routing of terminal traffic directly affects the status of the current region, while the routing of outgoing traffic affects the status of not only the current region but also the other regions, because traffic leaving the region from different border routers has different effects on the other regions. <strong>In our framework, we propose to</strong> use two separate Deep RL agents for traffic engineering in each individual region: T-agent and O-agent. <strong>Their definitions are given as follows:</strong></p></blockquote><p>Definition 3.1: T-agent is the Deep RL agent that controls the routing of terminal demands in each region. Definition 3.2: O-agent is the Deep RL agent that controls the routing of outgoing demands in each region. </p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/26/162331-878449.png" alt="image-20201026162330617"></p><blockquote><p>==这个图不错，可以画个类似的==</p></blockquote><ul><li><p><strong>先结合RL问题和一个solution的架构图，解释清楚RL的五要素分别对应现实中的哪些东西。</strong>(具体的奖励函数、action/state space的设定细节，可以在下一节里面详细谈论。比如下面这个例子里面，只说了reward是跟优化xx的目标有关，但是具体的形式和元素都没有说呢还)</p><p><strong>Fig. 2 illustrates our proposed solution</strong>. For each region, a locally centralized server maintains a T-agent and an O-agent for the region. Each server <strong>collects</strong> local <strong><u>state information</strong> (i.e., edge utilization</u>s) from the corresponding region periodically. <strong>Then, the agents <u>take actions</strong> (i.e., traffic splitting ratios over pre-computed paths)</u> independently based on the local state information for TE performance improvement. <strong><u>Reward values returned to</strong> the T-agents <strong>are</strong> computed <strong>with respect to a</strong> local TE <strong>objective</strong> (i.e., minimizing the maximum edge cost of the local region).</u> While the O-agents get their reward values for a cooperative TE objective by combining the reward values of the T-agents in the local and neighboring regions. <strong><u>The details of link statistics-based state, reduced action space, and congestion-related reward functions will be presented in Section</strong> IV-A and IV-B.</u> </p></li><li><p>然后本篇文章简单提了他们的training，and”将在后面的Section XX 中更加详细具体地讨论这件事情”.</p><ul><li>采用离线和在线策略的组合的原因</li><li>离线如何train的(捕获脱机TM数据)，在线如何train(也是简单说了下)</li></ul><blockquote><p>To make our framework work well after deployment, we need to train the agents efficiently. Since Deep RL agents learn policies through the exploration-exploitation-based method, online learning from scratch has been widely known to result in poor performance at the beginning [26]. In this paper, we take a combined offline and online strategy. In the offline phase, the agents are trained in a simulated network which has the same topology and capacity settings as the real one. The simulated network will be initialized with offline TMs captured from the real network. We train these agents incrementally using various TMs. After training, the learned DNN parameters will be loaded to online agents for inference (i.e., decision making). During the online stage, the system can continue to improve with little communication among regions and make near-optimal routing decisions quickly. We demonstrate how to train agents in Section IV-C.</p></blockquote></li></ul><h3 id="4-our-proposed-solutions"><a href="#4-our-proposed-solutions" class="headerlink" title="4. our proposed solutions"></a>4. our proposed solutions</h3><p>In this section, we describe the development of T-agent and O-agent separately, followed with the training method.</p><blockquote><p>这一段就似乎讲了为何这么设计五要素的考量</p></blockquote><h4 id="A-T-agent-Development"><a href="#A-T-agent-Development" class="headerlink" title="A. T-agent Development"></a>A. T-agent Development</h4><h5 id="State-space"><a href="#State-space" class="headerlink" title="State space"></a>State space</h5><p>good sentense : State space is the input of agents, which should capture the key status of the network environment.</p><blockquote><p>状态空间是代理程序的输入，它应该捕获网络环境的关键状态。 现有的大多数基于深度RL的方法都将流量统计信息（例如TM）作为代理的状态输入[15]-[17]。 但是，在缺乏全局视野和控制力的多区域网络中获取实时TM统计信息并不容易。 在我们的设计中，我们使用边缘统计信息，即边缘利用率，可以轻松地对其进行测量。 边缘利用率由流量需求和路由决策共同决定。 因此，它隐含地反映了交通需求的变化以及当前行为的影响。 链接利用率值提供了哪些链接已阻塞的指示，因此学习代理可以相应地更新当前策略，以减少这些链接上的流量和拥塞。</p></blockquote><blockquote><p>​    Formally，在迭代步骤t，我们将sm，T t表示为区域m中T-agent的状态向量。 状态向量通常可以表示为</p><blockquote><p>… ( 某公式 )</p></blockquote><p>其中fece是边e的当前利用率。 状态向量sm，T t的大小取决于区域m具有多少个边缘。<br>    具体地，边缘利用率为零表示发生边缘故障，即，边缘被破坏。 我们将sm，T t中的残破边缘利用率手动设置为一个相对较大的值（例如1.0），以便代理可以输出操作以减少残破边缘的流量（就像缓解瓶颈处的拥塞过程一样） 边缘）。</p></blockquote><h5 id="Action-space"><a href="#Action-space" class="headerlink" title="Action space"></a>Action space</h5><p>good sentence ：Action space is the output of agents and also routing decisions。</p><blockquote><p>动作空间是代理的输出，也是路由决策的输出。 像[16]这样的方法决定了如何在每个路由器节点上分配流量。 但是，如果代理执行错误的操作，则这种逐跳方法可能会导致路由不一致，甚至导致环路。 因此，我们决定使用将流量需求分配到多个转发路径上的路由决策。 为了简化动作空间并减少路径维护的开销，我们预先计算并构造了连接每对入口和出口节点的K条转发路径，这与以前的工作[5] [9] [17]是一致的。 因此，路由决策是这些路径上的一组流量分配比。 在本文中，我们使用[5]中提出的流量忽略路径选择算法来计算转发路径，这似乎最适合我们的TE问题（考虑路径属性，开销等）。 已验证计算路径具有一些吸引人的属性，例如良好的负载平衡，高分集和低拉伸。 这使我们的方案即使预先计算和构造少量路径，也能够处理流量动态和拓扑变化。</p><p>Formally，我们将Pm i，j表示为在区域m中连接入口节点i和出口节点j的一组预先计算的转发路径。 令am，T t为迭代步骤t区域m中T-agent的作用向量。  T-agent的作用向量可以表示为:</p><blockquote><p>公式</p></blockquote><p>其中ai，j p∈[0，1]表示路径p上从入口节点i传递到出口节点j的业务量的分数。 在相同的入口节点i和相同的出口节点j之间的终端需求可以具有不同的源节点，但是将采用相同的划分比率集{ai，j p | p∈Pm i，j}。 显然，</p></blockquote><h5 id="Reward"><a href="#Reward" class="headerlink" title="Reward"></a>Reward</h5><blockquote><p>奖励值是根据当前网络状态通过奖励功能计算得出的，可指导代理商策略的改进。 较大的奖励值表明，代理商采取的行动对TE目标有益。 我们将rm，T t表示为迭代步骤t区域m中T-agent的奖励值。 回顾我们的TE目标是最小化整个网络的最大边缘成本，奖励函数的直接设计是rm，T</p><blockquote><p>公式</p></blockquote><p>其中h（e）计算边e的成本。  TE目标值越小，意味着奖励值越大。 <strong>但是，基于全球目标值计算出的报酬无法正确评估T代理行动的质量。</strong> 例如，如果某个地区的T-agent采取行动并导致极高的边际成本，则其他T-agent即使他们采取的行动实际上是好的，也将获得较小的奖励值。 错误的奖励会误导T代理的DNN参数更新。 在我们的设计中，我们使每个T代理了解其针对本地目标的政策，即最大程度地降低其所在区域的最大边缘成本。 然后奖励函数可以表示为</p><blockquote><p>公式 （3）</p></blockquote><p>在等式中具有奖励功能。公式（3），每个T-agent只会根据其所在地区的状况来改进政策，这实际上也将有利于全球目标的优化。 这是因为T代理会调整终端需求的路由，以适应O代理和</p></blockquote><h4 id="B-O-agent-Development"><a href="#B-O-agent-Development" class="headerlink" title="B. O-agent Development"></a>B. O-agent Development</h4><p>….</p><h4 id="C-Training-Algorithm"><a href="#C-Training-Algorithm" class="headerlink" title="C. Training Algorithm"></a>C. Training Algorithm</h4><blockquote><p>​    我们构建了一个数字网络环境来训练代理。 模拟网络具有与实际目标网络相同的拓扑和相同的边缘容量设置。 给定一个TM和所有代理的行为，可以轻松计算每个代理的状态向量和奖励。 我们采用先进的Deep RL算法，并利用增量训练使代理能够适应高度异构的流量模式甚至链路故障。 接下来，我们展示Deep RL算法和增量训练。 </p><p>​    回想一下，训练的目的是使每个代理学习从状态向量到动作向量的策略映射，以使折扣的累积奖励最大化，如第III-B节所述。 在本文中，我们采用最先进的Deep RL算法之一DDPG [25]来帮助代理学习策略。  DDPG支持高维状态空间以及确定性和连续动作，这符合我们系统的要求。 在DDPG中，有一个在线演员网络和一个在线评论家网络。 在线参与者网络是政策的DNN。 在线评论家网络用于估计称为Q值的预期折扣累积奖励。 简而言之，在线评论家网络评估参与者网络的行为并帮助参与者网络更新参数。 通过针对评估的Q值和目标Q值最小化损失函数来训练在线评论家网络。 为了提高更新的稳定性，DDPG维护两个独立的网络，即目标参与者网络和目标评论者网络，以帮助估计目标Q值。 两个目标网络具有与相应的在线网络相同的DNN结构，并从这两个在线网络缓慢更新。</p></blockquote><blockquote><p>​    我们在设计中制定并构建了DDPG的DNN。 由于座席以相同的方式更新DNN参数，因此为了简洁起见，我们接下来考虑使用通用座席，并从索引中删除区域的索引（即m）和座席类型（即T和O）。 在一般代理中，有一个由四个DNN组成的DDPG实例，即在线角色网络π（st |θπ），目标角色网络π？（st |θπ？）。<br>   ），在线评论者网络Q（st，at |θQ）和目标评论者网络Q？（st，at |θQ？<br>   ）设定为θπ，θπ？，θQ和θQ？ ，分别。 在我们的实现中，actor网络包含两个分别具有64和32个神经元的完全连接的隐藏层，并且激活函数是Leaky Rectifier函数[28]。 输入层（输出层）具有与状态向量（动作向量）的长度匹配的多个单位。 输出层将Softmax函数[28]作为激活函数，以便遵循等式中所示的动作约束。  （1）和等式 （4）。 批判网络包含三个分别具有64、32和64个神经元的隐藏层，其激活功能为泄漏整流器功能。 输入包括状态向量以及参与者网络输出的动作向量。 前两个隐藏层已完全连接，并以状态向量为输入。 第三隐藏层将动作向量和第二隐藏层的输出的串联作为输入，并馈入一个单元的输出层。</p></blockquote><blockquote><p>​    在每个迭代步骤t，在线参与者网络都会根据环境采取措施。 然后，可以收集一个由st，at，rt和st + 1组成的四元组样本。  st + 1是在状态st中采取行动后的新状态向量。 新样本将存储在固定大小的缓冲区中，如果缓冲区已满，则将覆盖缓冲区中最旧的样本。 然后，我们从缓冲区中随机选择一批样本（以k为索引）。 可以通过θQ：=θQ+ηQ∇θQL更新在线评论家网络，其中L = E [？  k（yk -Q（s（k），a（k）|θQ）]，2和yk = r（k）+γQ？（s（k + 1），π？（s（k + 1））））  yk是样本k的目标Q值，是在两个目标网络的帮助下计算的；γ∈[0，1]是一个折现因子；ηQ决定了在线批评家网络的学习率。 通过θπ：=θπ+ηπ∇θπJ更新，其中∇θπJ= E [∇aQ（s，a |θQ）| s = s（k），a =π（s（k））·∇θππ（  s |θπ）| s = s（k）]ηπ决定了在线演员网络的学习率，最后，基于在线网络分别缓慢更新目标演员网络和目标评论者网络。<br>   =τθQ+（1 −τ）θQ？ 和θπ？  =τθπ+（1 −τ）θπ？  。  τ是用于调整网络学习率的小值。 为了学习令人满意的DNN参数，在线演员网络将在其输出中添加一个噪声值，以便在训练阶段进行动作探索，如前所述。 特别是，在每个迭代步骤中，通过</p><p>…</p></blockquote><blockquote><p>使用上述算法，对于具有给定TM的模拟网络，代理可以在足够的迭代步骤（即，足够大的T）之后学习良好的策略。 同时，希望能够在在线阶段很好地适应流量动态以及链路故障。 因此，我们利用增量训练的方法来增强代理的适应性。 特别是，我们使用一组TM（称为训练数据集）来训练代理。 在训练数据集中的每个TM设置的环境中，将针对T迭代步骤对代理进行训练，并且代理的参数将逐步更新。 通过创建动态环境，代理可以学习能够适应各种流量模式的策略。 由于代理以类似于前面所述的处理链路拥塞的方式处理链路故障，因此增量训练还可以促进链路故障场景中TE性能的改善。 实际上，可以离线从捕获的数据中提取用于离线训练的TM。 离线训练过程可以以集中方式或分散方式执行。 对于前者，将使用集中式服务器，在其中维护整个网络环境和所有代理。 也就是说，集中式服务器对于所有区域都是可靠的。 训练后，集中式服务器将把训练有素的代理（即DNN参数）分配到相应的区域。 对于后者，代理培训是在各个区域同时进行的。 特别是，每个区域都使用本地服务器维护局部环境，仅模拟其自己的区域以及该区域的两个代理（一个T代理和一个O代理）。 在每个迭代步骤中，相邻区域将交换一些信息，例如流量统计信息和奖励值。 因此，区域可以正常计算O型代理的状态和奖励。 第二种训练方式使区域避免共享一些敏感的内部信息，例如区域结构，边缘容量和边缘权重。 在在线阶段，代理可以以类似于第二种方式的方式，在区域之间几乎没有通信的情况下连续扩展其知识。</p></blockquote>]]></content>
    
    <summary type="html">
    
      Paper Writing pattern
    
    </summary>
    
    
      <category term="Summary" scheme="https://hexi519.github.io/categories/Summary/"/>
    
    
      <category term="Writing" scheme="https://hexi519.github.io/tags/Writing/"/>
    
  </entry>
  
  <entry>
    <title>Fuzzy Kanerva-based TCP Q-learning</title>
    <link href="https://hexi519.github.io/2020/10/25/PaperReading/Fuzzy%20Kanerva-based%20TCP%20Q-learning/"/>
    <id>https://hexi519.github.io/2020/10/25/PaperReading/Fuzzy%20Kanerva-based%20TCP%20Q-learning/</id>
    <published>2020-10-25T16:13:55.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Hesy-summary"><a href="#Hesy-summary" class="headerlink" title="Hesy summary"></a>Hesy summary</h1><p>DCOSS’16 </p><p>主要用于梳理下行文思路，用于写作学习。abstraction,design,performance都很出彩</p><ul><li><p><a href="#abstract">abstract</a>的三段论值得学习</p></li><li><p>introduction的逻辑应该是 <code>我们提出了XXXX，能克服前人工作的xx缺点</code> 而不是<code>前人工作有xx缺点，为此我们提出了XXXX</code></p></li><li><p>related work里面的抨击值得摘抄！</p></li><li><p>design的逻辑很好！</p><ul><li>整体的运行架构是什么 （ 如何将Q-learning算法结合我们的场景进行运行</li><li>RL的几个要素分别是什么 （ 如何结合Q-learning算法和我们的问题进行芥末</li><li>实现上遇到的challenge 以及我们的解决方案 , which is another 华彩</li></ul></li><li><p><a href="#Performance">performance</a>的逻辑和布局也学习到了！</p><ul><li>实验设置</li><li>整体在xx 和 yy 方面的提升 &amp;  为何会出现这样情况的分析</li><li>在xx方面的结果 翔实的展示； 在yy方面的结果 翔实的展示</li></ul></li><li><p>小细节</p><ul><li>自己拼接造出的单词 ，dash别忘了<ul><li>sub-component</li><li>pre-configured</li><li>re-think</li></ul></li></ul></li></ul><a id="more"></a><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><ul><li><p>【<strong>Background: important things and urgent need</strong>】 </p><p>Advances in YY technology have resulted in <strong>pervasive deployment</strong> of devices of … . <strong>The need</strong> for <strong>XX</strong> that ….( 描述下对XX的性能期待, e.g. 高吞吐,低延迟 )  <strong>necessitate re-thinking</strong> of conventional design of （你要研究的领域/东西）.</p><blockquote><p>无线技术的进步已导致在尺寸，存储和计算能力方面具有高度可变性的设备的普遍部署(pervasive deployment)。 为了保持以高可靠性传送数据的连续连接，需要重新考虑传统的传输层协议设计。</p></blockquote></li></ul><ul><li><p>【<strong>What we propose and what’s its features</strong>】</p><p><strong>This paper investigates</strong> the use of  <strong>ZZ ** （你使用的算法/技巧/工具） in **YY</strong>（你研究的领域）… , <strong>wherein</strong> …（描述下你做了什么）. <strong>Furthermore</strong>, it demonstrates how …(具体描述下研究工作中华彩的细节，套路大概就是”我发现了xx(性能瓶颈)在实现的时候很关键，我们是这样解决的”)</p><blockquote><p>本文研究了在拥塞避免状态期间Q学习在TCP cwnd adaptation中的使用，其中窗口的经典alternation已被replaced，从而允许协议立即响应先前看到的网络条件。此外，它展现了内存如何在构建探索空间中发挥关键作用，并提出了通过函数逼近来减少此开销的方法。[ 后面这句话实际上不是一个addtional point，还是在讲这个scheme本身，只不过是scheme的细节，which 是自己的巧思体现之处。] </p></blockquote></li></ul><ul><li><p>【<strong>Performance description</strong>】</p><p><strong>The superior performance</strong> of <u>our</u> approach over <em>Baseline XX</em> is <strong>demonstrated through a comprehensive simulation study</strong>, <strong>revealing</strong> xx% and xx% improvement in <em>metric1</em> and <em>metric2</em> respectively,on real-world(classic) traces/topologies. <strong>We also show</strong> <strong>how</strong> <strong>ZZ **（你使用的算法/技巧/工具） **can be used to</strong> (处理上一段所说的性能瓶颈，while 保持了一个好的performance( 高吞吐/低延迟,这个还是要细点说的) ) .</p><ul><li>这里our换成别个描述characteristic的形容词更好，e.g. learning-based/data-driven</li></ul><blockquote><p>通过全面的仿真研究证明了基于学习的方法优于TCP New Reno的性能，对于评估的拓扑，吞吐量和延迟分别提高了33.8％和12.1％。 我们还展示了如何使用函数逼近来显着降低基于学习的协议的内存需求，同时保持相同的吞吐量和延迟。</p></blockquote></li></ul><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h1><p>快到1页</p><p>==这里的表达不应该是“以往的工作有xx缺点，为改进此缺点我们提出…”，而应该是“以往的工作有xx缺点。我们提出了基于xx技术的XX。它的表现…and… ”==</p><h1 id="2-motivation-and-practical-relevance"><a href="#2-motivation-and-practical-relevance" class="headerlink" title="2 motivation and practical relevance"></a>2 motivation and practical relevance</h1><p>快到1页</p><h1 id="3-related-work"><a href="#3-related-work" class="headerlink" title="3 ==related work=="></a>3 ==related work==</h1><blockquote><p>这一段写的贼好，要好好学习！</p></blockquote><p>一栏</p><ul><li><p>传统CC的问题</p></li><li><p>现在CC的问题</p></li><li><p>其他CC相关的工作</p><blockquote><p>应用机器学习来帮助提高TCP性能的其他工作很少。 例如，[13]使用机器学习来构建损耗分类器，以区分链路损耗和拥塞损耗，[14]和[15]使用机器学习来更好地估计RTT和吞吐量。 这些技术都不能直接调整cwnd。</p></blockquote></li></ul><h1 id="4-Q-learning-based-TCP"><a href="#4-Q-learning-based-TCP" class="headerlink" title="4 Q-learning-based TCP"></a>4 Q-learning-based TCP</h1><blockquote><p>整体</p></blockquote><p>​    我们提出的算法TCPLearning是基于强化学习的协议。 在强化学习中，学习主体在没有先验知识的情况下与环境交互，根据所学习的策略选择动作，获得正面或负面的奖励，然后观察环境的下一个状态。学习代理的目标是制定一种策略，即状态空间到动作空间的映射，以最大化长期打折的奖励。 此后，TCPLearning不再想PCC那样使用probe来检测不同动作对性能的影响，而是使用增强算法Q-Learning来学习最佳策略，以根据经验直接在每个状态下做出动作选择。<br>   TCPLearning发送方使用New Reno协议的正常慢启动阶段。 如果慢启动在cwnd超过阈值时结束，则拥塞控制过程将进入拥塞避免阶段，我们的学习算法将接管控制cwnd。 如果由于观察到拥塞而导致慢速启动结束，则New Reno协议继续，并且不使用学习算法。 如果在拥塞避免阶段检测到数据包丢失，则学习算法将停止，并且将应用New Reno协议来实现快速重传和快速恢复。<br>   <strong>与在New Reno中一样，TCPLearning的最重要任务是调整cwnd的大小。 在每个时间段（通常是一个RTT）中，我们的算法通过处理ACK信息来收集吞吐量和RTT值，然后将它们组合成单个效用函数U。效用函数随着吞吐量的增加和延迟的减少而增加。 该算法的目标是了解cwnd大小的变化如何增加效用函数的值。<br>   学习算法使用Q学习来学习策略以选择动作并实现其目标。Q学习使用简单的值迭代更新过程。 在时间t处，对于每个状态st和at处的每个动作，算法按如下方式计算对其预期折现奖励或动作值函数Q（st，at）的更新：</strong></p><p>​    其中rt + 1是时间t +1的即时奖励，αt（st，at）是折现因子，使得0≤γ&lt;1。Q学习是学习率，使得0≤αt（st，at）≤  1和γ将Q（st，at）值存储在称为Q表的表中。 更新Q（st，at）值的时间复杂度为O（| A |），其中| A | 是动作数。</p><hr><blockquote><p>状态</p></blockquote><p>​    系统的状态由四个状态变量表示，<u>状态变量的值通过离散化划分</u>：</p><p>   •新接收到的ACK之间的间隔时间的移动平均值，离散为10个间隔。<br>   •发送方发送的数据包之间的间隔时间的移动平均值，离散为10个间隔。<br>   •当前的RTT与到目前为止找到的最佳RTT之比，离散为10个间隔。<br>   •缓慢启动阈值，离散为10个间隔。</p><hr><blockquote><p>动作</p></blockquote><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/25/210337-366485.png" alt="image-20201025210336629"></p><p>​    表II总结了更改cwnd的可用操作。 </p><p>​    奖励函数基于效用值的变化：</p><p>​                U = loge（吞吐量）-δ×loge（延迟）吞吐量</p><p>​    其中δ表示延迟相对于效用函数的相对重要性。 在我们的实验中，δ设置为1。</p><p>​    奖励函数等于：</p><ul><li>+2，如果效用在时间段t之后增加</li><li>-2，如果效用在时间段t之后减少。    </li></ul><p>​    其中t设置为0.1s（在我们的实验中为一个RTT）</p><h1 id="5-FUZZY-KANERVA-BASED-TCP-Q-LEARNING"><a href="#5-FUZZY-KANERVA-BASED-TCP-Q-LEARNING" class="headerlink" title="5  FUZZY KANERVA-BASED TCP Q-LEARNING"></a>5  FUZZY KANERVA-BASED TCP Q-LEARNING</h1><blockquote><p>先讲总体的思路，再讲细节的设计</p></blockquote><blockquote><p>==对应于我就是先讲总体的流程，然后再讲 1. lstm的设计  2. attention的设计（不仅能提高观察，还能提高性能 !  理由，在平缓的时候关注点能平坦,,, 在剧烈变化的时候关注点能聚焦… –&gt; 需要做个对比试验，此外，关于理由还是要再想清楚点.. ）==</p></blockquote><ul><li><p>function approximator的重要性</p><ul><li><p>现有的一些方法，以及他们存在的一些问题</p></li><li><p>我们使用的Kanerva编码的原理和formulation，以及如何融入我们这个框架里面的 【创新和修改部分】</p><blockquote><p>请注意，这里阐述细节并不是为了讲算法原理，而是要讲清楚如何讲算法应用到我们这里面来的</p></blockquote></li><li><p>给出伪代码</p></li><li><p>描述伪代码的流程 ( lines xx-xx ) ，这里还分析了下代码的时空复杂度</p></li></ul></li></ul><h1 id="6-Performance-Evaluation"><a href="#6-Performance-Evaluation" class="headerlink" title="6 Performance Evaluation "></a>6 Performance Evaluation <h2 id="Performance"></h2></h1><ul><li>实验设置<ul><li>评估了三个方法，baseline是New Reno</li><li>单源拓扑上测试了性能，哑铃状拓扑测试了公平性，每个算跑8次</li><li>链路设置：RTT为100ms；每800s在7.5Mbps和2.5Mbps之间切换；缓冲区大小为BDP，which is 50个数据包</li><li>每个算法跑了8次</li></ul></li></ul><blockquote><p>我们使用基于ns-3的数据包级仿真，通过与TCP New Reno进行比较，来评估在不同带宽条件下TCPLearning，CMAC和Fuzzy TCPLearning的性能。 我们从图1（a）所示的单瓶颈网络开始，然后将评估范围扩展到图1（b）所示的更复杂的多流网络，以进行与公平相关的研究。 我们使用这些拓扑来演示受控环境中学习的特征，并显示对吞吐量和延迟的影响。 瓶颈带宽（在路由器-接收器链路上）每800s交替在7.5Mbps和2.5Mbps之间切换。 网络RTT设置为100ms，缓冲区大小设置为BDP，在我们的仿真中为50个数据包。 我们使用每种算法进行8个实验，并报告平均吞吐量和延迟。 值的标准偏差使用误差线显示。<br>   一种。</p></blockquote><blockquote><p>We use ns-3 based packet level simulations to evaluate the performance of TCPLearning, CMAC and Fuzzy TCPLearning in varying bandwidth conditions by comparing with TCP New Reno. We begin with a single-bottleneck network shown in Fig. 1(a) and later extend the evaluation to a more complex multi-flow network shown in Fig. 1(b) for fairness-related studies. We use these topologies to demonstrate the characteristic features of learning in controlled environments and show the impact on throughput and delay. The bottleneck bandwidth (on the router-receiver link) switches alternately between 7.5Mbps and 2.5Mbps every 800s. The network RTT is set to 100ms and the buffer size is set to BDP, which is 50 packets in our simulation. We conduct 8 experiments using each algorithm and report the average throughput and delay. The standard deviation of values is shown using error bars.</p></blockquote><h2 id="A-TCP-Learning-without-Function-Approximation"><a href="#A-TCP-Learning-without-Function-Approximation" class="headerlink" title="A. TCP-Learning without Function Approximation"></a>A. TCP-Learning without Function Approximation</h2><p>在这种情况下，我们禁用函数逼近并设置探索率？ 对于TCPLearning到0.1。 初始学习率α设置为0.3，并且每隔10s降低0.995倍。 总仿真时间设置为<u>6400s</u>。</p><hr><ul><li><p>平均吞吐量和延迟： 【是一个总体的视图】</p><ul><li><p><strong>陈述了</strong>不同带宽情况下，算法和baseline之间的吞吐量情况差距</p><blockquote><p>​    <strong>图2（a）</strong>比较了TCP New Reno和TCPLearning在瓶颈带宽每800s介于7.5Mbps和2.5Mbps之间切换时获得的<strong>平均吞吐量</strong>。 结果表明，随着瓶颈带宽的波动，TCPLearning的性能明显优于TCP New Reno。 我们观察到，在7.5Mbps的瓶颈带宽下，TCPLearning的平均吞吐量为6.72Mbps，而TCP New Reno的平均吞吐量为4.46Mbps。 在瓶颈带宽为2.5Mbps的情况下，TCPLearning的平均吞吐量为2.27Mbps，而TCP New Reno的平均吞吐量为2.26Mbps。 我们注意到，由于默认缓冲区大小在100ms的网络RTT和2.5Mbps的瓶颈带宽下是最佳的，因此TCP New Reno充分利用了该缓冲区，并且TCPLearning获得了同样好的性能。</p><p>​    <strong>图2（b）</strong>比较了在相同网络设置下TCP New Reno和TCPLearning实现的<strong>平均RTT</strong>。 结果表明，在瓶颈带宽为7.5Mbps时，TCPLearning的平均RTT为111ms，而TCP New Reno的平均RTT为109ms。 在瓶颈带宽为2.5Mbps时，TCPLearning的平均RTT为114ms，而TCP New Reno的平均RTT为154ms。 在任何瓶颈带宽下，TCPLearning在平均吞吐量方面都优于TCP New Reno。 图2（a）表明，在这种高带宽波动的网络中，TCPLearning将平均吞吐量提高了33.8％。 当考虑图2（b）所示的延迟时，尽管TCPLearning的性能稍差一些，但在这种情况下，在2.5Mbps的瓶颈带宽下性能下降了1.8％，在7.5Mbps的瓶颈带宽下，其性能优于TCP New Reno 26％。 平均而言，TCPLearning可将延迟减少12.1％。</p></blockquote></li><li><p>开始<strong>分析解释</strong>为啥人家会差【我觉得这一段批评classic的，我可以学习下】，我们会好</p><p>请注意，<strong>要用图片来佐证你的分析</strong></p><blockquote><p>​    我们观察到，TCP New Reno的平均吞吐量为4.46Mbps，远小于瓶颈带宽7.5Mbps。 这是因为TCP New Reno的预定义的拥塞避免算法使cwnd超出了连接所能支持的范围，最终使网络拥塞，最终导致cwnd和吞吐量显着下降。 <u>更糟糕的是，由于TCP New Reno算法无法存储过去的操作以及这些操作对性能的影响，因此它会重复相同的行为。 图3显示了在模拟TCP New Reno期间cwnd的大小与时间的关系。 该图表明，该算法反复做出相同的错误决策，从而降低了性能。</u><br>   另外，TCP new Reno在cwnd每次<u>显着下降之后需要花费大量时间来恢复</u>，因为它必须在避免拥塞阶段线性增加cwnd。 但是，TCPLearning通过学习经验来克服了这一缺陷。 图3还显示了在TCPLearning仿真期间，cwnd的大小与时间的关系。 该图显示，随着学习过程的进行，TCPLearning进行了各种实验，这些实验会修改cwnd直到110s。  110s之后，学习到的动作值函数Q（s，a）收敛到最佳动作值函数Q ∗（s，a）。这时，TCPLearning找到一个最佳动作，该动作充分利用了缓冲区并且不会触发任何动作 数据包丢失。 这种习得的动作使cwnd足够大，可以达到良好的性能，但是比发生包丢失的上限稍小。 通过这种最佳操作获得的高吞吐量将保持稳定，直到800s之后，瓶颈带宽才会切换。</p></blockquote></li></ul></li></ul><hr><blockquote><p>讲完整体视图/情况  以及 为什么会这样 之后，开始讲实时的指标 ( 细化 )</p></blockquote><ul><li><p>实时吞吐量 【还是踩了别人一脚，分析也比较少了</p><blockquote><p>​    图4显示了TCP New Reno和TCPLearning的实时吞吐量，其中每800s的高带宽在7.5Mbps和2.5Mbps之间切换。 该图显示，当瓶颈带宽为7.5Mbps（在最初的800秒钟内）时，TCP New Reno会经历重复的数据包丢失，从而导致平均吞吐量较低且不稳定。 当瓶颈带宽切换到一个较小的值（800s后为2.5Mbps）时，TCP New Reno会充分利用缓冲区并获得高而稳定的吞吐量。 我们观察到，在使用TCP New Reno时，那些具有高瓶颈带宽的方案会有效并严重降低吞吐量。 但是，波动的瓶颈带宽对TCPLearning实现的吞吐量影响很小。 如图4所示，TCPLearning用110s来学习7.5Mbps瓶颈带宽时的最佳策略，并保持高而稳定的吞吐量，直到800s。 当瓶颈带宽在800s之后切换到2.5Mbps时，TCPLearning会非常迅速地收敛，并且仍然可以实现稳定的吞吐量，直到瓶颈带宽再次切换为止。</p></blockquote></li><li><p>实时RTT 【</p><blockquote><p>图5显示了在上述相同带宽切换情况下TCP New Reno和TCPLeaning的实时RTT。 我们发现，在瓶颈带宽波动的情况下，TCPLearning比TCP New Reno实现了更稳定和更低的RTT。</p></blockquote></li></ul><h2 id="B-TCPLearning-with-Function-Approximation-We"><a href="#B-TCPLearning-with-Function-Approximation-We" class="headerlink" title="B. TCPLearning with Function Approximation We"></a>B. TCPLearning with Function Approximation We</h2><blockquote><p>我们通过将CMAC算法和Fuzzy TCPLearning算法应用于图1（a）所示的相同网络拓扑来评估其性能。  CMAC算法将状态动作空间划分为一组不同的图块，并创建多个图块以在学习中提供粗粒度和细粒度的概括。 在我们的实验中，我们使用5个切片，每个切片有3,125个切片，因为我们有5个可能的操作和4个状态变量，每个变量均等地划分为5个间隔。 要学习动作值，我们需要存储15625个θ值，这些值等于每个平铺3125个图块乘以5个平铺。 由于每个平铺都有大的平铺，因此需要较少的内存来存储所有θ值。  Fuzzy TCPLearning算法将函数逼近与连续的隶属度等级结合使用，以控制并显着减少存储学习值（对于TCPLearning而言是Q表）所需的内存量，同时保持性能。<br>   为了进行实验，我们首先随机生成一组100个原型，然后初始化相应的θ值。 然后，使用等式2通过Q学习过程更新每个原型的θi值。</p></blockquote><ul><li><p><strong>平均吞吐量和延迟</strong></p><blockquote><p>图2还比较了CMAC和Fuzzy TCPLearning在两个交替的瓶颈带宽下获得的平均吞吐量和延迟。我们观察到，在两个不同的瓶颈带宽上，CMAC和Fuzzy TCPLearning在吞吐量和延迟方面都优于TCP New Reno。我们注意到，当瓶颈带宽为7.5Mbps时，与TCPLearning相比，CMAC和Fuzzy TCPLearning的吞吐量都有轻微下降。 当瓶颈带宽为2.5Mbps时，可以观察到几乎相同的吞吐量。 此外，就两个瓶颈带宽的延迟而言，CMAC和Fuzzy TCPLearning的性能均比New Reno更好，而性能比TCPLearning差。 我们得出结论，就吞吐量和延迟而言，平均而言，TCPLearning表现最佳。 但是，利用功能逼近技术，CMAC和模糊TCPLearning可以显着减少内存使用，同时实现可比的性能。</p></blockquote></li><li><p><strong>减少内存使用的影响</strong></p><blockquote><p>TCPLearning算法分配内存以存储可能遇到的50,000个状态操作对中的每对。 由于4个字节用于存储与一个状态操作对相对应的Q值，因此TCPLearning使用200KB的内存存储。 相反，CMAC算法仅需要存储θ值，该值可能远小于状态动作对的数量。 我们的实验中使用的θ值总数为15,625，最终的内存使用量为62.5KB，不到TCPLearning使用的内存的1/3。 模糊TCPLearning算法为100个状态-动作对分配存储。 由于需要20个字节来存储一个状态-动作对，另外400个字节用于存储100个原型的θ值，因此它仅使用2.4KB内存，因此非常适合物联网应用。</p></blockquote></li></ul><h2 id="C-Fairness-Observations"><a href="#C-Fairness-Observations" class="headerlink" title="C. Fairness Observations"></a>C. Fairness Observations</h2><p>​    我们通过评估图1（b）所示的哑铃网络拓扑中的性能来评估TCPLearning算法的公平性。 该拓扑包括<u>2个发送器和2个接收器，它们在100ms RTT时共享2.5Mbps的瓶颈带宽。 瓶颈路由器缓冲区大小设置为100个数据包</u>。 两个流中的数据传输同时开始。 表III显示了TCP New Reno和TCPLearning的两个竞争流的平均吞吐量。 我们观察到，使用TCP New Reno和TCPLearning两种流的平均吞吐量几乎相同，因此在the那教的公平性指数中得分均相等。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hesy-summary&quot;&gt;&lt;a href=&quot;#Hesy-summary&quot; class=&quot;headerlink&quot; title=&quot;Hesy summary&quot;&gt;&lt;/a&gt;Hesy summary&lt;/h1&gt;&lt;p&gt;DCOSS’16 &lt;/p&gt;
&lt;p&gt;主要用于梳理下行文思路，用于写作学习。abstraction,design,performance都很出彩&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#abstract&quot;&gt;abstract&lt;/a&gt;的三段论值得学习&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;introduction的逻辑应该是 &lt;code&gt;我们提出了XXXX，能克服前人工作的xx缺点&lt;/code&gt; 而不是&lt;code&gt;前人工作有xx缺点，为此我们提出了XXXX&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;related work里面的抨击值得摘抄！&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;design的逻辑很好！&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整体的运行架构是什么 （ 如何将Q-learning算法结合我们的场景进行运行&lt;/li&gt;
&lt;li&gt;RL的几个要素分别是什么 （ 如何结合Q-learning算法和我们的问题进行芥末&lt;/li&gt;
&lt;li&gt;实现上遇到的challenge 以及我们的解决方案 , which is another 华彩&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;#Performance&quot;&gt;performance&lt;/a&gt;的逻辑和布局也学习到了！&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实验设置&lt;/li&gt;
&lt;li&gt;整体在xx 和 yy 方面的提升 &amp;amp;  为何会出现这样情况的分析&lt;/li&gt;
&lt;li&gt;在xx方面的结果 翔实的展示； 在yy方面的结果 翔实的展示&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;小细节&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自己拼接造出的单词 ，dash别忘了&lt;ul&gt;
&lt;li&gt;sub-component&lt;/li&gt;
&lt;li&gt;pre-configured&lt;/li&gt;
&lt;li&gt;re-think&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PaperReading" scheme="https://hexi519.github.io/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
      <category term="Congestion Control" scheme="https://hexi519.github.io/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>spinningUpCodesReading</title>
    <link href="https://hexi519.github.io/2020/10/24/Codes/spinningUpCodesReading/"/>
    <id>https://hexi519.github.io/2020/10/24/Codes/spinningUpCodesReading/</id>
    <published>2020-10-24T09:12:07.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
    
    <summary type="html">
    
      notes of reading spinnigup Codes
    
    </summary>
    
    
      <category term="Codes" scheme="https://hexi519.github.io/categories/Codes/"/>
    
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>rlDemo</title>
    <link href="https://hexi519.github.io/2020/10/22/Codes/rlDemo/"/>
    <id>https://hexi519.github.io/2020/10/22/Codes/rlDemo/</id>
    <published>2020-10-22T01:54:51.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h1><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RhdGF3aGFsZWNoaW5hL2xlZWRlZXBybC1ub3Rlcy9ibG9iL21hc3Rlci9jb2Rlcy9RLWxlYXJuaW5nL21haW4ucHk=">base代码<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 老是说我没有权限就很烦...</span></span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py <span class="comment"># use default config  0.9,0.9,0.1,200,0.1,500</span></span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py --gamma 0.95 --me 100</span><br><span class="line">sudo /home/hesy/.conda/envs/py36/bin/python main.py --gamma 0.95 --es 0.99 --me 100</span><br></pre></td></tr></table></figure><ul><li><p>ε-decay和ε-start还有ε-end是耦合的，第一个感觉比较难调整，就调后面两个好了</p>  <img   src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031909-640019.png" alt="image-20201022023149453" style="zoom: 50%;" /><ul><li><p>先用默认参数跑了下，发现其实100步已经妥妥收敛了（右边），所以<strong>me果断设置100</strong> ，确实还不错（见下）</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030751-545506.png" alt="image-202010220307622" style="zoom: 67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031416-949404.png" alt="image-20201022041939" style="zoom:67%;" /></p></li><li><p>最短路径是15步，所以<strong>gamma</strong>我取了个1-1/15，<strong>约等于0.95</strong></p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/025053-715031.png" alt="image-20201022025051942" style="zoom: 67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031206-822872.png" alt="image-20201022024836105" style="zoom:50%;" /></p><p>目前看效果还不错（如上），肯定是train好了，接着调</p></li><li><p><strong>ee 调到0.99</strong>，希望一开始探索多一点</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031126-830561.png" alt="image-20201022025738159" style="zoom:67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/031206-89443.png" alt="image-20201022025802328" style="zoom:67%;" /></p><blockquote><p>可以看到一开始探索多了以后，学习得居然也快了,说明探索到了好的方法</p></blockquote></li><li><p>再分别试试<strong>调大学习率</strong>（0.15）和<strong>调小学习率（0.05</strong>）</p><p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030056-455700.png" alt="image-20201022030055460" style="zoom:67%;" /><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/030335-443486.png" alt="image-20201022030055460" style="zoom:67%;" /></p><blockquote><p>学习率大了以后果然学的就是快hhh </p></blockquote></li></ul></li></ul><h1 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h1><p>还没整理好，先占个坑位</p>]]></content>
    
    <summary type="html">
    
      toy play of rl
    
    </summary>
    
    
      <category term="Codes" scheme="https://hexi519.github.io/categories/Codes/"/>
    
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>rlReview</title>
    <link href="https://hexi519.github.io/2020/10/20/rlReview/"/>
    <id>https://hexi519.github.io/2020/10/20/rlReview/</id>
    <published>2020-10-20T01:28:19.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="回顾时-一下子没想出来的问题"><a href="#回顾时-一下子没想出来的问题" class="headerlink" title="回顾时 一下子没想出来的问题"></a>回顾时 一下子没想出来的问题</h1><ul><li><p>强化学习相对于监督学习为什么训练会更加困难？（强化学习的特征）</p><ul><li><p>强化学习处理的多是序列数据，其很难像监督学习的样本一样满足IID（独立同分布）条件。( needs trivial handling )</p></li><li><p>强化学习有奖励的延迟（Delay Reward），即在Agent的action作用在Environment中时，Environment对于Agent的State的奖励的延迟（Delayed Reward），使得反馈不及时。</p></li><li><p>相比于监督学习有正确的label，可以通过其修正自己的预测，强化学习相当于一个“试错”的过程，其完全根据Environment的“反馈”更新对自己最有利的Action。</p></li></ul></li><li><p>为什么在马尔可夫奖励过程（MRP）中需要有<strong>discount factor</strong>?</p><ul><li><p>有些马尔可夫过程是<strong>带环</strong>的，它并没有终结，然后我们想<strong>避免这个无穷的奖励</strong>；</p></li><li><p>当前步对遥远未来的reward的<strong>贡献</strong>比较小，所以用discount factor弱化未来的奖励在当前步骤的累加值；</p></li><li><p>考虑奖励的<strong>不确定性</strong>：假设在从当前步采取同样的action开始，采样不同的trace，可能有的会会有最终奖励、有的不会（这里以打游戏为例，通关得到的最终奖励远大于平时每个步骤得到的微小奖励 ( 有的设置里面平时的奖励实际上都没有，就只设置最终步骤的奖励 ) ）。综上，未来的奖励是受后续trace影响的，也就是不确定的，有一定概率的，所以从这个角度来看，我们也要给这个未来奖励打一个折扣。</p><blockquote><p>从另一个角度思考，考虑不打折扣的情况–》γ都是1的情况下，就很糟糕。</p></blockquote></li></ul></li><li><p>为什么说Sarsa ( on-policy ) 更加保守，而Q-learning ( off-policy ) 更加大胆且鼓励探索呢？</p><p><img src="https://images.weserv.nl/?url=https://datawhalechina.github.io/leedeeprl-notes/chapter3/img/3.18.png" alt="img"></p><ul><li><strong>鼓励探索</strong></li></ul><p>可以看到，虽然都是使用ε-greedy算法选择动作，但是对于同一个动作( especially探索出来的动作 )，Q-learning给分会比较高（毕竟是给了一个argmax的action对应的值哇）。那么一旦给分高了以后，偏向选择这个动作的概率就会大，就会探索出更多以这个action开头的trace，其中说不定能找到一个比之前更好的trace。而如果是Sarsa的话，这一次探索之后该动作对应的Q值一跃成为最大值可能性就小很多了。与之相比，Q-learning其实就是鼓励探索的。</p><ul><li><strong>更加大胆</strong></li></ul><p>一个很经典的例子就是cliffWalking里面，Q-learning的最终解可以贴着悬崖边上走，但是SARSA是不可以的，这是因为SARSA会考虑到这个贴着悬崖的状态有ε/4的概率会选择向下的动作，然后掉下去( 非最优动作的探索率是 ε/|A|,这里一共有四个动作:上\下\左\右 )，所以这ε/4的低分(死亡)会把这个状态的分数拉下去(而远离悬崖的状态都安全多了，不会有掉下去的概率)；但是Q-learning是只看这个状态会导致的最好结果，which means只看到最后成功的结果，忽视会掉下去的情况，倾向于”铤而走险“。所以个人认为，单纯从找到一个解决方案来看，还是Q-learning比较占优势。</p><blockquote><p> <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGV2aWxtYXljcnk4MTI4Mzk2NjgvcC8xMDMxMjY4NS5odG1s">但是实际中SARSA会比Q-learning表现得更好<i class="fa fa-external-link-alt"></i></span> 其实我觉得这个还得看我们用强化学习来解决什么问题了。我们是要用它来找到一个最优解，还是要让他从头到尾”完备、安全“地做完某事。博客中显然是选择了前一种的概念。</p></blockquote><blockquote><p><code>&quot;那么一旦给分高了以后，偏向选择这个动作的概率就会大&quot;</code></p><p> 这里要区分一个概念：对于ε-greedy来说，除了使得值函数的值最大的那个action以外，其他所有的action的选取概率实际上都是一样的。如果想要按照值函数大小为概率来选择动作的话，可以考虑玻尔兹曼策略或者UCB策略。</p><p>所以，这句话的隐含意思是，<strong>很大可能</strong>这次更新后( 因为加上的是最大值啊喂 )，这个动作对应的Q-value就一跃成为最大值（之一）了，此时其被选取、探索的概率就会变大。</p></blockquote><blockquote><p><strong>个人认为</strong>，Q-learning这方法会跟UCB做赌博机的那个实验效果一样，倾向于<strong>把所有的动作空间都try一遍</strong>（因为一旦概率落到新动作上，如果学习率比较大，那么这个新动作的Q值一下子就会变得很大，一跃成为Q值最大的，所以下次会优先(大概率)选择它，然后就相当于展开了以它为根结点的探索空间）……</p><p>支撑论据：</p><blockquote><p>refer@<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzI2ODQ2MTg2Ng==">知乎<i class="fa fa-external-link-alt"></i></span>，which第一个高票回复我觉得不对，直接在评论里面怼回去了。</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/011454-204261.png" alt="image-20201021175117502" style="zoom: 70%;" /><ul><li><p>可以看到同样的情况下，Q-learning收敛比较慢（因为探索的概率更大哇），但是一旦收敛，就比较稳定了。但是Sarsa就不一样，收敛了以后，由于探索性探索到的动作之前没有好好学习到，所以经常会出现锯齿（which Q-learning已经在前期探索到比较好的策略了）[所以<span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjMvY2hhcHRlcjM=">有人<i class="fa fa-external-link-alt"></i></span>说的“sarsa因为要兼顾探索所以策略不稳定“是这个意思( 并不是说q-learning就没有兼顾探索了hh) ]</p></li><li><p>另一方面，Sarsa由于缺乏探索性（偏向保守），所以没有收敛到一个最优解，也许需要更长的时间才能收敛到Q-learning的程度 ( 可以看到收敛曲线其实还是在缓慢下降的 )</p></li></ul></blockquote><p>所以动作空间别太大哈，不然不就凉凉了2333 【个人觉得off-policy 学习率大的时候适合动作空间比较小的】</p><blockquote><p>which事实证明并不是的2333….我着实没想通</p></blockquote></blockquote><blockquote><p><strong>异策略可以保证充分的探索性</strong>。例如⽤来评估和改善的策略是贪婪策略，⽤于产⽣数据的探索性策略为探索性策略，如ε-soft策略。  – 郭宪 《深入浅出强化学习：原理入门》</p></blockquote></li></ul><ul><li><p>ε-greedy策略是是ε-soft策略中的一种</p><p>如果“严格”的说，ε-greedy策略是 $\frac{\epsilon}{A(s)}-soft$ 的策略。</p><p>解释请参考<span class="exturl" data-url="aHR0cDovL2ZhbmN5ZXJpaS5naXRodWIuaW8vYm9va3MvcmwzLw==">这个博客<i class="fa fa-external-link-alt"></i></span></p></li><li><p>值迭代和策略迭代</p><ul><li><p>参考<span class="exturl" data-url="aHR0cDovL3d1bGMubWUvMjAxOC8wNS8wNS8lRTUlQkMlQkElRTUlOEMlOTYlRTUlQUQlQTYlRTQlQjklQTAlRTclQUMlOTQlRTglQUUlQjAoMSktJUU2JUE2JTgyJUU4JUJGJUIwLw==">这个笔记<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>policy iteration 最后收敛的 value V 是当前 policy 下的 value 值（也做对policy进行评估），目的是为了后面的policy improvement得到新的policy；所以是在<strong>显式地不停迭代 policy</strong>。</p><p>而value iteration 最后收敛得到的 value 是当前state状态下的最优的value值。当 value 最后收敛，那么最优的policy也就得到的。虽然这个过程中 policy 在也在隐式地更新，但是<strong>一直在显式更新的是 value</strong> 的，所以叫value iteration。</p><blockquote><p>那从这个角度来看，PG似乎应该属于policy gradient 2333,毕竟是直接对策略进行更改 ( PG中是直接输出策略而非值函数了，也就是update参数实际上就是update策略 。DQN的话update 参数其实是在更新值函数，因为其模型输出是值函数233 ） </p></blockquote></blockquote></li><li><p>SARSA和Q-learning也都是值迭代引出来的，只不过一个是同策略（on-policy），另一个是异策略（off-policy）。至于是TD还是MC，只不过采样方式和训练效率上的差别而已。</p></li></ul></li><li><p>PG和AC的划分标准可以参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MTY0NTc2OA==">这个知乎<i class="fa fa-external-link-alt"></i></span></p><ul><li><p>A2C实际上是Advantage Actor-Critic的缩写</p></li><li><p><code>在PG策略中，如果我们用Q函数来代替R，那么我们就得到了Actor-Critic方法。</code></p><blockquote><p>所以这里我的理解是：引入了值函数，which作为critic，就是Actor-Critic，有没有baseline并不是最重要的（AC里面，baseline也不一定要用$V(S_t)$ ，不过是因为一般来说，都有了$Q(s,a)$，没道理不用$V(S_t)$作为baseline ）</p></blockquote></li></ul></li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input disabled="" type="checkbox">  【强化学习】中Q-learning,DQN等off-policy算法不需要重要性采样的原因</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg5NTMzOS9hcnRpY2xlL2RldGFpbHMvODQ4ODExNjk=">CSDN<i class="fa fa-external-link-alt"></i></span></p></li><li><p>同策略 采样大，收敛慢； Q-learning 是异策略，还不需要importance sampling </p><blockquote><p>但是我看Q-learning也是一步一更新哇…感觉采样大这个劣势并没有利用好？</p></blockquote></li></ul></li><li><p><input disabled="" type="checkbox">  编程实战书P21 要结合历史观测 是因为部分可观测性？而不是因为非马尔可夫性？</p><p>似乎说得通… 我是因为没有认清当前的状态是什么所以才需要多个state拼在一起的窗口</p></li><li><p><input disabled="" type="checkbox">  交叉熵与one-hot之间的联系</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjQvY2hhcHRlcjQ=">百度飞桨部分给出了一些解释<i class="fa fa-external-link-alt"></i></span>给出了点解释，which我觉得还是没有讲清楚</li><li>check下<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3pob3Vib2xlaS9pbnRyb1JM">强化学习纲要<i class="fa fa-external-link-alt"></i></span>对应部分的讲解</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      Summary
    
    </summary>
    
    
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>rlReview</title>
    <link href="https://hexi519.github.io/2020/10/20/Summary/rlReview/"/>
    <id>https://hexi519.github.io/2020/10/20/Summary/rlReview/</id>
    <published>2020-10-20T01:28:19.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="回顾时-一下子没想出来的问题"><a href="#回顾时-一下子没想出来的问题" class="headerlink" title="回顾时 一下子没想出来的问题"></a>回顾时 一下子没想出来的问题</h1><ul><li><p>强化学习相对于监督学习为什么训练会更加困难？（强化学习的特征）</p><ul><li><p>强化学习处理的多是序列数据，其很难像监督学习的样本一样满足IID（独立同分布）条件。( needs trivial handling )</p></li><li><p>强化学习有奖励的延迟（Delay Reward），即在Agent的action作用在Environment中时，Environment对于Agent的State的奖励的延迟（Delayed Reward），使得反馈不及时。</p></li><li><p>相比于监督学习有正确的label，可以通过其修正自己的预测，强化学习相当于一个“试错”的过程，其完全根据Environment的“反馈”更新对自己最有利的Action。</p></li></ul></li><li><p>为什么在马尔可夫奖励过程（MRP）中需要有<strong>discount factor</strong>?</p><ul><li><p>有些马尔可夫过程是<strong>带环</strong>的，它并没有终结，然后我们想<strong>避免这个无穷的奖励</strong>；</p></li><li><p>当前步对遥远未来的reward的<strong>贡献</strong>比较小，所以用discount factor弱化未来的奖励在当前步骤的累加值；</p></li><li><p>考虑奖励的<strong>不确定性</strong>：假设在从当前步采取同样的action开始，采样不同的trace，可能有的会会有最终奖励、有的不会（这里以打游戏为例，通关得到的最终奖励远大于平时每个步骤得到的微小奖励 ( 有的设置里面平时的奖励实际上都没有，就只设置最终步骤的奖励 ) ）。综上，未来的奖励是受后续trace影响的，也就是不确定的，有一定概率的，所以从这个角度来看，我们也要给这个未来奖励打一个折扣。</p><blockquote><p>从另一个角度思考，考虑不打折扣的情况–》γ都是1的情况下，就很糟糕。</p></blockquote></li></ul></li><li><p>为什么说Sarsa ( on-policy ) 更加保守，而Q-learning ( off-policy ) 更加大胆且鼓励探索呢？</p><p><img src="https://images.weserv.nl/?url=https://datawhalechina.github.io/leedeeprl-notes/chapter3/img/3.18.png" alt="img"></p><ul><li><strong>鼓励探索</strong></li></ul><p>可以看到，虽然都是使用ε-greedy算法选择动作，但是对于同一个动作( especially探索出来的动作 )，Q-learning给分会比较高（毕竟是给了一个argmax的action对应的值哇）。那么一旦给分高了以后，偏向选择这个动作的概率就会大，就会探索出更多以这个action开头的trace，其中说不定能找到一个比之前更好的trace。而如果是Sarsa的话，这一次探索之后该动作对应的Q值一跃成为最大值可能性就小很多了。与之相比，Q-learning其实就是鼓励探索的。</p><ul><li><strong>更加大胆</strong></li></ul><p>一个很经典的例子就是cliffWalking里面，Q-learning的最终解可以贴着悬崖边上走，但是SARSA是不可以的，这是因为SARSA会考虑到这个贴着悬崖的状态有ε/4的概率会选择向下的动作，然后掉下去( 非最优动作的探索率是 ε/|A|,这里一共有四个动作:上\下\左\右 )，所以这ε/4的低分(死亡)会把这个状态的分数拉下去(而远离悬崖的状态都安全多了，不会有掉下去的概率)；但是Q-learning是只看这个状态会导致的最好结果，which means只看到最后成功的结果，忽视会掉下去的情况，倾向于”铤而走险“。所以个人认为，单纯从找到一个解决方案来看，还是Q-learning比较占优势。</p><blockquote><p> <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZGV2aWxtYXljcnk4MTI4Mzk2NjgvcC8xMDMxMjY4NS5odG1s">但是实际中SARSA会比Q-learning表现得更好<i class="fa fa-external-link-alt"></i></span> 其实我觉得这个还得看我们用强化学习来解决什么问题了。我们是要用它来找到一个最优解，还是要让他从头到尾”完备、安全“地做完某事。博客中显然是选择了前一种的概念。</p></blockquote><blockquote><p><code>&quot;那么一旦给分高了以后，偏向选择这个动作的概率就会大&quot;</code></p><p> 这里要区分一个概念：对于ε-greedy来说，除了使得值函数的值最大的那个action以外，其他所有的action的选取概率实际上都是一样的。如果想要按照值函数大小为概率来选择动作的话，可以考虑玻尔兹曼策略或者UCB策略。</p><p>所以，这句话的隐含意思是，<strong>很大可能</strong>这次更新后( 因为加上的是最大值啊喂 )，这个动作对应的Q-value就一跃成为最大值（之一）了，此时其被选取、探索的概率就会变大。</p></blockquote><blockquote><p><strong>个人认为</strong>，Q-learning这方法会跟UCB做赌博机的那个实验效果一样，倾向于<strong>把所有的动作空间都try一遍</strong>（因为一旦概率落到新动作上，如果学习率比较大，那么这个新动作的Q值一下子就会变得很大，一跃成为Q值最大的，所以下次会优先(大概率)选择它，然后就相当于展开了以它为根结点的探索空间）……</p><p>支撑论据：</p><blockquote><p>refer@<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzI2ODQ2MTg2Ng==">知乎<i class="fa fa-external-link-alt"></i></span>，which第一个高票回复我觉得不对，直接在评论里面怼回去了。</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202010/22/011454-204261.png" alt="image-20201021175117502" style="zoom: 70%;" /><ul><li><p>可以看到同样的情况下，Q-learning收敛比较慢（因为探索的概率更大哇），但是一旦收敛，就比较稳定了。但是Sarsa就不一样，收敛了以后，由于探索性探索到的动作之前没有好好学习到，所以经常会出现锯齿（which Q-learning已经在前期探索到比较好的策略了）[所以<span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjMvY2hhcHRlcjM=">有人<i class="fa fa-external-link-alt"></i></span>说的“sarsa因为要兼顾探索所以策略不稳定“是这个意思( 并不是说q-learning就没有兼顾探索了hh) ]</p></li><li><p>另一方面，Sarsa由于缺乏探索性（偏向保守），所以没有收敛到一个最优解，也许需要更长的时间才能收敛到Q-learning的程度 ( 可以看到收敛曲线其实还是在缓慢下降的 )</p></li></ul></blockquote><p>所以动作空间别太大哈，不然不就凉凉了2333 【个人觉得off-policy 学习率大的时候适合动作空间比较小的】</p><blockquote><p>which事实证明并不是的2333….我着实没想通</p></blockquote></blockquote><blockquote><p><strong>异策略可以保证充分的探索性</strong>。例如⽤来评估和改善的策略是贪婪策略，⽤于产⽣数据的探索性策略为探索性策略，如ε-soft策略。  – 郭宪 《深入浅出强化学习：原理入门》</p></blockquote></li></ul><ul><li><p>ε-greedy策略是是ε-soft策略中的一种</p><p>如果“严格”的说，ε-greedy策略是 $\frac{\epsilon}{A(s)}-soft$ 的策略。</p><p>解释请参考<span class="exturl" data-url="aHR0cDovL2ZhbmN5ZXJpaS5naXRodWIuaW8vYm9va3MvcmwzLw==">这个博客<i class="fa fa-external-link-alt"></i></span></p><p>进行符号测试： $\frac{\epsilon}{A(s)}-soft$  成果</p><p>进行符号测试： $ \frac{\epsilon}{A(s)}-soft $  成果</p><p>符号 $$ \frac{\epsilon}{A(s)}-soft$$  测试2</p></li><li><p>值迭代和策略迭代</p><ul><li><p>参考<span class="exturl" data-url="aHR0cDovL3d1bGMubWUvMjAxOC8wNS8wNS8lRTUlQkMlQkElRTUlOEMlOTYlRTUlQUQlQTYlRTQlQjklQTAlRTclQUMlOTQlRTglQUUlQjAoMSktJUU2JUE2JTgyJUU4JUJGJUIwLw==">这个笔记<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>policy iteration 最后收敛的 value V 是当前 policy 下的 value 值（也做对policy进行评估），目的是为了后面的policy improvement得到新的policy；所以是在<strong>显式地不停迭代 policy</strong>。</p><p>而value iteration 最后收敛得到的 value 是当前state状态下的最优的value值。当 value 最后收敛，那么最优的policy也就得到的。虽然这个过程中 policy 在也在隐式地更新，但是<strong>一直在显式更新的是 value</strong> 的，所以叫value iteration。</p><blockquote><p>那从这个角度来看，PG似乎应该属于policy gradient 2333,毕竟是直接对策略进行更改 ( PG中是直接输出策略而非值函数了，也就是update参数实际上就是update策略 。DQN的话update 参数其实是在更新值函数，因为其模型输出是值函数233 ） </p></blockquote></blockquote></li><li><p>SARSA和Q-learning也都是值迭代引出来的，只不过一个是同策略（on-policy），另一个是异策略（off-policy）。至于是TD还是MC，只不过采样方式和训练效率上的差别而已。</p></li></ul></li><li><p>PG和AC的划分标准可以参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MTY0NTc2OA==">这个知乎<i class="fa fa-external-link-alt"></i></span></p><ul><li><p>A2C实际上是Advantage Actor-Critic的缩写</p></li><li><p><code>在PG策略中，如果我们用Q函数来代替R，那么我们就得到了Actor-Critic方法。</code></p><blockquote><p>所以这里我的理解是：引入了值函数，which作为critic，就是Actor-Critic，有没有baseline并不是最重要的（AC里面，baseline也不一定要用$V(S_t)$ ，不过是因为一般来说，都有了$Q(s,a)$，没道理不用$V(S_t)$作为baseline ）</p></blockquote></li></ul></li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input disabled="" type="checkbox">  【强化学习】中Q-learning,DQN等off-policy算法不需要重要性采样的原因</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzg5NTMzOS9hcnRpY2xlL2RldGFpbHMvODQ4ODExNjk=">CSDN<i class="fa fa-external-link-alt"></i></span></p></li><li><p>同策略 采样大，收敛慢； Q-learning 是异策略，还不需要importance sampling </p><blockquote><p>但是我看Q-learning也是一步一更新哇…感觉采样大这个劣势并没有利用好？</p></blockquote></li></ul></li><li><p><input disabled="" type="checkbox">  编程实战书P21 要结合历史观测 是因为部分可观测性？而不是因为非马尔可夫性？</p><p>似乎说得通… 我是因为没有认清当前的状态是什么所以才需要多个state拼在一起的窗口</p></li><li><p><input disabled="" type="checkbox">  交叉熵与one-hot之间的联系</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vbGVlZGVlcHJsLW5vdGVzLyMvY2hhcHRlcjQvY2hhcHRlcjQ=">百度飞桨部分给出了一些解释<i class="fa fa-external-link-alt"></i></span>给出了点解释，which我觉得还是没有讲清楚</li><li>check下<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3pob3Vib2xlaS9pbnRyb1JM">强化学习纲要<i class="fa fa-external-link-alt"></i></span>对应部分的讲解</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      Summary
    
    </summary>
    
    
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>SQR&amp;DLWR|Evaluating and Boosting Reinforcement Learning for Intra-domain Routing</title>
    <link href="https://hexi519.github.io/2020/10/19/PaperReading/SQR-DLWR/"/>
    <id>https://hexi519.github.io/2020/10/19/PaperReading/SQR-DLWR/</id>
    <published>2020-10-19T10:24:31.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>机器学习在计算机视觉和计算机游戏等领域的成功引发了人们对在计算机网络中应用机器学习的兴趣激增。 本文试图回答一个广泛争论的问题：我们能否通过强化学习（RL）来提高域内路由的性能，域内路由是Internet上最基本的模块之一？ 由于复杂的网络流量条件和较大的路由选择空间，很难为现有的基于RL的路由解决方案给出确切的答案。 为了深入了解基于RL的路由的挑战，我们系统地对不同的基于RL的路由解决方案进行了分类，并从可扩展性，稳定性，鲁棒性和收敛性方面研究了几种代表性方法的性能。 结合评估各种基于RL的路由解决方案的经验教训，我们提出了两种方法，称为监督Q网络路由（supervised Q-network routing (SQR)）和基于离散链路权重的路由（discrete link weight-based routing，DLWR），它们可以提高基于RL的路由的性能，并提高性能。 形成事实上的最短路径域内路由。</p><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><p>​    路由是一种网络功能，可将数据包从给定的源传递到给定的目的地。 可以说，它是Internet中最基本的构建块，在服务质量（QoS）保证中起着至关重要的作用。 传统的路由策略，例如开放式最短路径优先（OSPF）路由[1]，可能会导致网络拥塞和链路利用率低，并且与<strong>最佳路由方法相比，性能可能会差5000倍[2]**。 在动态业务量变化的情况下，已经致力于优化路由路径。 例如，反压路由[3]最初是为无线网络提出的，也可以应用在有线网络中，它基于相邻节点之间的拥塞梯度来动态转发流量。 但是，它在路由路径中的收敛速度可能会很长，</strong>并且不一定会导致良好的小队列性能，如[4]<strong>中所证明的。 将机器学习应用于网络路由以获得更好的性能可以追溯到1994年，</strong>当时提出了Q路由的概念[5]。** 由于机器学习在其他领域（例如计算机视觉，游戏和自然语言处理）的巨大成功，最近对Q路由的兴趣再<strong>次兴起[6] [7]**。 另外，最近的一些研究通过在路由中应用深度（强化）学习，证明了令人鼓舞的结</strong>果[8] – [10]<strong>。 这些研究讨论了潜在的基于学习的路由方法，并使用一些典型的机器学习方法进行了评估，例如深度信念架构，深度神经网络（DNN）和信任区域策略优化（TRPO）。 **但是，Internet路由的性能在很大程度上取决于流量动态和各种网络状况</strong>。 <strong>例如，现有的Q路由及其变体会在数据包级别更新路由表，即，他们了解环境并估算单个数据包的数据包交付时间</strong>。 显然，它们的性能在高速网络中会受到影响，在高速网络中，数据包需要以微秒为单位转发。 <strong>在所有路由方案中，一个解决方案都不可能成为“最佳”解决方案并胜过其他解决方案</strong>。 根据这一观察，我们因此有动机去研究Internet路由中不同机器学习算法的利弊，并清除一些（虽然不太可能是全部）在路由中实际采用机器学习的障碍。 我们的研究并非不切实际地针对设计最有效的路由解决方案。 相反，我们提供了lessons(这里我觉得翻译成经验比较好)，在此基础上，我们展示了如何进一步改进现有方法。 </p><p>​    为此，我们研究了基于不同强化学习（RL）的路由策略对域内Internet路由性能的影响。 由于以下三个原因，我们缩小了关注点到RL和域内路由的: (1)<strong>基于RL的路由[8]不需要标记的数据</strong>，由于操作数据的规模大和网络的规模大，这是禁止的并且难以获得 状态;  （2）在路由器处于同一自治系统（AS）域内的域内路由中，可以获得所有路由信息；  （3）软件定义网络（SDN）的发展使通过全局网络视图通过中央控制平面实现智能路由算法变得容易了[11]。</p><p>​    我们在以下方面评估基于RL的路由：(1) <strong>可扩展性</strong>：在高速，大规模网络中是否可以保持良好的性能？(2) <strong>稳定性</strong>：路由方法是否对各种流量模式和网络条件具有弹性？(3) <strong>健壮性</strong>：路由方法是否可以有效避免“不良”路由状态?（例如，congested,long-delay links）？(4) <strong>Convergence</strong>：是否可以快速达到新的路由策略以适应动态网络变化？ 我们对强化学习的研究基于两种主要方法，即基于价值的优化方法和基于策略的优化方法。 图1总结了每种方法的架构及其相应的算法。在我们的研究中，对图1中标有*的算法（它们是强化学习的代表算法）进行了评估。 本文的贡献可以总结如下：</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p>introduction中说到Q路由的事情</p><ul><li><p>在数据包级别更新路由表 ，能保证收敛么…</p></li><li><p>需要调研这些文章</p></li><li><p><strong>在所有路由方案中，一个解决方案都不可能成为“最佳”解决方案并胜过其他解决方案</strong></p><blockquote><p>原来路由也是分场景的！</p></blockquote></li></ul></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      MASS&#39;19
    
    </summary>
    
    
      <category term="PaperReading" scheme="https://hexi519.github.io/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
      <category term="Routing" scheme="https://hexi519.github.io/tags/Routing/"/>
    
  </entry>
  
  <entry>
    <title>pythonConfig</title>
    <link href="https://hexi519.github.io/2020/09/28/Codes/pythonConfig/"/>
    <id>https://hexi519.github.io/2020/09/28/Codes/pythonConfig/</id>
    <published>2020-09-28T01:34:53.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="查看whl文件需要满足的条件"><a href="#查看whl文件需要满足的条件" class="headerlink" title="查看whl文件需要满足的条件"></a>查看whl文件需要满足的条件</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wheel.pep425tags</span><br><span class="line">print(wheel.pep425tags.get_supported())</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      python配置相关总结
    
    </summary>
    
    
      <category term="Codes" scheme="https://hexi519.github.io/categories/Codes/"/>
    
    
      <category term="Language" scheme="https://hexi519.github.io/tags/Language/"/>
    
  </entry>
  
  <entry>
    <title>UDT</title>
    <link href="https://hexi519.github.io/2020/09/22/Codes/UDT/"/>
    <id>https://hexi519.github.io/2020/09/22/Codes/UDT/</id>
    <published>2020-09-22T22:35:59.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="收集的、待整理的文章"><a href="#收集的、待整理的文章" class="headerlink" title="收集的、待整理的文章"></a>收集的、待整理的文章</h1><p>先不看架构了，直接看Aurora了</p><ul><li>wolfcs大佬的博客优先看，在reference那一节里面说了</li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vdWtlcm5lbC9wLzg5NzY5ODQuaHRtbA==">https://www.cnblogs.com/ukernel/p/8976984.html<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc2xpZGVzdGFsay5jb20vdTQyL3Q4ZWZqaw==">https://www.slidestalk.com/u42/t8efjk<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2t0bGlmZW5nL2FydGljbGUvZGV0YWlscy83ODUzMzM1NQ==">https://blog.csdn.net/ktlifeng/article/details/78533355<i class="fa fa-external-link-alt"></i></span></li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly91ZHQuc291cmNlZm9yZ2UuaW8v">sourceforge官网<i class="fa fa-external-link-alt"></i></span> 【05年出的，更新到09年】</p><blockquote><p>ppt 、poster、documention、discussion/help 版块(including Chinese)</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzZGZnaGprbDE5OTMvYXJ0aWNsZS9kZXRhaWxzLzU3NDE3MDc0">udt初步介绍<i class="fa fa-external-link-alt"></i></span> 里面有UDT的架构图，可惜没有再出后续了…</p><blockquote><img src="https://img-blog.csdn.net/20170226170700588?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYXNkZmdoamtsMTk5Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom: 33%;" /><img src="https://img-blog.csdn.net/20170226170750116?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYXNkZmdoamtsMTk5Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom:33%;" /></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  大佬系列博客：<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vY2F0ZWdvcmllcy8lRTclQkQlOTElRTclQkIlOUMlRTUlOEQlOEYlRTglQUUlQUUvcGFnZS81Lw==">udt源码分析<i class="fa fa-external-link-alt"></i></span> 后续想要读源码的话可以==再仔细看一下==（目前只是大概浏览了下）,which我觉得讲得真的不错</p><ul><li><p><input disabled="" type="checkbox">  大佬还有系列在<span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC93b2xmY3M=">oschina的平台上<i class="fa fa-external-link-alt"></i></span></p><blockquote><ul><li><input disabled="" type="checkbox"> 发送窗口大小及发送速率的调整</li><li><input checked="" disabled="" type="checkbox"> 实现分析总结</li></ul></blockquote></li></ul><blockquote><ul><li><p>UDT::startup()的调用过程为：UDT::startup()-&gt; CUDT::startup() -&gt; CUDTUnited::startup()。</p><p>从这里也可以看出UDT、CUDT、CUDTUnited之间的关系</p></li><li><p>UDT的命名规则有些讲究，前缀代表着数据类型</p></li><li><p><strong>设计架构</strong></p><ul><li><p>socket创建那一章说的：UDT的使用者在调用UDT API时，UDT API会直接调用CUDT类对应的static API函数，在CUDT类的这些static API函数中会将做实际事情的工作委托给s_UDTUnited的相应函数，但这个委托调用会被包在一个try-catch block中。s_UDTUnited的函数在遇到异常情况时抛出异常，CUDT类的static API函数捕获异常，根据捕获到的异常的具体类型，创建不同的CUDTException对象设置给s_UDTUnited的线程局部存储变量m_TLSError中并向UDT API调用者返回错误码，UDT API的调用者检测到错误码后，通过UDT::getlasterror()获取存储在m_TLSError中的异常。</p></li><li><p>bind( )函数<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vMjAxNS8wOS8wOS9VRFQlRTUlOEQlOEYlRTglQUUlQUUlRTUlQUUlOUUlRTclOEUlQjAlRTUlODglODYlRTYlOUUlOTAlRTIlODAlOTQlRTIlODAlOTRiaW5kJUUzJTgwJTgxbGlzdGVuJUU0JUI4JThFYWNjZXB0Lw==">那一章<i class="fa fa-external-link-alt"></i></span>说的: 和socket创建时一样是==分为3层==：UDT命名空间中提供了给应用程序调用的接口，可称为<strong>UDT API或User API</strong>；User API调用CUDT API，这一层主要用来做错误处理，也就是捕获动作实际执行过程中抛出的异常并保存起来，然后给应用程序使用；CUDT API调用CUDTUnited中API的实现。</p><blockquote><p>“此处可以看到，CUDT提供的这一层API，一个比较重要的作用大概就是做异常处理了。”</p><p>其实这里没有很懂UDT的==设计艺术==，为什么要分三个层次的类，中间那个特别像个中间件，为什么异常处理要单独拎出来。</p></blockquote></li><li><p>bind( )函数<span class="exturl" data-url="aHR0cHM6Ly93d3cud29sZmNzdGVjaC5jb20vMjAxNS8wOS8wOS9VRFQlRTUlOEQlOEYlRTglQUUlQUUlRTUlQUUlOUUlRTclOEUlQjAlRTUlODglODYlRTYlOUUlOTAlRTIlODAlOTQlRTIlODAlOTRiaW5kJUUzJTgwJTgxbGlzdGVuJUU0JUI4JThFYWNjZXB0Lw==">那一章<i class="fa fa-external-link-alt"></i></span>还介绍了UDT的多路复用器CMultiplexer、通道CChannel、发送队列CSndQueue和接收队列CRcvQueue的含义</p><ul><li><p><strong>CChannel</strong></p><blockquote><p>系统UDP socket的一个封装，它主要封装了系统UDP socket handle，IP版本号，socket地址的长度，发送缓冲区的大小及接收缓冲区的大小等信息，并提供了用于操作 系统UDP socket进行数据收发或属性设置等动作的函数。</p></blockquote></li><li><p><input disabled="" type="checkbox">  其实没有很懂多路复用器(Multiplexer)和socket之间的关系 ( 监听端口到底是什么操作？我理解的目前是socketchannel可以实现在一个线程里面监听多个某个端口的状况 ( 是否接收了数据等等 ) 并将更新的情况跟selector ( 也就是多路复用器 ) 交流 ,which会选择让哪个socket去处理这件事情) 、</p></li><li><p>CRcvQueue</p><blockquote><p>在接收队列CRcvQueue的worker线程中，接收到一条消息之后，它会根据消息的目标SocketID，及发送端的地址等信息，将消息以不同的方式进行dispatch</p></blockquote></li></ul></li></ul></li></ul></blockquote></li><li><p><input disabled="" type="checkbox">  这个<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vdWtlcm5lbC9wLzg5NzY5ODQuaHRtbA==">UDT源码剖析<i class="fa fa-external-link-alt"></i></span>系列博客讲得很详细，相当于每个头文件在讲解了</p></li><li><p><span class="exturl" data-url="aHR0cDovL3d3dy53aXNlc3R1ZHkuY24vb3BlbnRlY2gvdWR0LWNvbmdlc3Rpb25Db250cm9sQWxnb3JpdGhtLmh0bWw=">这个博客<i class="fa fa-external-link-alt"></i></span>相当于翻译了udt的论文</p></li><li><p><input disabled="" type="checkbox">  ==CS 224==的那个project是怎么整的 还得看下</p></li><li><p>udt思路及代码分析</p><ul><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cDovL3d3dy53aXNlc3R1ZHkuY24vb3BlbnRlY2gvdWR0LWNvbmdlc3Rpb25Db250cm9sQWxnb3JpdGhtLmh0bWw=">这个<i class="fa fa-external-link-alt"></i></span>里面有代码架构分析</li><li><input disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9uZXR3b3JrLjUxY3RvLmNvbS9hcnQvMjAxNDA5LzQ1MTEzOS5odG0=">这个<i class="fa fa-external-link-alt"></i></span>里面有伪代码</li></ul></li><li><p><span class="exturl" data-url="aHR0cHM6Ly91ZHQuc291cmNlZm9yZ2UuaW8vdWR0NC8=">官方提供的reference<i class="fa fa-external-link-alt"></i></span>里面就有api手册  [代码的doc文件里面也可以离线查看]</p></li></ul><h1 id="代码架构"><a href="#代码架构" class="headerlink" title="代码架构"></a>代码架构</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./src:     UDT <span class="built_in">source</span> code </span><br><span class="line">./app:     Example programs </span><br><span class="line">./doc:     UDT documentation (HTML)</span><br><span class="line">./win:     Visual C++ project files <span class="keyword">for</span> the Windows version of UDT </span><br></pre></td></tr></table></figure><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>refer@WolfCS的<span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC93b2xmY3MvYmxvZy81MTIwNjE=">UDT实现分析总结<i class="fa fa-external-link-alt"></i></span></p><ul><li><p><strong>UDT Socket</strong>是UDT中的核心，同时它也是一座桥梁，它将UDT的使用者应用程序与内部实现部分对于数据结构的管理、网络数据的传输连接起来。</p></li><li><p><strong>应用程序通过它</strong>将数据放进发送缓冲待发送，或者借由它来获取从网络接收数据。而与网络进行交互的部分，则从它那里拿到要发送的数据进行发送，或者在收到packet时将packet dispatch给它。</p></li></ul><h3 id="数据接收部分框架"><a href="#数据接收部分框架" class="headerlink" title="数据接收部分框架"></a>数据接收部分框架</h3><img src="http://static.oschina.net/uploads/space/2015/0928/110552_YTa3_919237.jpg" alt="110552_YTa3_919237.jpg" style="zoom: 67%;" /><h3 id="数据发送部分框架"><a href="#数据发送部分框架" class="headerlink" title="数据发送部分框架"></a>数据发送部分框架</h3><img src="http://static.oschina.net/uploads/space/2015/0928/135751_Ftye_919237.jpg" alt="img" style="zoom:67%;" /><h2 id="UDT-socket-structures"><a href="#UDT-socket-structures" class="headerlink" title="UDT socket structures"></a>UDT socket structures</h2><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/25/141253-492288.png" alt="image-20200923200351000" style="zoom: 80%;" /><ul><li><p>socket文件描述符 +  错误码 + UDT socket集合 + TraceInfo ()</p><ul><li><p>TraceInfo , performance的一些数据</p><ul><li><p><strong>aggregate</strong> values</p><ul><li>pktSndLossTotal 和 pktRcvLossTotal的区别？？这个RcvLoss怎么测试呢==？？==</li></ul></li><li><p><strong>local</strong> values since last recorded time</p><blockquote><p>目前理解是一段时间的period算出来的值  ==??不是很确定==</p></blockquote></li><li><p><strong>instant</strong> values at the time they are observed</p></li></ul></li></ul></li></ul><h2 id="UDT-socket-functions"><a href="#UDT-socket-functions" class="headerlink" title="UDT socket functions"></a>UDT socket functions</h2><ul><li>perfmon</li><li>其他的大部i分都跟传统的socket编程的api一致</li></ul><h2 id="CC-Base-Class"><a href="#CC-Base-Class" class="headerlink" title="CC Base Class"></a>CC Base Class</h2><ul><li><p>ccc.h文件定义了父类</p></li><li><p>app/cc.h里面定义了一个基于CCC的拥塞控制方法，是一个good tutorial</p></li><li><p>注意事项</p><ul><li>不要在CCC内部或者它的继承类中调用regular UDT API, 会有未知错误发生</li><li>CCCFactory&lt;…&gt;  是一个C++模板，不需要用类去继承他</li><li>UDT不会立马释放CCCFactory&lt;…&gt;的实例，应该在application类里面释放，只要是在setsockopt（）后就可以</li></ul></li></ul><h1 id="一些中途冒出来的想法"><a href="#一些中途冒出来的想法" class="headerlink" title="一些中途冒出来的想法"></a>一些中途冒出来的想法</h1><p>正如Sigcomm‘2020所示，我们的主机开销也算是延迟的一部分，那么我们的算法的耗时会不会影响整个delay的状况呢 ? </p><h1 id="代码疑惑"><a href="#代码疑惑" class="headerlink" title="代码疑惑"></a>代码疑惑</h1><ul><li><p><input disabled="" type="checkbox">  为什么可以不提前声明，也不include。虽然queue.h确实是在之前被编译的，但是这个就不需要指明依赖关系么</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926102437531.png" alt="image-20200926102437531" style="zoom: 50%;" /></li><li><p><input disabled="" type="checkbox">  又用到工厂模式了，可惜我还是不会（ 不过也不是重点，回头看下</p></li><li><p><input disabled="" type="checkbox">  之前master说TCP buffer不需要很大，不停poll就行？？ why ?没有很理解</p></li><li><p><input disabled="" type="checkbox">  用sourceCode整理一下代码结构</p></li></ul>]]></content>
    
    <summary type="html">
    
      UDT架构
    
    </summary>
    
    
      <category term="Codes" scheme="https://hexi519.github.io/categories/Codes/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Congestion Control" scheme="https://hexi519.github.io/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>socket编程</title>
    <link href="https://hexi519.github.io/2020/09/22/Codes/socket%E7%BC%96%E7%A8%8B/"/>
    <id>https://hexi519.github.io/2020/09/22/Codes/socket%E7%BC%96%E7%A8%8B/</id>
    <published>2020-09-22T22:35:59.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><ul><li><p>《Linux系统编程、网络编程》第10章 网络编程视频课程 ,which is in my Baidu Cloud</p><blockquote><p>目前看到12了，其他的组会上听吧</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVJKNDExQjc2MS8/c3BtX2lkX2Zyb209MzMzLjc4OC52aWRlb2NhcmQuMQ==">这个b站视频<i class="fa fa-external-link-alt"></i></span>似乎是专门讲Unix网络编程这本书的</p></li><li><p><input disabled="" type="checkbox">  百度云里面存了一个系列视频，我觉得也不错</p></li></ul><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><ul><li>socket就是一个文件描述符，但是没有文件名（Linux有七种文件描述符）</li></ul><h2 id="bind"><a href="#bind" class="headerlink" title="bind( )"></a>bind( )</h2><ul><li>bind ( int sockfd ,  const struct sockaddr *addr , socklen_t addrlen  )</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span>  <span class="keyword">short</span>  sa_family;     <span class="comment">/* address family, AF_xxx */</span></span><br><span class="line">    <span class="keyword">char</span>  sa_data[<span class="number">14</span>];                 <span class="comment">/* 14 bytes of protocol address */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span>  <span class="title">sockaddr_in</span> &#123;</span></span><br><span class="line">    <span class="keyword">short</span> <span class="keyword">int</span> sin_family;              <span class="comment">/* Address family */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">short</span> <span class="keyword">int</span> sin_port;       <span class="comment">/* Port number */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">in_addr</span> <span class="title">sin_addr</span>;</span>           <span class="comment">/* Internet address */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> sin_zero[<span class="number">8</span>];    <span class="comment">/*padding to be the same size as struct sockaddr*/</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>因为sockaddr中直接在char[] 里面写端口和ip比较麻烦，所以用了sockaddr_in, which是分开来记录的</p><blockquote><p>这里sin的意思就是：s代表sockaddr ， in就是sockaddr_in后缀的in的意思</p><p>sin_addr存储的是ipv4的地址 ，acutually就只有32位的 unsigned int ，s_addr 【这个起名真是绕人啊…】</p><p>姑且认为，这里sockaddr_in里面的in代表着是包含在sockaddr内部的</p></blockquote><p>将sockaddr_in强制转换成sockaddr，看到有人这么写：(struct sockaddr*) &amp;sockaddr_in , ==感觉很神奇？不知道理由是什么==</p></li></ul><h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll( )"></a>epoll( )</h2><ul><li><p><strong>epoll的过程</strong></p><ul><li><p>创建红黑树    <strong>epoll_create</strong>( int size)</p><blockquote><p>现在内核已经优化到size写一个大于0的数即可</p></blockquote></li><li><p>向树上增加要监听的文件描述符（已经上树了的就不用再上树了）</p><p><strong>epoll_ctl</strong> ( int epfd,  int op, int fd, struct epoll_event* event )</p><blockquote><p><strong>epfd</strong>  红黑树的根节点</p><p><strong>op</strong> 对红黑树的修改操作</p><pre><code>* EPOLL_CTL_ADD  上树 * EPOLL_CTL_MOD  修改* EPOLL_CTL_DEL 下树 </code></pre><p><strong>fd</strong> 要上树的文件描述符</p><p><strong>event</strong>  要监听该文件描述符的什么操作</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> epoll_data &#123;</span><br><span class="line">   <span class="keyword">void</span>    *ptr;</span><br><span class="line">   <span class="keyword">int</span>      fd;</span><br><span class="line">   <span class="keyword">uint32_t</span> u32;</span><br><span class="line">   <span class="keyword">uint64_t</span> u64;</span><br><span class="line">&#125; <span class="keyword">epoll_data_t</span>;  <span class="comment">// 一般就用上面两个</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">   <span class="keyword">uint32_t</span> events; <span class="comment">/*Epoll events,e.g.EPOLLIN,EPOLLOUT(也主要是这两个事件)*/</span></span><br><span class="line">   <span class="keyword">epoll_data_t</span> data;      <span class="comment">/* User data variable */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><strong>细节</strong>：在上树的时候，每个节点既包含了文件描述符fd的信息，又包含了event的信息</p></blockquote></li><li><p>监听节点  <strong>epoll_wait</strong>( int epfd, struct epoll_event *events,int maxevents, int timeout )</p><ul><li>events提供了一个用于存放返回值的数组</li><li>maxevents提供了数组的大小</li><li>返回值是 返回的事件的个数</li></ul></li></ul></li></ul><ul><li><input disabled="" type="checkbox"> epoll反应堆</li></ul><h2 id="setsockopt"><a href="#setsockopt" class="headerlink" title="setsockopt( )"></a>setsockopt( )</h2><ul><li>在创建socket之后，bind之前设定（比如说SO_REUSEADDR）<ul><li>SO_REUSEADDR 端口复用，为何可以端口复用？可以参考下<span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vZW50cnkvNjg0NDkwMzUwOTYyNDY1MTc5MA==">这篇博客<i class="fa fa-external-link-alt"></i></span>提出的理由</li></ul></li></ul><h2 id="tl-dr"><a href="#tl-dr" class="headerlink" title="tl;dr"></a>tl;dr</h2><ul><li><input disabled="" type="checkbox"> ==看完了<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVJKNDExQjc2MT9wPTU2">P56 epoll反应堆<i class="fa fa-external-link-alt"></i></span>==，觉得这个系列视频讲得蛮好的，有空要接着看。</li></ul><h1 id="字节序转换"><a href="#字节序转换" class="headerlink" title="字节序转换"></a>字节序转换</h1><ul><li><p>主机字节序  无论是大端还是小端  本机的字节序就叫主机字节序</p></li><li><p>htonl  这里的l 是long ，32位 ; htons 这里的s是 short ，16位。无论是long还是short ，都是大端的</p><p><strong>htonl</strong> 用于转换ip地址（4个字节）  –》 attention 这里的ip地址是数值形式的（而非点分十进制）</p><p><strong>htons</strong> 用于转换端口号（2个字节）</p><blockquote><p>host to numerical long , host to numerical short</p></blockquote></li><li><p><strong>inet_pton</strong></p><p>将ip地址从点分十进制( point )转换为大端的数值( numerical )形式</p><p><strong>inet_ntop</strong></p></li><li><p>网络编程中尽量都用无符号的 ，不然一不小心出现负值</p></li></ul><h1 id="五大IO模型"><a href="#五大IO模型" class="headerlink" title="五大IO模型"></a>五大IO模型</h1><h2 id="阻塞IO-BIO"><a href="#阻塞IO-BIO" class="headerlink" title="阻塞IO BIO"></a>阻塞IO BIO</h2><p>应用层accept( ) –&gt;  内核recvFrom( <strong>Block</strong>，…  ) 取一个socket</p><p>​            |</p><p>​            V</p><p>应用层read( ) –&gt;内核 recvFrom( <strong>Block</strong>，… ) 取字节流</p><p>​            |</p><p>​            V</p><p>​            ….</p><ul><li>如果accept的时候没有客户端连接上来，那么就卡在这一步，不会往下行进了</li><li>另一方面，如果此时有别的连接进来了，也不会搭理，因为线程阻塞在其中某个步骤中了‘<ul><li>没有办法处理多个客户端连接的情况</li></ul></li></ul><h2 id="非阻塞IO-基于线程驱动模型"><a href="#非阻塞IO-基于线程驱动模型" class="headerlink" title="非阻塞IO   基于线程驱动模型"></a>非阻塞IO   基于线程驱动模型</h2><p>应用层accept( ) –&gt; 内核recvFrom( <strong>nonBlock</strong>，… ) 取一个socket</p><p>​            |</p><p>​            V</p><p>应用层read( ) –&gt; 内核recvFrom( <strong>nonBlock</strong>，… ) 取字节流</p><p>​            |</p><p>​            V</p><p>​            ….</p><ul><li>如果有客户端进来，我可以都处理–&gt;实际上是利用非阻塞的性质，一个函数没有获得结果，我还是可以往下走，keep循环走这个流程</li></ul><h2 id="IO多路复用-NIO-new-IO-基于事件驱动模型"><a href="#IO多路复用-NIO-new-IO-基于事件驱动模型" class="headerlink" title="IO多路复用 NIO new IO   基于事件驱动模型"></a>IO多路复用 NIO new IO   基于事件驱动模型</h2><blockquote><p>New IO是java的一个包，which includes socketChannel,ByteBuffer，Nonblocking IO是Linux操作系统的非阻塞IO</p></blockquote><ul><li>多路复用器 应用层select( ) –&gt; 内核epoll( )</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/26/145842-614824.png" alt="image-20200926145841363"></p><pre><code>* epoll的过程是非阻塞的，但是处理数据的过程是阻塞的（当然还是得遍历，一个一个去处理）* 此外，epoll做了优化，不用把数据从内核空间拷贝到用户空间了，采用内存地址的方式，实现了“零拷贝”</code></pre><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><ul><li><p><strong>channel</strong></p><ul><li><p>BIO读写都是单向的</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926150226860.png" alt="image-20200926150226860" style="zoom:67%;" /><p>但是NIO是双向的（利用channel）</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200926151233132.png" alt="image-20200926151233132" style="zoom:67%;" /><p>且在byte数组基础上还包装成了bytebuffer</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY2hlbnBpL3AvNTM3Mjc4Ni5odG1s">bytebuffer与channel的交互<i class="fa fa-external-link-alt"></i></span></p></blockquote></li></ul></li><li><p><strong>selector</strong></p></li></ul><h2 id="NIO-reactor模型-反应堆模型"><a href="#NIO-reactor模型-反应堆模型" class="headerlink" title="NIO reactor模型  反应堆模型"></a>NIO reactor模型  反应堆模型</h2><ul><li>单线程</li><li>多线程</li><li>主从模型</li></ul>]]></content>
    
    <summary type="html">
    
      socket编程中API整理
    
    </summary>
    
    
      <category term="Codes" scheme="https://hexi519.github.io/categories/Codes/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>gcc链接梳理</title>
    <link href="https://hexi519.github.io/2020/09/18/Summary/LinkDebug/"/>
    <id>https://hexi519.github.io/2020/09/18/Summary/LinkDebug/</id>
    <published>2020-09-18T22:34:22.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA5MzUwNzYvYXJ0aWNsZS9kZXRhaWxzLzUxMzc0Mzg4">这个博客<i class="fa fa-external-link-alt"></i></span>写的很全</p></li><li><p>程序员的自我修养</p><blockquote><p>相关内容，自己的博客上有总结其中几章</p><ul><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTAxMTA1NTcz">chapeter 6 可执行文件(.o)及动态链接(.a)的装载与进程<i class="fa fa-external-link-alt"></i></span></p></li><li><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTAxMTE5Njk2">chapeter 8 Linux共享库(.so)的组织<i class="fa fa-external-link-alt"></i></span></p><blockquote><p>主要讲了一些补充的、正交的 加载相关的环境变量，方便debug编译和链接过程</p></blockquote></li></ul></blockquote></li></ul><h2 id="nm命令-–-查看二进制和符号表的利器"><a href="#nm命令-–-查看二进制和符号表的利器" class="headerlink" title="nm命令  –  查看二进制和符号表的利器"></a>nm命令  –  查看二进制和符号表的利器</h2><blockquote><p>其实还有很多常用的用来读库文件的命令，比如objdump ， readelf ,  这里不过是因为nm比较通用，所以重点介绍一下（其实觉得objdump可以出更多的信息的） </p></blockquote><ul><li><p>nm -g –defined-only libxxx.a # -g 查看外部符号表 ，也是–extern-only</p><blockquote><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/18/224322-528256.png" alt="image-20200918224319703" style="zoom: 67%;" /></blockquote><p>  会把.a文件是从<strong>哪些.o文件</strong>中打包过来以及<strong>对应吸收了哪些符号</strong>都标清楚。</p></li></ul><h2 id="a-libxxxx-a-archive-和-so-libxxxx-so-major-minor-shared-object-的区别"><a href="#a-libxxxx-a-archive-和-so-libxxxx-so-major-minor-shared-object-的区别" class="headerlink" title=".a(libxxxx.a)[archive]和 .so(libxxxx.so.major.minor) [shared object]的区别"></a>.a(libxxxx.a)[archive]和 .so(libxxxx.so.major.minor) [shared object]的区别</h2><h3 id="生成"><a href="#生成" class="headerlink" title="生成"></a><strong>生成</strong></h3><ol><li><p>生成<strong>静态库</strong>使用ar工具，其实ar是archive的意思</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ar cqs libhello.a hello.o</span><br></pre></td></tr></table></figure><p>​    静态库与汇编生成的目标文件一起链接为可执行文件，那么静态库必定跟.o文件格式相似。其实一个静态库可以简单看成是<strong>一组目标文件</strong>（.o/.obj文件）的集合，即很多目标文件经过压缩打包后形成的一个文件。（这里cqs是静态库的名称，别搞混了）</p></li><li><p>生成<strong>动态库</strong>用gcc来完成，由于可能存在多个版本，因此通常指定版本号：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步</span></span><br><span class="line">g++ -fPIC -o DynamicMath.o DynamicMath.cpp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步</span></span><br><span class="line">g++ -shared -o libhello.so.1.0 DynamicMath.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合起来就是</span></span><br><span class="line">g++ -fPIC -shared -o libhello.so.1.0 DynamicMath.o.cpp</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>-shared: 表示生成的是动态链接库</p><p>-fPIC: 生成位置独立的代码，用于编译共享库。在任意内存空间都可以被加载</p><p>-Wall: 生成所有警告信息</p><p>前两个是必加的参数，最后一个有时候会加</p></li></ul><h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a><strong>查看</strong></h3><ul><li><p><strong>查看静态库包含了哪些.o文件也很简单</strong>：</p><ul><li><p>nm -g 命令 （上文） 还会列出符号表 </p></li><li><p>ar -t llibxx.a  ( display a <u>table</u> listing contents of the archive )</p><blockquote><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/18/230631-588422.png" alt="image-20200918230630480" style="zoom:67%;" /></blockquote></li></ul></li><li><p>查看<strong>动态库</strong>包含了哪些文件</p><ul><li><p>目前没有找到办法查看，只能使用<strong>nm -D xx.so</strong>的方式去查看动态库的动态符号表</p><ul><li>注意，nm的-D参数只对动态库有效</li></ul></li></ul></li></ul><h3 id="调用-–》被载入的时刻不同-最主要的区别在于此"><a href="#调用-–》被载入的时刻不同-最主要的区别在于此" class="headerlink" title="调用 –》被载入的时刻不同 [最主要的区别在于此]"></a><strong>调用</strong> –》被载入的时刻不同 [<strong>最主要的区别</strong>在于此]</h3><ul><li><p>静态库的代码在编译过程中已经被载入可执行程序，因此体积较大</p></li><li><p>共享库(动态库)的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此代码体积较小。</p></li><li><p>共享库(动态库)的好处是，不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例。【这就是共享库诞生的原因之一，另一点就是静态库需要全量更新，但是动态库只需要增量更新】</p></li></ul><ul><li><p><strong>调用命令</strong> 都是一致的</p><p>gcc -L紧跟目录名字 -l紧跟库名字, e.g. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -o hello main.c -L. -lmyhello</span><br></pre></td></tr></table></figure><blockquote><p>-L表示搜寻库的目录，-I表示依赖库的名称（这里是L的小写，表示lib）。这个应该都知道把…</p><p>-I（这里是i的大写）（inlcude的意思） 这里用不到，但是也经常用，就直接补充下把，是头文件(.h)所在的路径  </p></blockquote><ul><li><p>请注意，==-lxx一定要写在最后面==，因为gcc的命令是从左到右执行的，被依赖项得放在右边，因为是先解析main.c然后看到里面有一些外部的符号，which是在myhello这个库里面的，然后就往右边解析去寻找这个符号</p><ul><li><p>为什么这么做就很明了， 按需取你需要的符号，which means 没必要把整个myhello库都加载进内存或者集成到最终的hello可执行文件中</p></li><li><p>如果有循环依赖( libA.a&lt;–&gt;libB.so )，那么也要反复写依赖库， which means要写成gcc -IA -IB -IA</p></li></ul></li><li><blockquote><p>gcc -lmath -c test.cc -o test.o  <strong>[ x ]</strong><br>gcc -c test.cc -o test.o -lmath  <strong>[ √ ]</strong></p></blockquote></li><li><p>动态静态库都存在的时候，优先使用.so文件（毕竟动态库开销小、跨平台）</p><blockquote><p>如果想链接的就是动态库的话，就用如下参数：-WI,-Bstatic</p><p>关于WI参数和Bstatic的用法，可以参考<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzIyOTQwMDQ4">这个回答<i class="fa fa-external-link-alt"></i></span></p><p>进一步，使用WI指定链接的soname可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmdfaHVmZW5nL2FydGljbGUvZGV0YWlscy81Mzg5OTEyMA==">这个<i class="fa fa-external-link-alt"></i></span></p></blockquote></li><li><p>动态库链接和运行时加载的过程是分开的，所以有时候链接的时候成功了，但是运行起来还是会报找不到符号表的错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-LsoLibPath  <span class="comment"># 链接时的路径</span></span><br><span class="line">-WI,rpath=soLibPath  <span class="comment"># 链接时指定的参数，用于运行时加载的路径</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="链接时的默认搜索顺序、搜索路径"><a href="#链接时的默认搜索顺序、搜索路径" class="headerlink" title="链接时的默认搜索顺序、搜索路径"></a>链接时的默认搜索顺序、搜索路径</h3><h4 id="静态库"><a href="#静态库" class="headerlink" title="静态库"></a>静态库</h4><p>搜索顺序：</p><ol><li><p>GCC命令中的参数 -L</p><ol start="2"><li>gcc的环境变量LIBRARY_PATH</li><li>内定目录 /lib /usr/lib /usr/local/lib 这是当初compile gcc时写在程序内的</li></ol></li></ol><h4 id="动态库"><a href="#动态库" class="headerlink" title="动态库"></a>动态库</h4><ol><li><p>GCC命令中的参数 -L</p></li><li><p>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</p></li><li><p>配置文件/etc/ld.so.conf中指定的动态库搜索路径</p></li><li><p>默认的动态库搜索路径 /lib 和 /usr/lib</p><blockquote><p>/lib 或 /usr/lib（64位系统下为/lib64 /usr/lib64）路径下的共享库比较特殊。 </p><p>a) 它是默认的共享库的搜索路径。 </p><p>b) 它没有放到/etc/ld.so.conf 文件中。但是在/etc/ld.so.cache 的缓存中有它。 </p><p>c) 其路径下的共享库的变动<strong>即时生效</strong>，不用执行ldconfig。就算缓存ldconfig -p 中没有，新加入的动态库也可以执行。</p></blockquote></li></ol><h3 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h3><ul><li>其实会发现，路径的配置都是遵循着一个从小到大，从内到外的顺序（就跟局部变量和全局变量一样）</li></ul><h2 id="ldconfig"><a href="#ldconfig" class="headerlink" title="ldconfig"></a>ldconfig</h2><p>==注意，这是针对<strong>动态库</strong>的<strong>加载时路径</strong>的配置，<strong>和编译的路径无关</strong>==</p><ul><li><p>/etc/ld.so.conf 是指定动态库搜索路径的一个配置文件</p><blockquote><p>一般cat出来，里面的内容就是：<code>include /etc/ld.so.conf.d/*.conf</code></p><p>这意味着，具体的动态库搜索路径还是由/etc/ld.so.conf.d里面的conf文件决定，简单看下这个文件夹里面有些什么：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/24/172716-465653.png" alt="image-20200924172715424"></p></blockquote></li><li><p>/etc/ld.so.conf.d</p><p>简单看下这个文件夹里面有些什么：</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202009/24/172716-465653.png" alt="image-20200924172715424"></p><p>实际上这是各个安装文件在安装时会自带的config文件，所有的配置集合最终会在ldconfig.so.cache里面存放</p><p>所以<strong>一般安装完一个文件</strong>，都会在ldconfig.so.conf.d文件夹里面更新相应的xx.config文件，这时候<strong>要使用ldconfig命令进行对ldconfig.so.cache文件的更新</strong>，which work according to ldconfig.so.conf , which will traverse ldconfig.so.d recursively to get the *.so/*.a files and record into teh cache file.</p></li><li><p>程序运行时加载库的时候，最终就是从<strong>ldconfig.so.cache</strong>这个文件里面去找</p><blockquote><p>这是一个二进制文件，没法直接查看，但是可以通过ldconfig -p去查看</p></blockquote></li><li><p><strong>ldconfig</strong></p><ul><li><p>当把库安装在/lib或者/usr/lib等默认的搜索路径以后，需要手动修改ld.so.conf文件添加对应路径，然后再调用ldconfig去更新cache文件</p><ul><li>注意，有root权限才可以修改ld.so.conf以及调用ldconfig进行对/etc/ldconfig.so.cache的更新</li></ul></li><li><p>没有root权限的时候就是采用修改环境变量LD_LIBRARY_PATH的方式 或者 编译时候添加参数( -WI,rpath=xxx )  </p><blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rpath</span> <span class="string">-- running path</span></span><br><span class="line"><span class="attr">Wl</span> <span class="string">的l 代表的是把后面的数传递给链接器(ld) </span></span><br></pre></td></tr></table></figure></blockquote><ul><li>注意，添加-L编译参数的方法属于链接路径，ldconfig管的是加载时路径，这两个不要混肴了</li><li>-WI参数和-Xlinker参数的区别可以看<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vcmlja3lrL3AvNDE4NjkwMi5odG1s">这个博客<i class="fa fa-external-link-alt"></i></span></li></ul></li><li><p>其他参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ldconfig -p 查看共享库的缓存内容 ( <span class="built_in">print</span> ld.config.cache )</span><br><span class="line">ldconfig -n 在当前文件夹下创建软链接，后面编译链接的时候还得加个-L路径参数指向这个文件夹</span><br><span class="line">ldconfig主要的作用是根据/etc/ld.so.conf 的内容，查找内容中所包含目录下实际的动态库文件，生成搜索共享库的缓存文件/etc/ld.so.cache</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="小心得"><a href="#小心得" class="headerlink" title="小心得"></a>小心得</h3><ul><li><p>安装完新的库之后，不管三七二十一，ldconfig一下</p></li><li><p>一开始我很好奇为什么要引入一个/etc/ld.so.cache，搞得那么麻烦。看到有资料是这么说的：</p><blockquote><p>linux下的共享库机制采用了类似于高速缓存的机制，将库信息保存在/etc/ld.so.cache里边</p></blockquote></li></ul><h2 id="ldd-ld-dependency"><a href="#ldd-ld-dependency" class="headerlink" title="ldd (ld dependency)"></a>ldd (ld dependency)</h2><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2RkYWkvcC8xMDM5NzUxMC5odG1s">ldd原理介绍<i class="fa fa-external-link-alt"></i></span> （最下方） </li></ul><p>例子：</p><p>ldd /usr/bin/passwd  得到返回：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NTP-slave:/usr/<span class="built_in">local</span>/openssl/lib </span><br><span class="line">linux-vdso.so.1 =&gt;  (0x00007fff15dff000)</span><br><span class="line">libpam.so.0 =&gt; /lib64/libpam.so.0 (0x00007fce5eb4b000)</span><br><span class="line">libldap-2.4.so.2 =&gt; /usr/lib64/libldap-2.4.so.2 (0x00007fce5e901000)</span><br><span class="line">        ...省略...</span><br><span class="line">libcrypto.so.0.9.8 =&gt; /usr/lib64/libcrypto.so.0.9.8 (0x00007fce5cefc000)</span><br><span class="line">/lib64/ld-linux-x86-64.so.2 (0x00007fce5f1a3000)</span><br><span class="line">libz.so.1 =&gt; /lib64/libz.so.1 (0x00007fce5cce5000)</span><br></pre></td></tr></table></figure><p>第一列：程序需要依赖什么库<br>第二列: 系统提供的与程序需要的库所对应的库<br>第三列：库加载的开始地址</p><p>通过上面的信息，我们可以得到以下几个信息：<br>1.通过对比第一列和第二列，我们可以分析程序需要依赖的库和系统实际提供的，是否相匹配<br>2.通过观察第三列，我们可以知道在当前的库中的符号在对应的进程的地址空间中的开始位置<br>如果依赖的某个库找不到，通过这个命令可以迅速定位问题所在</p><ul><li>是一个脚本而不是程序</li></ul><h1 id="待整理"><a href="#待整理" class="headerlink" title="待整理"></a>待整理</h1><ul><li><p><span class="exturl" data-url="aHR0cDovL3d3dy5qZWVweGllLm5ldC9hcnRpY2xlLzg4NDU2MC5odG1s">符号表的含义<i class="fa fa-external-link-alt"></i></span>  &amp; <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbGl1eWFueWd6L3AvNTUzNjYwNy5odG1s">还有这个<i class="fa fa-external-link-alt"></i></span></p><ul><li><p>mangle</p><blockquote><p>恢复mangle后的函数名称使用<strong>c++filt</strong>命令即可,e.g.</p><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200925114818204.png" alt="image-20200925114818204" style="zoom: 80%;" /></blockquote></li><li><p>U是未定义，which means 是调用外界的函数（在其它库中定义的），T(位于text section)表示函数是当前库中定义的，W(weak)类是当前库中定义，被其它库中的函数覆盖），B(位于bss section)</p></li><li><p>nm -n 按照地址排列符号 （–numeric sort )</p></li><li><p>nm -u 打印未定义符号 （ldd -r xx.so 也可以）</p></li></ul></li><li><p><input checked="" disabled="" type="checkbox">  终于明白了为什么makefile里面有的地方不需要.h，有的地方需要了</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/14ac540fae3bfde3bbaa6b7025ac4d365650fa7f/image4typora/202010/05/000501-970705.png"/><p>​    写在依赖里面是为了及时的更新，是makefile的特性，跟gcc和g++的命令无关。本身cc -E 里面就会处理头文件的事情，which means 头文件不需要我们手动去指定依赖，其实代码里面写的很清楚了，编译器是知道的，而且结果很明显，确实是知道的（详见阮一峰的博客：<span class="exturl" data-url="aHR0cDovL3d3dy5ydWFueWlmZW5nLmNvbS9ibG9nLzIwMTQvMTEvY29tcGlsZXIuaHRtbA==">编译器的工作过程<i class="fa fa-external-link-alt"></i></span>中的“第五步 预处理”的剖析）</p></li></ul><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input disabled="" type="checkbox">  静态链接和动态链接都是ld么</p><blockquote><p>目前我的理解是：</p><p>ld是静态链接器，动态链接器实际上是ld-linux.so（ 具体看机子</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      动态链接和静态链接
    
    </summary>
    
    
      <category term="Summary" scheme="https://hexi519.github.io/categories/Summary/"/>
    
    
      <category term="Compilation and Link" scheme="https://hexi519.github.io/tags/Compilation-and-Link/"/>
    
  </entry>
  
  <entry>
    <title>Summary of makefile</title>
    <link href="https://hexi519.github.io/2020/09/17/Summary/makeFileSummary/"/>
    <id>https://hexi519.github.io/2020/09/17/Summary/makeFileSummary/</id>
    <published>2020-09-17T17:18:59.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvaW50cm9kdWN0aW9uLmh0bWw=">陈皓：跟我一起写makefile<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="others-拓展"><a href="#others-拓展" class="headerlink" title="others[拓展]"></a>others[拓展]</h2><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9jb29sc2hlbGwuY24vYXJ0aWNsZXMvMzc5MC5odG1s">陈皓：如何调试MAKEFILE变量<i class="fa fa-external-link-alt"></i></span><ul><li>makefile中的origin函数 等等， 在这里又介绍了几个自带的函数</li><li>陈皓自己写了个用于debug的mk</li><li>make的f参数，指定特定名称的文件，多个参数一起用，会连接起来传递给程序一起执行</li><li>还附上了一个remake tool的教程，which tl;dr ，以后再说吧</li></ul></li></ul><h1 id="basis"><a href="#basis" class="headerlink" title="basis"></a>basis</h1><ul><li><p>Makefile里主要包含了五个东西：显式规则、隐晦规则(自动推导)、变量定义、文件指示(makefile里面包含别的makefile 以及 其他一些规则)和注释(#)</p></li><li><p>Makefile最灵魂的东西就是：</p></li><li><p>如果目标(<target>)不存在 <strong>或者</strong> prerequisites的日期新于目标，就执行相应的command</p></li><li><p>make的<strong>工作方式</strong></p>  <figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GNU的make工作时的执行步骤如下：（想来其它的make也是类似）</span><br><span class="line"><span class="number">1.</span> 读入所有的Makefile。</span><br><span class="line"><span class="number">2.</span> 读入被include的其它Makefile。</span><br><span class="line"><span class="number">3.</span> 初始化文件中的变量。</span><br><span class="line"><span class="number">4.</span> 推导隐晦规则，并分析所有规则。</span><br><span class="line"><span class="number">5.</span> 为所有的目标文件创建依赖关系链。</span><br><span class="line"><span class="number">6.</span> 根据依赖关系，决定哪些目标要重新生成。</span><br><span class="line"><span class="number">7.</span> 执行生成命令。</span><br></pre></td></tr></table></figure><ul><li>两个阶段<ul><li>lazy展开（有点python的意思</li></ul></li></ul></li></ul><h2 id="trivial-points"><a href="#trivial-points" class="headerlink" title="trivial points"></a>trivial points</h2><ul><li>.PHONY 伪目标<ul><li>clean命令放最后，因为最前的是默认的总目标</li><li><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvcnVsZXMuaHRtbA==">伪目标的巧用<i class="fa fa-external-link-alt"></i></span> –》 [ 单独一个make可以work的原理 ]</li></ul></li><li>命令前的小减号 , 出现错误只会弹警告，然后继续运行，不会退出  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-include &lt;filename&gt;   <span class="comment"># 找不到就不用找了</span></span><br><span class="line">-rm edit $(objects)   <span class="comment"># 删除失败就就继续执行吧</span></span><br></pre></td></tr></table></figure></li><li><strong>自动推导</strong> [隐晦规则]<br>  在生成xx.o的过程中可以省去gcc -c xx.c的命令</li><li><strong>另类风格</strong><br>  文件依赖关系会显得有点凌乱，但是会让makefile变得简单<br>  简而言之，就是一个xx.o可以在多行的左边出现</li><li>make -f / make –file 指定除了makefile 和Makefile以外的别的命名方式</li><li>寻找别的makefile的目录<ul><li>系统缺省的目录</li><li>-I / –include-dir 指定的目录</li><li>VPATH变量 &amp; 更灵活的vpath （in whose pattern我们应该用%而不是*的通配符），目录之间使用冒号(:)分隔</li><li>环境变量MAKEFILES<ul><li>不建议使用</li></ul></li></ul></li></ul><h2 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h2><ul><li>一般来说，make会以UNIX的标准Shell，也就是 /bin/sh 来执行命令。</li><li>命令要缩进(tab)</li></ul><h1 id="书写命令"><a href="#书写命令" class="headerlink" title="书写命令"></a>书写命令</h1><blockquote><p>每条规则中的命令和操作系统Shell的命令行是一致的。make会<strong>按顺序一条一条的执行命令会</strong>，每条命令的开头必须以 Tab 键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。</p></blockquote><ul><li><p>注意点！</p><ul><li>如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就<strong>不能把这两条命令写在两行上</strong>，而应该把这两条命令写在一行上，用分号分隔</li></ul></li><li><p>全局参数</p><ul><li>debug<ul><li>–just-print / -n</li><li>-s / –silent / –quiet</li></ul></li><li>-i / –ignore-errors<ul><li>.IGNORE为目标的规则 是另一种级别的防止命令出错的方式</li></ul></li><li>-k / –keep-going</li><li>-w / –print-directory<ul><li>-C 的时候自动打开-w</li><li>-s的时候-w总是失效的</li></ul></li></ul></li></ul><h2 id="嵌套执行make"><a href="#嵌套执行make" class="headerlink" title="嵌套执行make"></a>嵌套执行make</h2><ul><li>总控Makefile , subsystem</li><li>变量传递<ul><li>传递变量到下层用export<ul><li>后面什么都不跟，表示传递所有的变量</li></ul></li><li>SHELL 和 MAKEFLAGS 不管你是否export，其总是要传递到下层 Makefile中<ul><li>MAKEFLAGS如果是自己定义的，得确保其中的选项是大家都会用到的。如果其中有 -t , -n 和 -q 参数，容易出现让人意想不到的结果</li></ul></li><li>make命令中的有几个参数并不往下传递</li><li>不想往下层传递参数的话：<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">subsystem:</span></span><br><span class="line">cd subdir &amp;&amp; <span class="variable">$(MAKE)</span> MAKEFLAGS=</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="命令包"><a href="#命令包" class="headerlink" title="命令包"></a>命令包</h2><ul><li>调用的时候和调用变量一样的方式  </li></ul><h1 id="条件判断和函数"><a href="#条件判断和函数" class="headerlink" title="条件判断和函数"></a>条件判断和函数</h1><h2 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h2><ul><li><p>格式</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;conditional-directive&gt;</span><br><span class="line">&lt;text-if-true&gt;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&lt;text-if-false&gt;</span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure></li><li><p>命令</p><ul><li><p>ifeq &amp; ifneq</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ifeq</span> (&lt;arg1&gt;, &lt;arg2&gt;)</span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> <span class="string">&quot;&lt;arg2&gt;&quot;</span></span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> &#x27;&lt;arg2&gt;&#x27;</span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; <span class="string">&quot;&lt;arg2&gt;&quot;</span>        </span><br></pre></td></tr></table></figure></li><li><p>ifdef &amp; ifndef</p><ul><li>ifdef只是测试一个变量是否有值，其并不会把变量扩展到当前位置。*</li></ul></li></ul></li><li><p>注意点<br>  <strong>make是在读取Makefile时就计算条件表达式的值</strong>，并根据条件表达式的值来选择语句，所以，不要把自动化变量（如 $@ 等）放入条件表达式中，因为<strong>自动化变量是在运行时才有的</strong>。</p></li></ul><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$(&lt;function&gt; &lt;arguments&gt;)</span><br></pre></td></tr></table></figure><ul><li><p>$(subst <from>,<to>,<text>)</p></li><li><p>$(patsubst <pattern>,<replacement>,<text>)</p><ul><li>顾名思义，不是text上的substitution了，而是pattern上的substitution</li><li>和变量替换的作用一样<blockquote><p>$(objects:.o=.c) 和 $(patsubst %.o,%.c,$(objects)) 是一样的。</p></blockquote></li></ul></li><li><p>$(strip <string>)</p></li><li><p>$(findstring <find>,<in>)</p></li><li><p>$(filter &lt;pattern…&gt;,<text>)</p></li><li><p>$(filter-out &lt;pattern…&gt;,<text>)</p></li><li><p>$(sort <list>)</p></li><li><p>$(word <n>,<text>)</p></li><li><p>$(wildcard PATTERN…) </p><ul><li><strong>在Makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。这种情况下如果需要通配符有效，就需要使用函数“wildcard”</strong>。<blockquote><p>在Makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。需要注意的是：这种情况下规则中通配符的展开和上一小节匹配通配符的区别。</p></blockquote></li></ul></li><li><p>循环 $(foreach <var>,<list>,<text>)</p></li><li><p>判断 $(if <condition>,<then-part>)   /  $(if <condition>,<then-part>,<else-part>)</p></li><li><p>shell函数</p><blockquote><p>注意，这个函数会新生成一个Shell程序来执行命令，所以你要注意其运行性能，如果你的Makefile中有一些比较复杂的规则，并大量使用了这个函数，那么对于你的系统性能是有害的。特别是Makefile的隐晦的规则可能会让你的shell函数执行的次数比你想像的多得多。<br>… <span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvcnVsZXMuaHRtbA==">tl;dr<i class="fa fa-external-link-alt"></i></span></p></blockquote></li></ul><h1 id="书写规则"><a href="#书写规则" class="headerlink" title="书写规则"></a>书写规则</h1><ul><li>最重要的是 依赖关系 &amp; 生成目标的方法</li><li>通配符<ul><li>~ , * , ?</li><li>在目标和命令中都可以用</li></ul></li><li>多目标</li><li>静态模式语法  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;targets ...&gt; : &lt;target-pattern&gt; : &lt;prereq-patterns ...&gt;</span><br><span class="line">    &lt;commands&gt;</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><ul><li>e.g.  <target-pattern> like %.o , <prereq-pattern> like %.c</li><li>注意，这里<target-pattern> 和<prereq-pattern> 都是一个集合，所以后面的 $&lt; 表示第一个依赖文件，会<strong>依次</strong>取出这个集合里面的所有文件</li><li>example<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">objects = foo.o bar.o</span><br><span class="line"><span class="section">all: <span class="variable">$(objects)</span></span></span><br><span class="line"><span class="variable">$(objects)</span>: %.o: %.c</span><br><span class="line">    <span class="variable">$(CC)</span> -c <span class="variable">$(CFLAGS)</span> <span class="variable">$&lt;</span> -o <span class="variable">$@</span> </span><br></pre></td></tr></table></figure></li></ul></li><li>自动生换成依赖性  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cc -M xx.cc </span><br><span class="line">cc -MM xx.cc </span><br></pre></td></tr></table></figure><ul><li>与源代码解耦合的方法  <ul><li>.d文件包含.c文件的依赖</li><li>makefile配置生成.d文件，然后再包含这些.d文件</li></ul></li></ul></li></ul><h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><ul><li><p>命名规则</p><blockquote><p>传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。<br>可以是数字开头的</p></blockquote></li><li><p>调用</p><ul><li>${} 与 $() </li><li>也可以不加括号，但是加上比较安全</li></ul></li><li><p>定义 &amp; 赋值</p><ul><li><p>= </p><ul><li>右边可以是目前未定义变量</li><li>小心递归定义</li><li>避免在变量中使用函数,whcih 比较增大开</li></ul></li><li><p>:=</p><ul><li>只可以用前面定义好了的 ，所以比较安全</li></ul></li><li><p>#的用法：表示变量定义的中止</p><ul><li><p>正例</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nullstring :=</span><br><span class="line">space := <span class="variable">$(nullstring)</span> <span class="comment"># end of the line</span></span><br></pre></td></tr></table></figure><blockquote><p>nullstring是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。</p></blockquote></li><li><p>反例</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dir := /foo/bar    <span class="comment"># directory to put the frobs in</span></span><br></pre></td></tr></table></figure><blockquote><p>dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这样变量来指定别的目录——“$(dir)/file”那么就完蛋了。</p></blockquote></li><li><p>个人想法<br>  何必呢。直接回车换行，也不用#不是很好。不过也可能一方面是为了方便阅读，另一方面也是显式定义，防止不小心打了空格啥的没有看见</p></li><li><p>?=<br>  如果之前没定义过，就赋值，否则就omit</p></li></ul></li></ul></li></ul><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><h3 id="变量值替换"><a href="#变量值替换" class="headerlink" title="变量值替换"></a>变量值替换</h3><ul><li>$(var:a=b) 或 ${var:a=b}<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:.o=.c)</span><br></pre></td></tr></table></figure>另一种也能完成变量替换的级数就是 “静态模式”<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:%.o=%.c)</span><br></pre></td></tr></table></figure></li></ul><h3 id="变量值再当作变量"><a href="#变量值再当作变量" class="headerlink" title="变量值再当作变量"></a>变量值再当作变量</h3><ul><li><p>用法</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = y</span><br><span class="line">y = z</span><br><span class="line">a := $(<span class="variable">$(x)</span>)</span><br></pre></td></tr></table></figure><ul><li>这个知识点主要要明确的就是，是“x=y”，而不是“x=$(y)”,如果没有$,关于y的值不会自动解开来赋值给x的</li></ul></li><li><p>使用多个变量来组成一个变量的名字，然后再取其值</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">first_second = Hello</span><br><span class="line">a = first</span><br><span class="line">b = second</span><br><span class="line">all = $($a_$b)</span><br></pre></td></tr></table></figure><blockquote><p>这个例子中，如果 $(a1) 的值是“a”的话，那么， $(sources) 的值就是“a.c b.c c.c”；如果 $(a1) 的值是“1”，那么 $(sources) 的值是“1.c 2.c 3.c”。<br>所以配合条件句使用特别好</p></blockquote></li><li><p>也可以放在左值中</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(dir)</span>_sources := <span class="variable">$(<span class="built_in">wildcard</span> <span class="variable">$(dir)</span>/*.c)</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="多行变量"><a href="#多行变量" class="headerlink" title="多行变量"></a>多行变量</h3><ul><li><p>利用原理：因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以 Tab 键开头，那么make 就不会把其认为是命令。</p></li><li><p>格式</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">define</span> two-lines</span><br><span class="line">echo foo</span><br><span class="line">echo <span class="variable">$(bar)</span></span><br><span class="line"><span class="keyword">endef</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="overridd"><a href="#overridd" class="headerlink" title="overridd"></a>overridd</h3><p>如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 覆盖外部命令行的定义</span></span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; = &lt;value&gt;;</span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; := &lt;value&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 追加覆盖方式</span></span><br><span class="line"><span class="keyword">override</span> &lt;variable&gt;; += &lt;more text&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多行变量的覆盖</span></span><br><span class="line"><span class="keyword">override</span> <span class="keyword">define</span> foo</span><br><span class="line">bar</span><br><span class="line"><span class="keyword">endef</span></span><br></pre></td></tr></table></figure><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><ul><li>优先考虑文件中的，但是如果有make -e的参数，就优先考虑e(nvironment)的变量</li></ul><h2 id="目标变量-Target-specific-Variable"><a href="#目标变量-Target-specific-Variable" class="headerlink" title="目标变量 Target-specific Variable"></a>目标变量 Target-specific Variable</h2><ul><li><p>变量分类</p><ul><li>全局变量<br>  整个文件，我们都可以访问这些变量</li><li>自动化变量<br>  如 $&lt; 等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义</li><li>目标变量<br>  可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值</li></ul></li><li><p>这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">prog : CFLAGS = -g</span><br><span class="line">prog : prog.o foo.o bar.o</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.o foo.o bar.o</span><br><span class="line"></span><br><span class="line">prog.o : prog.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.c</span><br><span class="line"></span><br><span class="line">foo.o : foo.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> foo.c</span><br><span class="line"></span><br><span class="line">bar.o : bar.c</span><br><span class="line">    <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> bar.c</span><br></pre></td></tr></table></figure><p>在这个示例中，不管全局的 $(CFLAGS) 的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则）， $(CFLAGS) 的值都是 -g</p></li><li><p>语法</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;target ...&gt; : &lt;variable-assignment&gt;;</span><br><span class="line">&lt;target ...&gt; : overide &lt;variable-assignment&gt;</span><br></pre></td></tr></table></figure><p><variable-assignment>;可以是前面讲过的各种赋值表达式，如 = 、 := 、 += <code>或是</code>?= 。第二个语法是针对于make命令行带入的变量，或是系统环境变量。</p></li></ul><h2 id="模式变量-Pattern-specific-Variable"><a href="#模式变量-Pattern-specific-Variable" class="headerlink" title="模式变量 Pattern-specific Variable"></a>模式变量 Pattern-specific Variable</h2><ul><li>其实没有很懂 如何 定义到<strong>模式</strong>上，还要<span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvdmFyaWFibGVzLmh0bWw=">回来<i class="fa fa-external-link-alt"></i></span>再看下</li></ul><h2 id="自动化变量"><a href="#自动化变量" class="headerlink" title="自动化变量"></a>自动化变量</h2><h2 id="特殊变量"><a href="#特殊变量" class="headerlink" title="特殊变量"></a>特殊变量</h2><ul><li>${MAKELEVEL}</li><li>${MAKE}<ul><li>代替make命令本身，在递归调用子文件中的makefile的时候，不能出现make本身(否则会陷入无穷的递归)，应该使用${MAKE}</li><li><span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjIwNjEyOC9ob3ctdG8tY2FsbC1tYWtlZmlsZS1mcm9tLWFub3RoZXItbWFrZWZpbGU=">refer<i class="fa fa-external-link-alt"></i></span></li><li>经常和-C参数一起使用，代表进入一个目录后使用make命令<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    cd subdir &amp;&amp; <span class="variable">$(MAKE)</span> <span class="comment"># 注意，这两行命令不能分开写</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  与上面的作用是一致的</span></span><br><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C subdir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更进一步，我想要执行特定的命令(比如clean)</span></span><br><span class="line"><span class="section">subsystem:</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C subdir clean</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="关于各种赋值符号的小总结"><a href="#关于各种赋值符号的小总结" class="headerlink" title="关于各种赋值符号的小总结"></a>关于各种赋值符号的小总结</h2><ul><li>=</li><li>:=</li><li>?=</li><li>+=</li></ul><h1 id="隐含规则"><a href="#隐含规则" class="headerlink" title="隐含规则"></a>隐含规则</h1><h2 id="basis-1"><a href="#basis-1" class="headerlink" title="basis"></a>basis</h2><ul><li>如果没有写.o文件的生成规则，默认就会调用如下规则:把 .o 的目标的依赖文件置成 .c ，并使用C的编译命令 cc –c $(CFLAGS)  foo.c 来生成 foo.o 的目标</li><li>隐含规则可能优先于别的规则被使用，因为隐含规则也有分优先级</li><li>模式的隐含规则，只不过是规则中要有 % 罢了</li></ul><h2 id="自动化变量-1"><a href="#自动化变量-1" class="headerlink" title="自动化变量"></a>自动化变量</h2><ul><li><p>扩展时会一个个文件取出</p><ul><li><p>$@</p></li><li><p>$%</p></li><li><p>$&lt;</p></li><li><p>$*</p><blockquote><p>$* 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$* 就表示 f1。</p><p>这里陈皓的一起来写makefile里面写错了</p></blockquote></li></ul></li><li><p>返回文件列表</p><ul><li><p>$?<br>  <strong>比较有用</strong></p><blockquote><p>所有比目标新的依赖目标的集合。以空格分隔。</p></blockquote></li><li><p>$^</p><blockquote><p>所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。</p></blockquote></li><li><p>$+</p><blockquote><p>所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那么这个变量会去除重复的依赖目标，只保留一份。</p></blockquote></li></ul></li></ul><h2 id="本章节尾部tl-dr"><a href="#本章节尾部tl-dr" class="headerlink" title="本章节尾部tl;dr"></a><span class="exturl" data-url="aHR0cHM6Ly9zZWlzbWFuLmdpdGh1Yi5pby9ob3ctdG8td3JpdGUtbWFrZWZpbGUvaW1wbGljaXRfcnVsZXMuaHRtbCM=">本章节尾部<i class="fa fa-external-link-alt"></i></span>tl;dr</h2><h1 id="question"><a href="#question" class="headerlink" title="question"></a>question</h1><ul><li><p><input checked="" disabled="" type="checkbox">  手写makefile不是很麻烦？没有自动的么？like cmake</p><blockquote><p>autotools（常见的./configure文件就是autotools生成的）和 cmake （cmakelist） 都是用于自动生成makefile的</p></blockquote></li><li><p><input checked="" disabled="" type="checkbox">  := 和 = 的区别</p><blockquote><p>后者可以使用未定义(但是后文定义了的)变量，但是前者不可以（所以更安全）</p></blockquote></li><li><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vd2FycmVuLXdvbmcvcC8zOTc5MjcwLmh0bWw=">Makefile中*和%的区别<i class="fa fa-external-link-alt"></i></span></p></li><li><p><input checked="" disabled="" type="checkbox">  CPPFLAGS 和 CXXFLAGS 的区别</p><blockquote><p>前者是C预处理器的参数（PP代表preprocessing），后者是C++的语言编译器</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      makefile的总结和梳理
    
    </summary>
    
    
      <category term="Summary" scheme="https://hexi519.github.io/categories/Summary/"/>
    
    
      <category term="Compilation and Link" scheme="https://hexi519.github.io/tags/Compilation-and-Link/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic TCP Initial Windows and Congestion Control Schemes through Reinforcement Learning(JSAC&#39;19)</title>
    <link href="https://hexi519.github.io/2020/09/09/PaperReading/TCP-RL/"/>
    <id>https://hexi519.github.io/2020/09/09/PaperReading/TCP-RL/</id>
    <published>2020-09-09T12:00:00.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul><li>不需要<strong>客户端</strong>或者中间件做任何改动 [ 惊了 ]</li></ul><blockquote><p>为了解决挑战一，TCP-RL 修改了前端服务器的 Linux 内核代码和 Web Server 应用 Nginx的代码，使得服务器能够测量并且实时输出每条用户请求的 TCP 流信息(比如网络传输延迟、丢包率、RTT 等)。整个过程在服务器端完 成，不需要客户端或者中间件做任何改动。该数据采集和测量的工具不仅仅可以用于初始窗口的调整，也可用于 Web 服务的网络性能指标管理、监控、 故障诊断。</p></blockquote><ul><li>对于问题的建模做的很好，而且作为了一个challenge</li></ul><p>hesy:The long flow switch like this, the cold start process should not be ignored–”Use SmartIW</p><h1 id="inspiration-of-hesy"><a href="#inspiration-of-hesy" class="headerlink" title="inspiration of hesy"></a>inspiration of hesy</h1><ul><li><p>要会用这个词: <strong>data-driven</strong> 代替 ML-based 或者RL-based。高大上！</p></li><li><p>contribution绝对不能写自己是首先用DRL做这个的，因为还有些水会也是做这个的，所以我们也要credit他们并且讲清楚区别。</p></li><li><p>写作的时候要注意层次感，不能一上来就说这个feature适合用RL做，应该先给出一个也比较适合但是naive的solution，再说RL可以解决这个naive的defects</p></li><li><p>目标函数或者奖励函数的形式  需要找人背书，不能自己造一个</p><ul><li>目标函数没有想好要不要让清空队列，因为延迟梯度也能包含这个目标。（或许可以做一个实验来证明这两个的相关性，看下Timely怎么做ECN和延迟的相关性的，记得这两个并不是很大程度上的相关鸭）</li></ul></li><li><p>实验细节要好好看下</p></li></ul>]]></content>
    
    <summary type="html">
    
      RL+CC
    
    </summary>
    
    
      <category term="PaperReading" scheme="https://hexi519.github.io/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
      <category term="Congestion Control" scheme="https://hexi519.github.io/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>Research on Transport Control and Flow Scheduling in Low-latency Datacenter Networks</title>
    <link href="https://hexi519.github.io/2020/08/08/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/"/>
    <id>https://hexi519.github.io/2020/08/08/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/</id>
    <published>2020-08-08T21:39:43.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="第一章-引言"><a href="#第一章-引言" class="headerlink" title="第一章 引言"></a>第一章 引言</h1><ul><li>数据中心应用类型</li><li>数据中心流量特性</li><li>仍存在的问题</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/08/214444-685710.png" alt="image-20200808214442717"></p><p>说实话感觉这里讲的不是很清楚，回头再来仔细梳理下把。</p><h1 id="第二章-背景和相关综述"><a href="#第二章-背景和相关综述" class="headerlink" title="第二章 背景和相关综述"></a>第二章 背景和相关综述</h1><ul><li>传统TCP及研究进展<ul><li>调整AIMD参数 –》good idea ==但是还是那个问题，为什么要搞pacing，而放弃窗口==</li><li>==incast 难道是数据中心特有的问题?== 其实只要BDP足够小就可以把？RTT不够小，但是我bandwidth够小总可以吧？TCP incast不就是拥塞么?<ul><li>我感觉只要是低延迟链路，就会有这种情况 （一旦有超时发生， 网络中会出现长时间的链路闲置状态）</li><li>如果要在数据中心做，得考虑放弃短流的调度，只调度长流？看看iroko怎么做的？</li></ul></li><li>DCTCP是解决TCP incast的？？</li></ul></li></ul><ul><li><p>TCP incast</p><ul><li><p>以前的解决方案</p><blockquote><p>第一类的主要方法是修改TCP配置参数，将RTO设置为微秒级 别，从而减小超时重传所需的等待时间; 第二类为修改TCP的拥塞控制算法，提高 缓存利用率，进而避免丢包；第三类是通过修改QCN算法来提高协议公平性；第 四类摒弃 TCP 方案采用 UDP 方案彻底避免超时重传的问题。</p></blockquote></li></ul></li><li><p>多种流量共存</p><ul><li><p>长流(重视高吞吐) &amp; 短流(重视低延迟) –》 目标不同</p></li><li><p>相互作用：长流容易造成短流的饥饿</p></li><li><p>还有部分应用存在截止时间需求 ，whose 主要性能指标是截止时间错过率</p></li><li><p>应对措施</p><blockquote><p>非截止时间流调度机制和传输协议研究，截止时间流调度机制 和传输协议研究和混合流调度机制和传输协议研</p></blockquote></li></ul></li><li><p>任务调度</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/09/154827-641523.png" alt="image-20200809154826511"></p><h1 id="第三章-支持选择性反馈的编码传输协议研究研究"><a href="#第三章-支持选择性反馈的编码传输协议研究研究" class="headerlink" title="第三章 支持选择性反馈的编码传输协议研究研究"></a>第三章 支持选择性反馈的编码传输协议研究研究</h1><ul><li>关于发送速率，on friendliness ，需要做的是：找论文背书，基于别人的公式进行建模</li></ul><h1 id="第四章-数据中心网络的混合流调度机制SMF"><a href="#第四章-数据中心网络的混合流调度机制SMF" class="headerlink" title="第四章 数据中心网络的混合流调度机制SMF"></a>第四章 数据中心网络的混合流调度机制SMF</h1><blockquote><p>这一部分讲的比较详细</p></blockquote><h2 id="miscelleneous"><a href="#miscelleneous" class="headerlink" title="miscelleneous"></a>miscelleneous</h2><ul><li>如何判断截止时间流还有非截止时间流本身也是个很大的问题啊！</li><li>传统解决方案中，基于速率的控制协议（RCP）到底是什么呢？Karuna采用的MCP又是什么呢?</li></ul><h2 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h2><ul><li><p>SMF</p><ul><li>对于非截止事件流，采用SJF</li><li>对于截止事件流，采用MLFQ</li><li>是满足多重目标的分布式拥塞控制协议，旨在调度混合流以改善流完成率和流完成时间</li><li>也对初始窗口大小做了改进，where也很重要。裴丹的，实际上是根据具体的业务进行改进了的。看看SMF采取了哪些feature，怎么做的，或许也是一个点？</li></ul></li><li><p>NP-hard问题证明</p><ul><li>截止时间流</li><li>非截止时间流（ 感觉讲得也很粗糙</li><li>所以使用启发式</li></ul></li><li><p>对于不能在截止时间前完成的流，<strong>“早丢弃”</strong>方式提前丢弃以节省网络带宽</p><ul><li>==自己的机制里面如果太简单，也可以加一些“早丢弃”等手工的规则==</li></ul></li><li><p>考察指标</p></li></ul><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200809171054378.png" alt="image-20200809171054378" style="zoom: 80%;" /><h1 id="第五章-任务级别的截止时间感知流调度机制研究TAPS"><a href="#第五章-任务级别的截止时间感知流调度机制研究TAPS" class="headerlink" title="第五章 任务级别的截止时间感知流调度机制研究TAPS"></a>第五章 任务级别的截止时间感知流调度机制研究TAPS</h1><h2 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h2><ul><li><p>如果某任务没有在截止事件前完成，那么该任务已经成功传输完成的所有数据都是无用数据。非常不幸的是，数据中心网络中采用的大部分传输协议，都是基于竞争的传输协议，如 TCP，RCP[35]，ICTCP[10]，DCTCP[2]，采用平均分配带宽的原则为网络中互相竞争的每条流分配链路以及可用带宽。这些方案固然可以有效将数据流从源端传输到目的端，但是他们忽略了数据流或是任务的截止时间，同时也没有意识到不同流之间的区别，无法做到最小化网络流完成时间。</p></li><li><p>统计数据表明，对于 web 应用，每个任务至少包括 88 条流[2]，对于 MapReduce 搜索工作每个任务包含 30 到 50000 条流[6]，对于 Cosmos 每个任务约包含 30 到 70 条流[97]。这些统计数据表明在数据中心内，很多应用对于每个任务会产生相应的多条数据流来完成，因此任务才是处理的单位。</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>使用SDN</p>]]></content>
    
    <summary type="html">
    
      data center TCP congestion control ， 做了三方面的工作
    
    </summary>
    
    
      <category term="PaperReading" scheme="https://hexi519.github.io/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Congestion Control" scheme="https://hexi519.github.io/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>python总结</title>
    <link href="https://hexi519.github.io/2020/08/08/Summary/python/"/>
    <id>https://hexi519.github.io/2020/08/08/Summary/python/</id>
    <published>2020-08-08T17:35:17.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="深浅拷贝"><a href="#深浅拷贝" class="headerlink" title="深浅拷贝"></a>深浅拷贝</h1><ul><li>说千道万，不如<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWNjNDExaDdoZD9mcm9tPXNlYXJjaCZzZWlkPTE3OTE4NDE2ODkwNDkxMDIzMzY=">画图实在<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbG9sZWluYS9wLzUyNzY5MTguaHRtbA==">函数传参，传的是引用<i class="fa fa-external-link-alt"></i></span><blockquote><p>Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个<strong>可变对象（比如字典或者列表）</strong>的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个<strong>不可变对象（比如int、str或者tuple</strong>）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。 </p><blockquote><p> 注意，tuple本身不可变，但是tuple里面的元素可变</p></blockquote></blockquote></li></ul><h1 id="闭包-amp-nonlocal"><a href="#闭包-amp-nonlocal" class="headerlink" title="闭包 &amp; nonlocal"></a>闭包 &amp; nonlocal</h1><ul><li><a href="nonlocal">nonlocal</a></li><li><span class="exturl" data-url="aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAwNDQ2MTQwNA==">闭包<i class="fa fa-external-link-alt"></i></span><ul><li>其中几个作用：节省开销，将函数与某个参数绑定</li><li>装饰器就是一种闭包</li></ul></li></ul><h1 id="subprocess"><a href="#subprocess" class="headerlink" title="subprocess"></a>subprocess</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E0NjQwNTcyMTYvYXJ0aWNsZS9kZXRhaWxzLzQ3MzU1MjE5">这个<i class="fa fa-external-link-alt"></i></span></p><h1 id="joyful-pandas"><a href="#joyful-pandas" class="headerlink" title="joyful pandas"></a>joyful pandas</h1><blockquote><p>pandas的一些少见的注意事项，具体代码和例子来源于datawhale的<span class="exturl" data-url="aHR0cHM6Ly9uYnZpZXdlci5qdXB5dGVyLm9yZy9naXRodWIvR1lISEFIQS9Kb3lmdWwtUGFuZGFzL3RyZWUvbWFzdGVyLw==">Joyful-Pandas系列<i class="fa fa-external-link-alt"></i></span></p></blockquote><h3 id="1-基础"><a href="#1-基础" class="headerlink" title="1.基础"></a>1.基础</h3><ul><li>df.value_count()</li><li>df.unique()</li><li>df.nunique()</li><li>df.describe()的一些用法<ul><li>可以自行选择分位数 df.describe(percentiles=[.05, .25, .75, .95])</li><li>非数值型也可以用describe函数</li></ul></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/26/112845-885917.png" alt="image-20200826112844748"></p><ul><li>还有一些练习题，也可以做下</li></ul><h3 id="2-索引"><a href="#2-索引" class="headerlink" title="2. 索引"></a>2. 索引</h3><ul><li><p>函数式索引 &amp; 布尔索引</p></li><li><p><strong>loc</strong>可以接收整数或整数列表或布尔列表以及Series，而<strong>iloc</strong>中接收的参数只能为整数或整数列表或布尔列表，不能使用布尔Series，如果要用就必须使用.values()把dataframe里面的列表拿出来</p></li><li><p>索引不要用浮点数，否则在切片索引的时候，[2: ]就表示的不是索引的下标从第二个开始了，而是用比大小的方式去看哪些行的索引值比2大，都拿出来</p></li><li><p>[]的索引方式中，比较灵活。有几种方式：</p><ul><li><p>索引index：</p><ol><li><p>data[3:5] 数字的话，就是索引行的绝对位置，就算index也是数字，也不要混淆啊！</p><ul><li><p>这个和data.iloc[3:5]效果是一样的(Series和DataFrame都适用)</p><blockquote><p>tip: loc和iloc其实都是二维的，如果只写了一个维度，就是指的index</p></blockquote></li><li><p>对于Series来说，这个和data[data.index[3:5]]效果是一样的（但是DataFrame就会报错的）</p></li></ul></li><li><p>如果index也是数字，想要索引对应于某个数值的index怎么办？(比如索引index为33的那一行)<br> data[data.index.get_loc(33)]</p></li></ol></li><li><p>索引column：<br>  如果index是str类型，data[“label”]默认也是索引column（最标准的写法还是loc[:,”label”]）</p><blockquote><p>注意，我个人测试的时候loc对于Series也是不会报错的，但是我还是不建议。因为容易混肴，Series没必要用loc，具体的含义我也搞不清楚</p></blockquote></li></ul></li><li><p>[快速标量索引]:当只需要取一个元素时，at和iat方法能够提供更快的实现</p><blockquote><p>看到区间索引，其实目前觉得差不多了。没必要再学更多了</p></blockquote></li></ul><h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><blockquote><p>所有高级的api，包括seaborns在内，都是基于最基本的matplotlib开始的，那么一定都得先搞清matplotlib的基本概念（ax和fig等）</p></blockquote><img src="https://img-blog.csdnimg.cn/20200311202147484.png" alt="在这里插入图片描述" style="zoom:67%;" /><ul><li>每一次subplot动作都是独立的</li></ul><blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure(num=<span class="string">&#x27;panel&#x27;</span>, figsize=(<span class="number">8</span>,<span class="number">4</span>),facecolor=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制两个不同大小的区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>) <span class="comment"># 划分1行3列，第1个子区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>) <span class="comment"># 划分1行2列，第2个子区域</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>其实把每一次 <code>subplot</code> 动作看作是独立的就行了，第一次将整个画板划分为1行3列完全不影响第二次划分为1行2列，它们仅影响当前划分后子图的大小。</p><img src="https://img-blog.csdnimg.cn/20190930150818814.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxMzQ3ODY5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;" /></blockquote><ul><li><p>添加子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######## 使用figure + addsubplot ########</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">221</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">222</span>)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">212</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">######## 使用figure + subplot ########</span></span><br><span class="line">fig = plt.figure(num=<span class="string">&#x27;panel&#x27;</span>, figsize=(<span class="number">8</span>,<span class="number">4</span>),facecolor=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment"># 划分三个小区域，绘制出第一个和第三个区域</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)  <span class="comment"># 划分1行3列，第1个子区域  </span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)  <span class="comment"># 划分1行3列，第3个子区域</span></span><br><span class="line">plt.show()</span><br><span class="line">true<span class="comment"># 注意，这里是plt.subplot而不是fig.add_subplot，which让我感到奇怪，但是先记住吧</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">######## 使用subplots,which是最常用的 ########</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">6</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot data</span></span><br><span class="line">axes[<span class="number">0</span>].plot(A,B)</span><br><span class="line">axes[<span class="number">1</span>].scatter(A,C)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>用 <code>subplots</code> 创建一个画板，同时也创建了一个绘图子区域 <code>axes</code>。画板赋值给了 <code>fig</code>，绘画子区域赋值给了 <code>ax</code>。这样一来，所有 <code>fig.***</code> 都是对整个画板进行操作，所有 <code>ax.***</code> 都是对这个 Aexs 子区域进行操作。</p></blockquote></li><li><p><strong>fig.xx 如果用于处理ax内部的属性，比如轴的刻度范围之类的，其实都是对ax.xx的api的封装</strong>，所以掌握ax.xx才是王道 和 最正确的方式</p></li></ul>]]></content>
    
    <summary type="html">
    
      关于python的总结
    
    </summary>
    
    
      <category term="Summary" scheme="https://hexi519.github.io/categories/Summary/"/>
    
    
      <category term="Language" scheme="https://hexi519.github.io/tags/Language/"/>
    
  </entry>
  
  <entry>
    <title>Network常识记录</title>
    <link href="https://hexi519.github.io/2020/08/07/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/"/>
    <id>https://hexi519.github.io/2020/08/07/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/</id>
    <published>2020-08-07T22:35:17.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="一些默认设置"><a href="#一些默认设置" class="headerlink" title="一些默认设置"></a>一些默认设置</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc3ByaW50Lm5ldC9zbGFfcGVyZm9ybWFuY2UucGhwP25ldHdvcms9c2w=">Sprint.net中统计的网络性能参数<i class="fa fa-external-link-alt"></i></span> </li><li>rtt普通情况下也就0.1s【CUBIC论文中写的】(数据中心中就是微秒级别)<ul><li>BBR论文中表示，由于buffer是BDP的几个数量级，所以rtt从毫秒级别变成了秒级</li></ul></li><li>DC中的带宽应该是10Gbps</li></ul><h1 id="How-can-we-be-aware-of-congestion"><a href="#How-can-we-be-aware-of-congestion" class="headerlink" title="How can we be aware of congestion"></a>How can we be aware of congestion</h1><ul><li><p>the internet is a <strong><code>decentralized</code></strong> system, and as a result of that, doesn’t have any central coordinator telling senders to slow down if link queues downstream of some sender are filling up.</p></li><li><p>There are two main indicators: <strong><code>packet loss</code></strong> and increased  <strong><code>round trip times</code></strong>  for packets. </p><ul><li><p>If a sender notices packet loss, it’s a pretty good indicator that congestion is occuring. </p></li><li><p>Another consequence of queues filling up though is that if packets are spending more time in a queue before making it onto the link, the round trip time, which measures the time from when the sender sends a segment out to the time that it receives an acknowledgement, will increase.</p><blockquote><p>summary：可以通过 <strong>packet loss</strong> 和 <strong>RTT</strong> 这两个现象来观察是否有congestion</p></blockquote></li></ul></li></ul><h1 id="概念解释-辨析"><a href="#概念解释-辨析" class="headerlink" title="概念解释/辨析"></a>概念解释/辨析</h1><h2 id="sending-rate-amp-delivery-rate"><a href="#sending-rate-amp-delivery-rate" class="headerlink" title="sending rate &amp; delivery rate"></a>sending rate &amp; delivery rate</h2><ul><li>sending rate就是发送速率</li><li>delivery rate强调接收方收到的包的速率（你发出去但是人家不一定能收到不是</li></ul><h2 id="pacing"><a href="#pacing" class="headerlink" title="pacing"></a>pacing</h2><ul><li>TCP的流控机制，基本上是有两种的，专业一点的说法分别叫做pure rate control和windows-based这两种<ul><li>pure rate control <ul><li>告诉你sender一个发送速率(bottleneck bandwidth)，sender的发送速率不超过这个确定值。</li></ul></li><li>window-based control<ul><li>这个就是常见的TCP 滑动窗口的协议，就是有一个ack确认后我才能发送下面的。</li></ul></li><li>pacing结合了这两种<ul><li>uses the tcp window to determine how much to send but uses rates instead of acknowledgments to determine when to send.</li><li>为什么要这样，因为标准TCP的发包是back-to-back的,TCP的这种clumped方式会引发高延迟以及burst traffic下的丢包大大增加，同时还有ACK Compression，Multiplexing等各种问题都会导致性能受损，所以有人突出了一个机制，我们能不能不让包堆在一起发，在一个窗口里流出间隔，那我们的排队队长就会下降的。</li><li>pacing可以看作TCP的一个变体，是结合了上面的两个流控方式，他使用tcp window决定发多少,用bottleneck bandwidth决定什么时候发，它定义了一个发包的间隔</li></ul></li><li>paing需要优化嘛？需要。 更多的可以看这个<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMDc0MTA3Mw==">专栏<i class="fa fa-external-link-alt"></i></span>搜集的paper  </li></ul></li></ul><h2 id="ACK-compression"><a href="#ACK-compression" class="headerlink" title="ACK compression"></a>ACK compression</h2><ul><li>由于中间链路的缓存以及和其他TCP连接一起共享缓存等原因，可能会导致ACK报文成堆到达发送端。这种场景我们就称呼为ACK压缩。</li><li>i.e. 一个TCP发送者的 自计时取决于到来的，由接收机按照相同时间间隔生成的ACK。如果这些的ACK通过网络过境期间存在一些开销在队列中，但是，它们的间隔可能会改变。当ACK的到达间距小于它们发送的间距，发送者可能会被误导，发送比网络可以接受的更多的数据，这可能导致堵塞和效率损失。</li><li>于ACK compression场景，reno拥塞控制就是逐个处理每个ACK报文，这样就会导致拥塞窗口突然增大，发送端突然发出大量的TCP报文，这种突然发出大量数据的行为我们称呼为burst，影响网络平稳。另外一方面ACK compression还会影响RTT估计，之前我们介绍过有些拥塞控制算法基于时延来来估计网络拥塞情况，因此 ACK compresion还会影响这类基于时延的拥塞控制算法的性能。</li></ul><h2 id="数据平面-amp-控制平面"><a href="#数据平面-amp-控制平面" class="headerlink" title="数据平面&amp;控制平面"></a>数据平面&amp;控制平面</h2><p>除了控制平面(Control Plane)和数据平面(Data Plane)还有管理平面(Management Plane)。数据平面又叫转发平面(Forwarding Plane),通过查看收到流量的目的地址，按照转发表(forwarding table)来处理流量的去向。可能转发流量去一个出接口，可能丢弃流量，或者送去控制平面做进一步处理。控制平面维持数据平面操作所需的必要信息。 这些信息通过协议和算法，收集和计算得来。网络节点间的控制平面能相互交换信息。这些信息被处理之后用于建立不同的表来帮助数据平面的流量操作。除了EIGRP, OSPF, BGP，PIM, HSRP等3层协议以外，CDP,UDLD,LACP,ARP,STP,VLAN等2层协议都属于控制平面。管理平面就是处理配置和监控控制平面。比如CLI, SNMP,XML, Wireshark,NetFlow,SPAN,API,JSON，NETCONF等等都属于管理平面。   </p><h2 id="latency-V-S-delay"><a href="#latency-V-S-delay" class="headerlink" title="latency V.S. delay"></a>latency V.S. delay</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzU5MzgwNjc0">refer<i class="fa fa-external-link-alt"></i></span></p><ul><li><p><strong>latency</strong></p><p>指的是一个报文进入一台设备以致这台设备所经历的实践。实际上考验的是报文在这台设备上<strong>消耗的时间</strong>。时间越短，这台设备的性能越高。</p></li><li><p><strong>delay</strong></p><p>是指一个操作和另个一个操作之间<strong>停顿的时间</strong>。</p></li></ul><p>所以，latency是不可避免的正常开销，然而delay是额外的开销。</p><h1 id="做CC实验要注意的点"><a href="#做CC实验要注意的点" class="headerlink" title="做CC实验要注意的点"></a>做CC实验要注意的点</h1><ul><li>不仅要测拥塞程度是否改进了</li><li>还要测量收敛速度和fairness to existing congestion control protocols</li></ul><h1 id="数据中心的CC"><a href="#数据中心的CC" class="headerlink" title="数据中心的CC"></a>数据中心的CC</h1><h2 id="learn-from-Lili-Liu’s-paper"><a href="#learn-from-Lili-Liu’s-paper" class="headerlink" title="learn from Lili Liu’s paper"></a>learn from Lili Liu’s paper</h2><ul><li><p>一般<strong>低延迟应用</strong>的流<strong>的 SLA</strong> (Service Level Agreement)要求是 300ms 内完成</p></li><li><p><strong>研究TCP</strong>（而不是一些基于UDP协议）<strong>的重要性</strong> （ 请注意，quic只是实现的一个途径–》用户态 ）</p><ul><li><p>数据中心要求可靠性，目前实现数据中心间的可靠传输的唯一途径是TCP</p><blockquote><p>数据中心间的链路是由 ISP 提供带宽和时延保障的专用链路，但由于路由切换及一 些突发事件，这种专用链路上偶尔也会发生丢包 </p></blockquote><p>根据 ISP 与服务商的SLA，<strong>丢包率一般在 0.5% 到 5% 之间，时延一般不超过 20ms</strong>。</p></li><li><p>研究结果表明数据中心网络中99%的流量都是TCP流量[2]</p><blockquote><p>参考文献[2]是一个2010年的文章</p></blockquote></li><li><p>然而，数据中心网络的传输协议大多数都采用TCP，<strong>并使用平均分配带宽为原则</strong>，将网络资源平均分配。如此做的方案主要有**<u>TCP、RCP[35]、DCTCP和HULL[18]等</u>**</p></li></ul></li><li><p>诸多研究表明<strong>TCP RTO是导致TCP Incast</strong> 的主要原因</p><ul><li>在 TCP 中，默认超时重传计时器 $RTO_min$ 为 200ms，数据中心网络正常 RTT 通常为 200µs</li></ul></li><li><p>数据中心网络传输协议近年来<strong>主要面临的问题</strong>有：</p><ul><li>TCP Incast 问题</li><li>低延迟、高吞吐性能需求</li><li>多任务模式等（对于FCT有要求）</li></ul></li><li><p>最近发表的一个研究([3])表明，网络中由于低效的链路带宽利用率，平均<strong>有 7.25% 的数据流未能在截止时间前完成</strong>。</p></li><li><p>TCP的设计采用平<strong>均分配带宽原则</strong></p></li><li><p><strong>截止时间流和非截止时间流</strong></p><ul><li>尽管数据中心网络中<strong>有截止时间流</strong>所占比率很低，大概是所有流量的 5%。</li><li><strong>非截止时间流</strong>的应用彼此不同。有些应用像 VM 迁移或者数据备份等，在传输开始前就可以得知该流的大小，然而对于一些像数据库存取和 HTTP 分块传输的应用，这些应用在他们传输开始之前不知道流大小或者截止时间相关信息。<ul><li>因此，对于非截止时间流，较短的流完成时间和较高的吞吐率是他们的<strong>主要性能指标</strong>。</li></ul></li></ul></li></ul><h1 id="HULL"><a href="#HULL" class="headerlink" title="HULL"></a>HULL</h1><ul><li>high-performance ultra-low latency</li><li>他从三个层次来进行了设计：<ul><li>Phantom queues: Detecting and signaling congestion<ul><li>这个机制是一种为了创建剩余buffer提出的一种机制，也就是我们常说的bandwidth headroom，通过减少长流带宽来获取更高的短流效率，在端口使用仿真的虚拟队列基于链路利用率而不是利用队列的占有率来设计ECN标记。</li></ul></li><li>DCTCP: Adaptive reaction to ECN</li><li>Packet pacing<ul><li>这个在前面的文章里面也讲了Pacing的实现原理，但是我们也分析过Pacing其实不一定会带来特别好的效果，是有一定条件的，所以这篇文章用了一个硬件pacer，感觉很厉害。但是本质还是按照固定间隔发送封包。</li></ul></li></ul></li></ul><h1 id="some-resources（博客资源-and-so-on）"><a href="#some-resources（博客资源-and-so-on）" class="headerlink" title="some resources（博客资源 and so on）"></a>some resources（博客资源 and so on）</h1><p><span class="exturl" data-url="aHR0cHM6Ly9zcXVpZGFydGguY29tL3JjL3Byb2dyYW1taW5nL25ldHdvcmtpbmcvMjAxOC8wNy8xOC9pbnRyby1jb25nZXN0aW9uLmh0bWw=">squidarth:intro congestion-control<i class="fa fa-external-link-alt"></i></span></p>]]></content>
    
    <summary type="html">
    
      关于拥塞控制的常识/resources
    
    </summary>
    
    
      <category term="Summary" scheme="https://hexi519.github.io/categories/Summary/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>建站 | Jekyll -》 mkdocs -》 hexo</title>
    <link href="https://hexi519.github.io/2020/07/30/siteBuilding/"/>
    <id>https://hexi519.github.io/2020/07/30/siteBuilding/</id>
    <published>2020-07-30T21:50:53.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Jekyll"><a href="#Jekyll" class="headerlink" title="Jekyll"></a>Jekyll</h1><p>之前是用的jekyll，但是没找到我想要的全局搜索功能，有兴趣的还是可以看下：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA0MTg0NzIw">Jekyll建站<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="mkdocs"><a href="#mkdocs" class="headerlink" title="mkdocs"></a>mkdocs</h1><blockquote><p>其实Jekyll已经省去了很多麻烦了，但是我真的真的很烦每个md开头要写一大段乱七八糟的配置，不方便迁移，所以就转到mkdocs了，虽然模板的页面效果没有Jekyll丰富，但是对懒人还是极其友好的。</p></blockquote><blockquote><p>本来想用mkdocs的，毕竟还是挺省事儿的，文件结构也很清晰，学神点拨下我发现hexo可以全局搜索，跟mkdocs的标题搜索等级比起来，更香了！<br>简单学了下，后续可能考虑用mkdocs做一些项目文档手册，作为子网址吧，做手册挺合适的。</p></blockquote><h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cueG5jb2RpbmcuY29tLzIwMjAvMDMvMDEvdG9vbC9ta2RvY3MuaHRtbA==">蛮详细的，尤其是关于yml配置文件相关的<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d1dG9uZ3RyZWUuZ2l0aHViLmlvL2Rldm9wcy9tYW5hZ2UteW91ci1jbXMtdXNpbmctbWtkb2Nz">配置也很详细，尤其有一些关于mkdocs的冷知识<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC9menhpYW9tYW5nZS9ibG9nLzMwMTA5MjE=">列了一些注意事项，which我也觉得很重要<i class="fa fa-external-link-alt"></i></span></li><li>这个没仔细看，但是感觉很高贵的样子 <span class="exturl" data-url="aHR0cHM6Ly90b3V0aWFvLmlvL3Bvc3RzL3Q5M2E1Yy9wcmV2aWV3">将 Jupyter 自动发布到 GitHub Pages<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="配置中遇到的问题"><a href="#配置中遇到的问题" class="headerlink" title="配置中遇到的问题"></a>配置中遇到的问题</h2><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0b25lOTE1OS9hcnRpY2xlL2RldGFpbHMvNzkwNzEzMTY=">py37下字符编码遇到的问题<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h1><blockquote><p>我的两个config.xml（_config.next.xml是对应next主题的配置）都做了比较详细的注释，大家改起来也会很方便，欢迎在我的基础上修改！（虽然我本来也就是改学神的 :)</p></blockquote><h2 id="ref-1"><a href="#ref-1" class="headerlink" title="ref"></a>ref</h2><ol><li><p>环境配置请参考：<span class="exturl" data-url="aHR0cHM6Ly9scnNjeS5naXRodWIuaW8vMjAxNy8xMS8xMC9VYnVudHUtR2l0aHViLWlvLWNvbmZpZy1IZXhvLw==">linux下使用hexo建站<i class="fa fa-external-link-alt"></i></span>    </p><blockquote><ul><li>安装的时候提示8.x已经deprecated，所以我按照提示安装了12.x</li><li>在服务器上跑<code>npm install -g hexo-cli</code>等命令的时候，会遇到权限不够，根据提示给sudo就行</li></ul></blockquote></li><li><p>推送过程和基本配置网上已经很多了</p><blockquote><ul><li>next主题的仓库已经过期，我用的是学神给的这个：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0">https://github.com/theme-next/hexo-theme-next<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly90ZGluZy50b3AvYXJjaGl2ZXMvNDJjMzhiMTAuaHRtbA==">next主题的基本设置<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85NDAzODY4OA==">hexo主题进阶设置<i class="fa fa-external-link-alt"></i></span></li></ul></blockquote></li><li><p>其他trivial的可选功能</p><blockquote><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9kNjhkZTA2N2VhNzQ=">Hexo添加Disqus评论<i class="fa fa-external-link-alt"></i></span></li><li>hexo添加google-analytic功能 （ 不想做了2333累了</li></ul></blockquote></li></ol><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><p>hexo new ‘文章标题’<br>hexo new draft<br> hexo clean</p><blockquote><p>清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。</p></blockquote><p>hexo g<br>hexo s<br>hexo d</p><hr><h1 id="mkdown-图床-获取-永久链接-（-香"><a href="#mkdown-图床-获取-永久链接-（-香" class="headerlink" title="mkdown+图床 获取 永久链接 （ 香"></a>mkdown+图床 获取 永久链接 （ 香</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA3NjIyMjAy">我之前写的文章：typora+gitee图床<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h1><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC81YzQxN2RhNzUxODgyNTI1YzYzODA5Y2Q=">简单入个门<i class="fa fa-external-link-alt"></i></span></li><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC82ODU0NTczMjE4Nzc5MzgxNzcz">hexo+Actions保姆教程<i class="fa fa-external-link-alt"></i></span></li></ul><p>本来想自己写的，结果学神也用的actions，哈哈作业一抄到底 （ docker确实不太精通啊…  - -||| ）</p><hr><h1 id="miscelleous"><a href="#miscelleous" class="headerlink" title="miscelleous"></a>miscelleous</h1><ul><li><input disabled="" type="checkbox"> 添加多个部署源<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">deploy</span>:</span><br><span class="line">- <span class="attribute">type</span>: git</span><br><span class="line">  <span class="attribute">repo</span>:</span><br><span class="line">- <span class="attribute">type</span>: heroku</span><br><span class="line">  <span class="attribute">repo</span>:</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      github pages建站
    
    </summary>
    
    
      <category term="程序员的自我修养" scheme="https://hexi519.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/"/>
    
    
      <category term="tool" scheme="https://hexi519.github.io/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>DeePCCI(SIGCOMM&#39;19)</title>
    <link href="https://hexi519.github.io/2020/02/05/PaperReading/DeePCCI(SIGCOMM&#39;19)/"/>
    <id>https://hexi519.github.io/2020/02/05/PaperReading/DeePCCI(SIGCOMM&#39;19)/</id>
    <published>2020-02-05T12:00:00.000Z</published>
    <updated>2020-10-27T09:06:45.689Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><blockquote><p>拥塞控制（CC）[12]是当今传输协议的基本组成部分，并强烈影响数据传输的性能。 CC最初建于1980年代以应对早期Internet的拥塞崩溃[17]，但CC仍在发展，并且出现了新的变体，例如BBR [1]或Vivace [3]。</p></blockquote><blockquote><p>CC引入了一个拥塞窗口（cwnd），该窗口限制了飞行中未确认字节的数量。==每种CC算法都定义了在特定算法定义的拥塞信号下，cwnd的变化情况==。给定CC方法的数量及其对性能的影响[9]，因此研究CC的使用方法很重要。例如，如果知道新的CC通常会与哪些其他算法竞争，则为公平起见，更容易对其进行调整。</p></blockquote><h2 id="传统的缺点"><a href="#传统的缺点" class="headerlink" title="传统的缺点"></a>传统的缺点</h2><blockquote><ul><li>但是，用于识别CC变体的现有工作（例如[2、18、24]）不适用于最新的CC和传输协议。==扩展和维护这些方法很复杂，因为它需要详细的领域知识才能知道CC参数化和配置如何影响其行为。== 当CC离开内核并引入用户空间协议（例如QUIC [11]）时，这一点变得尤为重要，这些协议相当容易更改，并且已经可以大规模部署[21]。</li></ul></blockquote><blockquote><ul><li>==此外，许多识别方法都基于fragile assumptions。== 例如，当使用TCP pacing （例如，与RENO [12]或CUBIC [5]结合使用）时，它们将失败。</li><li>*令人担忧的是，我们已知的所有被动方法都基于头部信息is parsable的的假设**。完全加密的传输（例如QUIC实施方案）使这些设计无效，并且如果可能的话，将需要进行重大更改。</li></ul></blockquote><p><strong>因此，目前就推理部署CC提出挑战。</strong></p><h2 id="难点与贡献"><a href="#难点与贡献" class="headerlink" title="难点与贡献"></a>难点与贡献</h2><p>作为应对这些挑战的第一步，本文介绍了DeePCCI，这是一种基于监督的基于深度学习的被动拥塞控制识别方法。<br>==它仅根据流数据包到达时间信息识别CC变体，因此甚至可以在加密的传输头上使用。==<br>此外，它使用深度学习来学习功能-从而避免了手动的，特定于领域的功能设计。<br>因此，与相关方法不同，==DeePCCI除了流分组定时的可用性之外，不做任何假设，== <strong>除了能够收集CC变体的训练流量之外，不需要任何领域知识。</strong><br>我们认为，这种假设和免手动调整方法允许在Internet流量中进行通用且可扩展的CC标识。具体来说，我们介绍DeePCCI的设计，评估及其局限性，并做出以下贡献：</p><p>•我们描述了流量的预处理和用于识别拥塞控制变量的深度学习模型。<br>•我们介绍了如何在测试平台上生成带有标记数据的多种拥塞控制变量模型。</p><p>我们评估了CUBIC，RENO和BBR作为主要拥塞控制变量的测试平台的性能。我们展示了该方法能够在各种情况下识别流量拥塞控制变量，但同时也介绍并讨论了无法识别拥塞控制变量的情况。结构体。第2节讨论了CC识别的最新技术及其缺点。第3节介绍DeePCCI的设计，而第4节介绍我们如何生成训练数据和评估我们的方法。最后，第5节总结了论文并讨论了未来的工作。</p><h1 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h1><blockquote><p>各种工作涉及识别CC变体。这些方法主要分为两类：使用被动[2、6、13、18、20]或主动[19、24]测量的识别方法。</p></blockquote><blockquote><p>主动方法可通过主动打开并操纵CC来激发CC反应进行检测。 Padhye和Floyd提出了TBIT [19]，该协议将精心制作的TCP段发送到Web服务器以主动触发拥塞控制。它记录响应丢失的数据包发送了哪些段，因为这种反应在TBIT中所区分的CC变体之间有很大差异。<br><br><br>杨等。目前的CAAI [24]扩展了TBIT的方法。为了估计发送方的cwnd，CAAI人为地延迟了观察所有飞行段的ACK。然后，CAAI导致数据包丢失，并从变化的cwnd中提取特征。这些功能随后用于使用随机森林进行分类。虽然这两种方法都可以实现较高的识别精度，但是由于错误选择的主机，因此依靠主动测量很容易引入测量偏差。<br><br><br>被动方法（与我们一样）不与主机交互，而是依靠流量跟踪来推断使用的流量CC变体，因此，它们允许收集有关实际流量的信息，该信息取决于有利位置而不是主动选择的主机。<br><br><br>Paxson等。和Jaiswal等。使用tcpanaly [20]和tcpflows [13]重建TCP状态机，以比较接收到的数据包和预期数据包。两种方法都需要非常详细的CC甚至实施知识来重建状态机。我们的方法的不同之处在于它不需要详细的CC知识。卡萨格兰德等。 [2]将cwnd中的特征更改用作其方法TCPMoon中的特征。针对这些功能检查了不同的手工规则，以区分CC。对于cwnd估计，作者使用基于TCP时间戳的RTT估计。因此，使用TCPMoon无法识别没有TCP时间戳选项或加密了传输头的流。由于我们的方法仅观察数据包到达的行为，因此不需要任何明文传输协议字段。<br><br><br>Oshio等。 [18]提出了一种基于聚类的方法。他们根据RTT估计值提取cwnd的特征并将其聚类以区分两个竞争的CC变体。我们的方法的不同之处在于，它不仅限于两个相互竞争的变体。哈戈斯等。<br><br><br>[6]使用发送方和接收方之间的未完成字节作为粗略且嘈杂的cwnd估计。使用递归神经网络对该估计值进行细化。精简后的Cwnd的突然减少用作CUBIC，BIC和RENO之间不同的乘法减少因子的估计。尽管此方法使用深度学习是相似的，但它仍然需要手动设计的乘数递减因子，因此只能识别基于损失的CC。我们的方法使用端到端深度学习模型，还识别基于延迟的CC并避免使用手动功能。</p></blockquote><h2 id="active-measurements"><a href="#active-measurements" class="headerlink" title="active measurements"></a>active measurements</h2><ul><li>制造丢包现象（ 通过延迟ack的发送或者是发送crafted packets to senders ）获得终端的变化情况<ul><li>获取了特征数据以后使用随机森林的方法</li></ul></li></ul><h2 id="passive-measurements"><a href="#passive-measurements" class="headerlink" title="passive measurements"></a>passive measurements</h2><ul><li>gather information on real traffic on vantage points ，而不是像active measurements那样观测主动选好的hosts</li><li>rebuild TCP  state machine –》 需要detailed CC domain knowledge and implementation knowledge</li><li>建模去估计Cwnd changes –》 like 使用TCP的时间戳来估计RTT （ 加密了以后就不适用了</li></ul><p><br><br><br></p><h1 id="DeePCCI-design"><a href="#DeePCCI-design" class="headerlink" title="DeePCCI design"></a>DeePCCI design</h1><h2 id="CC-Manifestaion-in-Traffic"><a href="#CC-Manifestaion-in-Traffic" class="headerlink" title="CC Manifestaion in Traffic"></a>CC Manifestaion in Traffic</h2><ul><li>only use <strong>arrival time</strong> of a flow as input<ul><li>unlike Netflow 是什么意思 ？ Netflow没有packet timing嘛</li><li>目的 :associate packets to flow</li></ul></li></ul><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://images.weserv.nl/?url=https://img-blog.csdnimg.cn/20190924094304705.png" alt="在这里插入图片描述"></p><h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><ul><li>用于特征提取</li><li>改进了VGG net  结合了 residual network</li></ul><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>如果packet的size是固定的，就用VGGNet就够了 ，但是由于我们想看的是length-variant的packet，所以使用LSTM–》有记忆<ul><li>用的是unidirectional network     </li></ul></li></ul><p><br><br><br></p><h1 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h1><h2 id="Mininet-based-Network-Testbed"><a href="#Mininet-based-Network-Testbed" class="headerlink" title="Mininet-based Network Testbed"></a>Mininet-based Network Testbed</h2><ul><li>不同的网络环境<ul><li>TCP sender number</li><li>link latency</li><li>bottleneck link’s BDP</li></ul></li><li>选择了三个variant进行对比 ( RENO, CUBIC ,BBR ) <ul><li>每个发送60s 的fully-loaded TCP stream </li><li>观测者比发送者早2s开启     </li></ul></li></ul><h2 id="Single-Host-Network"><a href="#Single-Host-Network" class="headerlink" title="Single-Host Network"></a>Single-Host Network</h2><ul><li><strong>baseline condition</strong></li><li>哑铃状拓扑</li><li>没有背景流量</li></ul><h2 id="Multi-Host-Network"><a href="#Multi-Host-Network" class="headerlink" title="Multi-Host Network"></a>Multi-Host Network</h2><ul><li>reside on each side of the network</li></ul><h2 id="Cross-Traffic-Network"><a href="#Cross-Traffic-Network" class="headerlink" title="Cross-Traffic Network"></a>Cross-Traffic Network</h2><ul><li>side flow</li><li>main flow</li></ul><h2 id="performance"><a href="#performance" class="headerlink" title="performance"></a>performance</h2><h3 id="identifacation-by-Delay-and-Bandwidth"><a href="#identifacation-by-Delay-and-Bandwidth" class="headerlink" title="identifacation by Delay and Bandwidth"></a>identifacation by Delay and Bandwidth</h3><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>带宽越大、延迟越大、host越多越容易识别成功</li></ul><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><ul><li><p>带宽越大越成功是因为</p><ul><li>归因于拥塞窗口的整数离散化，而最大cwnd取决于瓶颈带宽。 ( 我的理解就是：允许的cc窗口的区别度高 ）</li><li>以较大的带宽采样了诸如CUBIC的cubic行为的更多步骤。 较低的带宽意味着较少的采样步骤，并且三次行为很难与例如RENO的线性行为相区别。</li></ul></li><li><p>认为延迟越大越成功</p><ul><li>与histogram的bin-size  有关<blockquote><p>我个人在这里的理解就是： bin-size 就有点像分辨率 如果延迟太小，会导致整个图被横向压扁；如果延迟大一点，整个图就会舒展开，一些特征啥的会更加清晰，容易被CNN识别、提取到<br>有点意思 :)</p></blockquote></li></ul></li><li><p>认为多主机效果更好是因为</p><ul><li>对于相同的延迟，多主机情况也能获得更好的结果。我们将此影响归因于流量竞争。当link饱和时，单主机流的速率不会随着cwnd的增加而迅速增加，<strong>但是在多主机方案中增加流的cwnd可以增加其在队列中的数据包的份额，从而增加其速率。</strong> <strong>因此，对不同拥塞控制变量的cwnd的单独更改会对速率产生更大的影响，从而更强烈地影响数据包到达</strong>，并在更长的时间内影响较小的延迟和带宽问题。</li></ul></li></ul><p><strong>【感觉这一点实际上是利用了这三种方案面对竞争时候的特性有所区别的特点，并不是说：Competing的时候会有种让CC增加cwnd的动力(只有发的多才能收的快 收的快才能滑动)  ，而应该说：面对 competing的时候有不同的特性，有的人会趋于让cwnd增大，所以对应的包发得多，到达的间隔就短了】</strong></p><blockquote><p>如我们所见，<strong>带宽和延迟会影响我们的方法</strong>，延迟/带宽过小会导致识别性能降低。<strong>为了进一步评估，我们将以50Mbps作为带宽</strong>继续进行实验，以更好地了解该方法在何处面临挑战。 </p></blockquote>]]></content>
    
    <summary type="html">
    
      RL+CC
    
    </summary>
    
    
      <category term="PaperReading" scheme="https://hexi519.github.io/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="https://hexi519.github.io/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="https://hexi519.github.io/tags/Reinforcement-Learning/"/>
    
      <category term="Congestion Control" scheme="https://hexi519.github.io/tags/Congestion-Control/"/>
    
  </entry>
  
</feed>
