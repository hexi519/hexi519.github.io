<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hesy&#39;s Blog</title>
  
  <subtitle>Seek for your love</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-12T14:08:51.098Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Hesy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/12/PaperReading/TCP-RL/"/>
    <id>http://yoursite.com/2020/09/12/PaperReading/TCP-RL/</id>
    <published>2020-09-12T14:08:51.098Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul><li>不需要<strong>客户端</strong>或者中间件做任何改动 [ 惊了 ]</li></ul><blockquote><p>为了解决挑战一，TCP-RL 修改了前端服务器的 Linux 内核代码和 Web Server 应用 Nginx的代码，使得服务器能够测量并且实时输出每条用户请求的 TCP 流信息(比如网络传输延迟、丢包率、RTT 等)。整个过程在服务器端完 成，不需要客户端或者中间件做任何改动。该数据采集和测量的工具不仅仅可以用于初始窗口的调整，也可用于 Web 服务的网络性能指标管理、监控、 故障诊断。</p></blockquote><ul><li>对于问题的建模做的很好，而且作为了一个challenge</li></ul><ul><li>我觉得slides里面这个图做的很好</li></ul><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200810092501270.png" alt="image-20200810092501270"></p><p>hesy:The long flow switch like this, the cold start process should not be ignored–”Use SmartIW</p><h1 id="inspiration-of-hesy"><a href="#inspiration-of-hesy" class="headerlink" title="inspiration of hesy"></a>inspiration of hesy</h1><ul><li><p>要会用这个词: <strong>data-driven</strong> 代替 ML-based 或者RL-based。高大上！</p></li><li><p>contribution绝对不能写自己是首先用DRL做这个的，因为还有些水会也是做这个的，所以我们也要credit他们并且讲清楚区别。</p></li><li><p>写作的时候要注意层次感，不能一上来就说这个feature适合用RL做，应该先给出一个也比较适合但是naive的solution，再说RL可以解决这个naive的defects</p></li><li><p>目标函数或者奖励函数的形式  需要找人背书，不能自己造一个</p><ul><li>目标函数没有想好要不要让清空队列，因为延迟梯度也能包含这个目标。（或许可以做一个实验来证明这两个的相关性，看下Timely怎么做ECN和延迟的相关性的，记得这两个并不是很大程度上的相关鸭）</li></ul></li><li><p>实验细节要好好看下</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;ul&gt;
&lt;li&gt;不需要&lt;strong&gt;客户端&lt;/strong&gt;或者中间件做任何改
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>DeePCCI(SIGCOMM&#39;19)</title>
    <link href="http://yoursite.com/2020/08/09/PaperReading/IOT/"/>
    <id>http://yoursite.com/2020/08/09/PaperReading/IOT/</id>
    <published>2020-08-09T12:00:00.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css">]]></content>
    
    <summary type="html">
    
      RL+CC
    
    </summary>
    
    
      <category term="PaperReading" scheme="http://yoursite.com/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
      <category term="Congestion Control" scheme="http://yoursite.com/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>Research on Transport Control and Flow Scheduling in Low-latency Datacenter Networks</title>
    <link href="http://yoursite.com/2020/08/08/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/"/>
    <id>http://yoursite.com/2020/08/08/PaperReading/Research-on-Transport-Control-and-Flow-Scheduling-in-Low-latency-Datacenter-Networks/</id>
    <published>2020-08-08T21:39:43.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="第一章-引言"><a href="#第一章-引言" class="headerlink" title="第一章 引言"></a>第一章 引言</h1><ul><li>数据中心应用类型</li><li>数据中心流量特性</li><li>仍存在的问题</li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/08/214444-685710.png" alt="image-20200808214442717"></p><p>说实话感觉这里讲的不是很清楚，回头再来仔细梳理下把。</p><h1 id="第二章-背景和相关综述"><a href="#第二章-背景和相关综述" class="headerlink" title="第二章 背景和相关综述"></a>第二章 背景和相关综述</h1><ul><li>传统TCP及研究进展<ul><li>调整AIMD参数 –》good idea ==但是还是那个问题，为什么要搞pacing，而放弃窗口==</li><li>==incast 难道是数据中心特有的问题?== 其实只要BDP足够小就可以把？RTT不够小，但是我bandwidth够小总可以吧？TCP incast不就是拥塞么?<ul><li>我感觉只要是低延迟链路，就会有这种情况 （一旦有超时发生， 网络中会出现长时间的链路闲置状态）</li><li>如果要在数据中心做，得考虑放弃短流的调度，只调度长流？看看iroko怎么做的？</li></ul></li><li>DCTCP是解决TCP incast的？？</li></ul></li></ul><ul><li><p>TCP incast</p><ul><li><p>以前的解决方案</p><blockquote><p>第一类的主要方法是修改TCP配置参数，将RTO设置为微秒级 别，从而减小超时重传所需的等待时间; 第二类为修改TCP的拥塞控制算法，提高 缓存利用率，进而避免丢包；第三类是通过修改QCN算法来提高协议公平性；第 四类摒弃 TCP 方案采用 UDP 方案彻底避免超时重传的问题。</p></blockquote></li></ul></li><li><p>多种流量共存</p><ul><li><p>长流(重视高吞吐) &amp; 短流(重视低延迟) –》 目标不同</p></li><li><p>相互作用：长流容易造成短流的饥饿</p></li><li><p>还有部分应用存在截止时间需求 ，whose 主要性能指标是截止时间错过率</p></li><li><p>应对措施</p><blockquote><p>非截止时间流调度机制和传输协议研究，截止时间流调度机制 和传输协议研究和混合流调度机制和传输协议研</p></blockquote></li></ul></li><li><p>任务调度</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/09/154827-641523.png" alt="image-20200809154826511"></p><h1 id="第三章-支持选择性反馈的编码传输协议研究研究"><a href="#第三章-支持选择性反馈的编码传输协议研究研究" class="headerlink" title="第三章 支持选择性反馈的编码传输协议研究研究"></a>第三章 支持选择性反馈的编码传输协议研究研究</h1><ul><li>关于发送速率，on friendliness ，需要做的是：找论文背书，基于别人的公式进行建模</li></ul><h1 id="第四章-数据中心网络的混合流调度机制SMF"><a href="#第四章-数据中心网络的混合流调度机制SMF" class="headerlink" title="第四章 数据中心网络的混合流调度机制SMF"></a>第四章 数据中心网络的混合流调度机制SMF</h1><blockquote><p>这一部分讲的比较详细</p></blockquote><h2 id="miscelleneous"><a href="#miscelleneous" class="headerlink" title="miscelleneous"></a>miscelleneous</h2><ul><li>如何判断截止时间流还有非截止时间流本身也是个很大的问题啊！</li><li>传统解决方案中，基于速率的控制协议（RCP）到底是什么呢？Karuna采用的MCP又是什么呢?</li></ul><h2 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h2><ul><li><p>SMF</p><ul><li>对于非截止事件流，采用SJF</li><li>对于截止事件流，采用MLFQ</li><li>是满足多重目标的分布式拥塞控制协议，旨在调度混合流以改善流完成率和流完成时间</li><li>也对初始窗口大小做了改进，where也很重要。裴丹的，实际上是根据具体的业务进行改进了的。看看SMF采取了哪些feature，怎么做的，或许也是一个点？</li></ul></li><li><p>NP-hard问题证明</p><ul><li>截止时间流</li><li>非截止时间流（ 感觉讲得也很粗糙</li><li>所以使用启发式</li></ul></li><li><p>对于不能在截止时间前完成的流，<strong>“早丢弃”</strong>方式提前丢弃以节省网络带宽</p><ul><li>==自己的机制里面如果太简单，也可以加一些“早丢弃”等手工的规则==</li></ul></li><li><p>考察指标</p></li></ul><img src="C:\Users\hesy\AppData\Roaming\Typora\typora-user-images\image-20200809171054378.png" alt="image-20200809171054378" style="zoom: 80%;" /><h1 id="第五章-任务级别的截止时间感知流调度机制研究TAPS"><a href="#第五章-任务级别的截止时间感知流调度机制研究TAPS" class="headerlink" title="第五章 任务级别的截止时间感知流调度机制研究TAPS"></a>第五章 任务级别的截止时间感知流调度机制研究TAPS</h1><h2 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h2><ul><li><p>如果某任务没有在截止事件前完成，那么该任务已经成功传输完成的所有数据都是无用数据。非常不幸的是，数据中心网络中采用的大部分传输协议，都是基于竞争的传输协议，如 TCP，RCP[35]，ICTCP[10]，DCTCP[2]，采用平均分配带宽的原则为网络中互相竞争的每条流分配链路以及可用带宽。这些方案固然可以有效将数据流从源端传输到目的端，但是他们忽略了数据流或是任务的截止时间，同时也没有意识到不同流之间的区别，无法做到最小化网络流完成时间。</p></li><li><p>统计数据表明，对于 web 应用，每个任务至少包括 88 条流[2]，对于 MapReduce 搜索工作每个任务包含 30 到 50000 条流[6]，对于 Cosmos 每个任务约包含 30 到 70 条流[97]。这些统计数据表明在数据中心内，很多应用对于每个任务会产生相应的多条数据流来完成，因此任务才是处理的单位。</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>使用SDN</p>]]></content>
    
    <summary type="html">
    
      data center TCP congestion control ， 做了三方面的工作
    
    </summary>
    
    
      <category term="PaperReading" scheme="http://yoursite.com/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
      <category term="Congestion Control" scheme="http://yoursite.com/tags/Congestion-Control/"/>
    
  </entry>
  
  <entry>
    <title>python总结</title>
    <link href="http://yoursite.com/2020/08/08/Summary/python/"/>
    <id>http://yoursite.com/2020/08/08/Summary/python/</id>
    <published>2020-08-08T17:35:17.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="深浅拷贝"><a href="#深浅拷贝" class="headerlink" title="深浅拷贝"></a>深浅拷贝</h1><ul><li>说千道万，不如<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWNjNDExaDdoZD9mcm9tPXNlYXJjaCZzZWlkPTE3OTE4NDE2ODkwNDkxMDIzMzY=">画图实在<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbG9sZWluYS9wLzUyNzY5MTguaHRtbA==">函数传参，传的是引用<i class="fa fa-external-link-alt"></i></span><blockquote><p>Python参数传递采用的肯定是“传对象引用”的方式。这种方式相当于传值和传引用的一种综合。如果函数收到的是一个<strong>可变对象（比如字典或者列表）</strong>的引用，就能修改对象的原始值－－相当于通过“传引用”来传递对象。如果函数收到的是一个<strong>不可变对象（比如int、str或者tuple</strong>）的引用，就不能直接修改原始对象－－相当于通过“传值’来传递对象。 </p><blockquote><p> 注意，tuple本身不可变，但是tuple里面的元素可变</p></blockquote></blockquote></li></ul><h1 id="闭包-amp-nonlocal"><a href="#闭包-amp-nonlocal" class="headerlink" title="闭包 &amp; nonlocal"></a>闭包 &amp; nonlocal</h1><ul><li><a href="nonlocal">nonlocal</a></li><li><span class="exturl" data-url="aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAwNDQ2MTQwNA==">闭包<i class="fa fa-external-link-alt"></i></span><ul><li>其中几个作用：节省开销，将函数与某个参数绑定</li><li>装饰器就是一种闭包</li></ul></li></ul><h1 id="subprocess"><a href="#subprocess" class="headerlink" title="subprocess"></a>subprocess</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E0NjQwNTcyMTYvYXJ0aWNsZS9kZXRhaWxzLzQ3MzU1MjE5">这个<i class="fa fa-external-link-alt"></i></span></p><h1 id="joyful-pandas"><a href="#joyful-pandas" class="headerlink" title="joyful pandas"></a>joyful pandas</h1><blockquote><p>pandas的一些少见的注意事项，具体代码和例子来源于datawhale的<span class="exturl" data-url="aHR0cHM6Ly9uYnZpZXdlci5qdXB5dGVyLm9yZy9naXRodWIvR1lISEFIQS9Kb3lmdWwtUGFuZGFzL3RyZWUvbWFzdGVyLw==">Joyful-Pandas系列<i class="fa fa-external-link-alt"></i></span></p></blockquote><h3 id="1-基础"><a href="#1-基础" class="headerlink" title="1.基础"></a>1.基础</h3><ul><li>df.value_count()</li><li>df.unique()</li><li>df.nunique()</li><li>df.describe()的一些用法<ul><li>可以自行选择分位数 df.describe(percentiles=[.05, .25, .75, .95])</li><li>非数值型也可以用describe函数</li></ul></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202008/26/112845-885917.png" alt="image-20200826112844748"></p><ul><li>还有一些练习题，也可以做下</li></ul><h3 id="2-索引"><a href="#2-索引" class="headerlink" title="2. 索引"></a>2. 索引</h3><ul><li><p>函数式索引 &amp; 布尔索引</p></li><li><p><strong>loc</strong>可以接收整数或整数列表或布尔列表以及Series，而<strong>iloc</strong>中接收的参数只能为整数或整数列表或布尔列表，不能使用布尔Series，如果要用就必须使用.values()把dataframe里面的列表拿出来</p></li><li><p>索引不要用浮点数，否则在切片索引的时候，[2: ]就表示的不是索引的下标从第二个开始了，而是用比大小的方式去看哪些行的索引值比2大，都拿出来</p></li><li><p>[]的索引方式中，比较灵活。有几种方式：</p><ul><li>索引index：<ol><li>data[3:5] 数字的话，就是索引行的绝对位置，就算index也是数字，也不要混淆啊！<ul><li>这个和data.iloc[3:5]效果是一样的(Series和DataFrame都适用)<blockquote><p>tip: loc和iloc其实都是二维的，如果只写了一个维度，就是指的index</p></blockquote></li><li>对于Series来说，这个和data[data.index[3:5]]效果是一样的（但是DataFrame就会报错的）</li></ul></li><li>如果index也是数字，想要索引对应于某个数值的index怎么办？(比如索引index为33的那一行)<br> data[data.index.get_loc(33)]</li></ol></li><li>索引column：<br>  如果index是str类型，data[“label”]默认也是索引column（最标准的写法还是loc[:,”label”]）<blockquote><p>注意，我个人测试的时候loc对于Series也是不会报错的，但是我还是不建议。因为容易混肴，Series没必要用loc，具体的含义我也搞不清楚</p></blockquote></li></ul></li><li><p>[快速标量索引]:当只需要取一个元素时，at和iat方法能够提供更快的实现</p><blockquote><p>看到区间索引，其实目前觉得差不多了。没必要再学更多了</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      关于python的总结
    
    </summary>
    
    
      <category term="Summary" scheme="http://yoursite.com/categories/Summary/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>CC常识记录</title>
    <link href="http://yoursite.com/2020/08/07/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2020/08/07/Summary/CC%E5%B8%B8%E8%AF%86%E8%AE%B0%E5%BD%95/</id>
    <published>2020-08-07T22:35:17.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="一些默认设置"><a href="#一些默认设置" class="headerlink" title="一些默认设置"></a>一些默认设置</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc3ByaW50Lm5ldC9zbGFfcGVyZm9ybWFuY2UucGhwP25ldHdvcms9c2w=">Sprint.net中统计的网络性能参数<i class="fa fa-external-link-alt"></i></span> </li><li>rtt普通情况下也就0.1s【CUBIC论文中写的】<ul><li>BBR论文中表示，由于buffer是BDP的几个数量级，所以rtt从毫秒级别变成了秒级</li></ul></li></ul><h1 id="How-can-we-be-aware-of-congestion"><a href="#How-can-we-be-aware-of-congestion" class="headerlink" title="How can we be aware of congestion"></a>How can we be aware of congestion</h1><ul><li><p>the internet is a <strong><code>decentralized</code></strong> system, and as a result of that, doesn’t have any central coordinator telling senders to slow down if link queues downstream of some sender are filling up.</p></li><li><p>There are two main indicators: <strong><code>packet loss</code></strong> and increased  <strong><code>round trip times</code></strong>  for packets. </p><ul><li><p>If a sender notices packet loss, it’s a pretty good indicator that congestion is occuring. </p></li><li><p>Another consequence of queues filling up though is that if packets are spending more time in a queue before making it onto the link, the round trip time, which measures the time from when the sender sends a segment out to the time that it receives an acknowledgement, will increase.</p><blockquote><p>summary：可以通过 <strong>packet loss</strong> 和 <strong>RTT</strong> 这两个现象来观察是否有congestion</p></blockquote></li></ul></li></ul><h1 id="概念解释-辨析"><a href="#概念解释-辨析" class="headerlink" title="概念解释/辨析"></a>概念解释/辨析</h1><h2 id="sending-rate-amp-delivery-rate"><a href="#sending-rate-amp-delivery-rate" class="headerlink" title="sending rate &amp; delivery rate"></a>sending rate &amp; delivery rate</h2><ul><li>sending rate就是发送速率</li><li>delivery rate强调接收方收到的包的速率（你发出去但是人家不一定能收到不是</li></ul><h2 id="pacing"><a href="#pacing" class="headerlink" title="pacing"></a>pacing</h2><ul><li>TCP的流控机制，基本上是有两种的，专业一点的说法分别叫做pure rate control和windows-based这两种<ul><li>pure rate control <ul><li>告诉你sender一个发送速率(bottleneck bandwidth)，sender的发送速率不超过这个确定值。</li></ul></li><li>window-based control<ul><li>这个就是常见的TCP 滑动窗口的协议，就是有一个ack确认后我才能发送下面的。</li></ul></li><li>pacing结合了这两种<ul><li>uses the tcp window to determine how much to send but uses rates instead of acknowledgments to determine when to send.</li><li>为什么要这样，因为标准TCP的发包是back-to-back的,TCP的这种clumped方式会引发高延迟以及burst traffic下的丢包大大增加，同时还有ACK Compression，Multiplexing等各种问题都会导致性能受损，所以有人突出了一个机制，我们能不能不让包堆在一起发，在一个窗口里流出间隔，那我们的排队队长就会下降的。</li><li>pacing可以看作TCP的一个变体，是结合了上面的两个流控方式，他使用tcp window决定发多少,用bottleneck bandwidth决定什么时候发，它定义了一个发包的间隔</li></ul></li><li>paing需要优化嘛？需要。 更多的可以看这个<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMDc0MTA3Mw==">专栏<i class="fa fa-external-link-alt"></i></span>搜集的paper  </li></ul></li></ul><h2 id="ACK-compression"><a href="#ACK-compression" class="headerlink" title="ACK compression"></a>ACK compression</h2><ul><li>由于中间链路的缓存以及和其他TCP连接一起共享缓存等原因，可能会导致ACK报文成堆到达发送端。这种场景我们就称呼为ACK压缩。</li><li>i.e. 一个TCP发送者的 自计时取决于到来的，由接收机按照相同时间间隔生成的ACK。如果这些的ACK通过网络过境期间存在一些开销在队列中，但是，它们的间隔可能会改变。当ACK的到达间距小于它们发送的间距，发送者可能会被误导，发送比网络可以接受的更多的数据，这可能导致堵塞和效率损失。</li><li>于ACK compression场景，reno拥塞控制就是逐个处理每个ACK报文，这样就会导致拥塞窗口突然增大，发送端突然发出大量的TCP报文，这种突然发出大量数据的行为我们称呼为burst，影响网络平稳。另外一方面ACK compression还会影响RTT估计，之前我们介绍过有些拥塞控制算法基于时延来来估计网络拥塞情况，因此 ACK compresion还会影响这类基于时延的拥塞控制算法的性能。</li></ul><h2 id="数据平面-amp-控制平面"><a href="#数据平面-amp-控制平面" class="headerlink" title="数据平面&amp;控制平面"></a>数据平面&amp;控制平面</h2><p>除了控制平面(Control Plane)和数据平面(Data Plane)还有管理平面(Management Plane)。数据平面又叫转发平面(Forwarding Plane),通过查看收到流量的目的地址，按照转发表(forwarding table)来处理流量的去向。可能转发流量去一个出接口，可能丢弃流量，或者送去控制平面做进一步处理。控制平面维持数据平面操作所需的必要信息。 这些信息通过协议和算法，收集和计算得来。网络节点间的控制平面能相互交换信息。这些信息被处理之后用于建立不同的表来帮助数据平面的流量操作。除了EIGRP, OSPF, BGP，PIM, HSRP等3层协议以外，CDP,UDLD,LACP,ARP,STP,VLAN等2层协议都属于控制平面。管理平面就是处理配置和监控控制平面。比如CLI, SNMP,XML, Wireshark,NetFlow,SPAN,API,JSON，NETCONF等等都属于管理平面。   </p><h1 id="做CC实验要注意的点"><a href="#做CC实验要注意的点" class="headerlink" title="做CC实验要注意的点"></a>做CC实验要注意的点</h1><ul><li>不仅要测拥塞程度是否改进了</li><li>还要测量收敛速度和fairness to existing congestion control protocols</li></ul><h1 id="数据中心的CC"><a href="#数据中心的CC" class="headerlink" title="数据中心的CC"></a>数据中心的CC</h1><h2 id="learn-from-Lili-Liu’s-paper"><a href="#learn-from-Lili-Liu’s-paper" class="headerlink" title="learn from Lili Liu’s paper"></a>learn from Lili Liu’s paper</h2><ul><li><p>一般<strong>低延迟应用</strong>的流<strong>的 SLA</strong> (Service Level Agreement)要求是 300ms 内完成</p></li><li><p><strong>研究TCP</strong>（而不是一些基于UDP协议）<strong>的重要性</strong> （ 请注意，quic只是实现的一个途径–》用户态 ）</p><ul><li><p>数据中心要求可靠性，目前实现数据中心间的可靠传输的唯一途径是TCP</p><blockquote><p>数据中心间的链路是由 ISP 提供带宽和时延保障的专用链路，但由于路由切换及一 些突发事件，这种专用链路上偶尔也会发生丢包 </p></blockquote><p>根据 ISP 与服务商的SLA，<strong>丢包率一般在 0.5% 到 5% 之间，时延一般不超过 20ms</strong>。</p></li><li><p>研究结果表明数据中心网络中99%的流量都是TCP流量[2]</p><blockquote><p>参考文献[2]是一个2010年的文章</p></blockquote></li><li><p>然而，数据中心网络的传输协议大多数都采用TCP，<strong>并使用平均分配带宽为原则</strong>，将网络资源平均分配。如此做的方案主要有**<u>TCP、RCP[35]、DCTCP和HULL[18]等</u>**</p></li></ul></li><li><p>诸多研究表明<strong>TCP RTO是导致TCP Incast</strong> 的主要原因</p><ul><li>在 TCP 中，默认超时重传计时器 $RTO_min$ 为 200ms，数据中心网络正常 RTT 通常为 200µs</li></ul></li><li><p>数据中心网络传输协议近年来<strong>主要面临的问题</strong>有：</p><ul><li>TCP Incast 问题</li><li>低延迟、高吞吐性能需求</li><li>多任务模式等（对于FCT有要求）</li></ul></li><li><p>最近发表的一个研究([3])表明，网络中由于低效的链路带宽利用率，平均<strong>有 7.25% 的数据流未能在截止时间前完成</strong>。</p></li><li><p>TCP的设计采用平<strong>均分配带宽原则</strong></p></li><li><p><strong>截止时间流和非截止时间流</strong></p><ul><li>尽管数据中心网络中<strong>有截止时间流</strong>所占比率很低，大概是所有流量的 5%。</li><li><strong>非截止时间流</strong>的应用彼此不同。有些应用像 VM 迁移或者数据备份等，在传输开始前就可以得知该流的大小，然而对于一些像数据库存取和 HTTP 分块传输的应用，这些应用在他们传输开始之前不知道流大小或者截止时间相关信息。<ul><li>因此，对于非截止时间流，较短的流完成时间和较高的吞吐率是他们的<strong>主要性能指标</strong>。</li></ul></li></ul></li></ul><h1 id="HULL"><a href="#HULL" class="headerlink" title="HULL"></a>HULL</h1><ul><li>high-performance ultra-low latency</li><li>他从三个层次来进行了设计：<ul><li>Phantom queues: Detecting and signaling congestion<ul><li>这个机制是一种为了创建剩余buffer提出的一种机制，也就是我们常说的bandwidth headroom，通过减少长流带宽来获取更高的短流效率，在端口使用仿真的虚拟队列基于链路利用率而不是利用队列的占有率来设计ECN标记。</li></ul></li><li>DCTCP: Adaptive reaction to ECN</li><li>Packet pacing<ul><li>这个在前面的文章里面也讲了Pacing的实现原理，但是我们也分析过Pacing其实不一定会带来特别好的效果，是有一定条件的，所以这篇文章用了一个硬件pacer，感觉很厉害。但是本质还是按照固定间隔发送封包。</li></ul></li></ul></li></ul><h1 id="some-resources（博客资源-and-so-on）"><a href="#some-resources（博客资源-and-so-on）" class="headerlink" title="some resources（博客资源 and so on）"></a>some resources（博客资源 and so on）</h1><p><span class="exturl" data-url="aHR0cHM6Ly9zcXVpZGFydGguY29tL3JjL3Byb2dyYW1taW5nL25ldHdvcmtpbmcvMjAxOC8wNy8xOC9pbnRyby1jb25nZXN0aW9uLmh0bWw=">squidarth:intro congestion-control<i class="fa fa-external-link-alt"></i></span></p>]]></content>
    
    <summary type="html">
    
      关于拥塞控制的常识/resources
    
    </summary>
    
    
      <category term="Summary" scheme="http://yoursite.com/categories/Summary/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>建站 | Jekyll -》 mkdocs -》 hexo</title>
    <link href="http://yoursite.com/2020/07/30/siteBuilding/"/>
    <id>http://yoursite.com/2020/07/30/siteBuilding/</id>
    <published>2020-07-30T21:50:53.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Jekyll"><a href="#Jekyll" class="headerlink" title="Jekyll"></a>Jekyll</h1><p>之前是用的jekyll，但是没找到我想要的全局搜索功能，有兴趣的还是可以看下：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA0MTg0NzIw">Jekyll建站<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="mkdocs"><a href="#mkdocs" class="headerlink" title="mkdocs"></a>mkdocs</h1><blockquote><p>其实Jekyll已经省去了很多麻烦了，但是我真的真的很烦每个md开头要写一大段乱七八糟的配置，不方便迁移，所以就转到mkdocs了，虽然模板的页面效果没有Jekyll丰富，但是对懒人还是极其友好的。</p></blockquote><blockquote><p>本来想用mkdocs的，毕竟还是挺省事儿的，文件结构也很清晰，学神点拨下我发现hexo可以全局搜索，跟mkdocs的标题搜索等级比起来，更香了！<br>简单学了下，后续可能考虑用mkdocs做一些项目文档手册，作为子网址吧，做手册挺合适的。</p></blockquote><h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cueG5jb2RpbmcuY29tLzIwMjAvMDMvMDEvdG9vbC9ta2RvY3MuaHRtbA==">蛮详细的，尤其是关于yml配置文件相关的<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cDovL3d1dG9uZ3RyZWUuZ2l0aHViLmlvL2Rldm9wcy9tYW5hZ2UteW91ci1jbXMtdXNpbmctbWtkb2Nz">配置也很详细，尤其有一些关于mkdocs的冷知识<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9teS5vc2NoaW5hLm5ldC9menhpYW9tYW5nZS9ibG9nLzMwMTA5MjE=">列了一些注意事项，which我也觉得很重要<i class="fa fa-external-link-alt"></i></span></li><li>这个没仔细看，但是感觉很高贵的样子 <span class="exturl" data-url="aHR0cHM6Ly90b3V0aWFvLmlvL3Bvc3RzL3Q5M2E1Yy9wcmV2aWV3">将 Jupyter 自动发布到 GitHub Pages<i class="fa fa-external-link-alt"></i></span></li></ul><h2 id="配置中遇到的问题"><a href="#配置中遇到的问题" class="headerlink" title="配置中遇到的问题"></a>配置中遇到的问题</h2><p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0b25lOTE1OS9hcnRpY2xlL2RldGFpbHMvNzkwNzEzMTY=">py37下字符编码遇到的问题<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h1><blockquote><p>我的两个config.xml（_config.next.xml是对应next主题的配置）都做了比较详细的注释，大家改起来也会很方便，欢迎在我的基础上修改！（虽然我本来也就是改学神的 :)</p></blockquote><h2 id="ref-1"><a href="#ref-1" class="headerlink" title="ref"></a>ref</h2><ol><li><p>环境配置请参考：<span class="exturl" data-url="aHR0cHM6Ly9scnNjeS5naXRodWIuaW8vMjAxNy8xMS8xMC9VYnVudHUtR2l0aHViLWlvLWNvbmZpZy1IZXhvLw==">linux下使用hexo建站<i class="fa fa-external-link-alt"></i></span>    </p><blockquote><ul><li>安装的时候提示8.x已经deprecated，所以我按照提示安装了12.x</li><li>在服务器上跑<code>npm install -g hexo-cli</code>等命令的时候，会遇到权限不够，根据提示给sudo就行</li></ul></blockquote></li><li><p>推送过程和基本配置网上已经很多了</p><blockquote><ul><li>next主题的仓库已经过期，我用的是学神给的这个：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0">https://github.com/theme-next/hexo-theme-next<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly90ZGluZy50b3AvYXJjaGl2ZXMvNDJjMzhiMTAuaHRtbA==">next主题的基本设置<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC85NDAzODY4OA==">hexo主题进阶设置<i class="fa fa-external-link-alt"></i></span></li></ul></blockquote></li><li><p>其他trivial的可选功能</p><blockquote><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9kNjhkZTA2N2VhNzQ=">Hexo添加Disqus评论<i class="fa fa-external-link-alt"></i></span></li><li>hexo添加google-analytic功能 （ 不想做了2333累了</li></ul></blockquote></li></ol><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><p>hexo new ‘文章标题’<br>hexo new draft<br> hexo clean</p><blockquote><p>清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。</p></blockquote><p>hexo g<br>hexo s<br>hexo d</p><hr><h1 id="mkdown-图床-获取-永久链接-（-香"><a href="#mkdown-图床-获取-永久链接-（-香" class="headerlink" title="mkdown+图床 获取 永久链接 （ 香"></a>mkdown+图床 获取 永久链接 （ 香</h1><p>可以参考<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSC9hcnRpY2xlL2RldGFpbHMvMTA3NjIyMjAy">我之前写的文章：typora+gitee图床<i class="fa fa-external-link-alt"></i></span></p><hr><h1 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h1><ul><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC81YzQxN2RhNzUxODgyNTI1YzYzODA5Y2Q=">简单入个门<i class="fa fa-external-link-alt"></i></span></li><li><input checked="" disabled="" type="checkbox"> <span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC82ODU0NTczMjE4Nzc5MzgxNzcz">hexo+Actions保姆教程<i class="fa fa-external-link-alt"></i></span></li></ul><p>本来想自己写的，结果学神也用的actions，哈哈作业一抄到底 （ docker确实不太精通啊…  - -||| ）</p><hr><h1 id="miscelleous"><a href="#miscelleous" class="headerlink" title="miscelleous"></a>miscelleous</h1><ul><li><input disabled="" type="checkbox"> 添加多个部署源<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">deploy</span>:</span><br><span class="line">- <span class="attribute">type</span>: git</span><br><span class="line">  <span class="attribute">repo</span>:</span><br><span class="line">- <span class="attribute">type</span>: heroku</span><br><span class="line">  <span class="attribute">repo</span>:</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      github pages建站
    
    </summary>
    
    
      <category term="程序员的自我修养" scheme="http://yoursite.com/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/"/>
    
    
      <category term="tool" scheme="http://yoursite.com/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>DeePCCI(SIGCOMM&#39;19)</title>
    <link href="http://yoursite.com/2020/02/05/PaperReading/DeePCCI(SIGCOMM&#39;19)/"/>
    <id>http://yoursite.com/2020/02/05/PaperReading/DeePCCI(SIGCOMM&#39;19)/</id>
    <published>2020-02-05T12:00:00.000Z</published>
    <updated>2020-09-12T14:08:51.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><blockquote><p>拥塞控制（CC）[12]是当今传输协议的基本组成部分，并强烈影响数据传输的性能。 CC最初建于1980年代以应对早期Internet的拥塞崩溃[17]，但CC仍在发展，并且出现了新的变体，例如BBR [1]或Vivace [3]。</p></blockquote><blockquote><p>CC引入了一个拥塞窗口（cwnd），该窗口限制了飞行中未确认字节的数量。==每种CC算法都定义了在特定算法定义的拥塞信号下，cwnd的变化情况==。给定CC方法的数量及其对性能的影响[9]，因此研究CC的使用方法很重要。例如，如果知道新的CC通常会与哪些其他算法竞争，则为公平起见，更容易对其进行调整。</p></blockquote><h2 id="传统的缺点"><a href="#传统的缺点" class="headerlink" title="传统的缺点"></a>传统的缺点</h2><blockquote><ul><li>但是，用于识别CC变体的现有工作（例如[2、18、24]）不适用于最新的CC和传输协议。==扩展和维护这些方法很复杂，因为它需要详细的领域知识才能知道CC参数化和配置如何影响其行为。== 当CC离开内核并引入用户空间协议（例如QUIC [11]）时，这一点变得尤为重要，这些协议相当容易更改，并且已经可以大规模部署[21]。</li></ul></blockquote><blockquote><ul><li>==此外，许多识别方法都基于fragile assumptions。== 例如，当使用TCP pacing （例如，与RENO [12]或CUBIC [5]结合使用）时，它们将失败。</li><li>*令人担忧的是，我们已知的所有被动方法都基于头部信息is parsable的的假设**。完全加密的传输（例如QUIC实施方案）使这些设计无效，并且如果可能的话，将需要进行重大更改。</li></ul></blockquote><p><strong>因此，目前就推理部署CC提出挑战。</strong></p><h2 id="难点与贡献"><a href="#难点与贡献" class="headerlink" title="难点与贡献"></a>难点与贡献</h2><p>作为应对这些挑战的第一步，本文介绍了DeePCCI，这是一种基于监督的基于深度学习的被动拥塞控制识别方法。<br>==它仅根据流数据包到达时间信息识别CC变体，因此甚至可以在加密的传输头上使用。==<br>此外，它使用深度学习来学习功能-从而避免了手动的，特定于领域的功能设计。<br>因此，与相关方法不同，==DeePCCI除了流分组定时的可用性之外，不做任何假设，== <strong>除了能够收集CC变体的训练流量之外，不需要任何领域知识。</strong><br>我们认为，这种假设和免手动调整方法允许在Internet流量中进行通用且可扩展的CC标识。具体来说，我们介绍DeePCCI的设计，评估及其局限性，并做出以下贡献：</p><p>•我们描述了流量的预处理和用于识别拥塞控制变量的深度学习模型。<br>•我们介绍了如何在测试平台上生成带有标记数据的多种拥塞控制变量模型。</p><p>我们评估了CUBIC，RENO和BBR作为主要拥塞控制变量的测试平台的性能。我们展示了该方法能够在各种情况下识别流量拥塞控制变量，但同时也介绍并讨论了无法识别拥塞控制变量的情况。结构体。第2节讨论了CC识别的最新技术及其缺点。第3节介绍DeePCCI的设计，而第4节介绍我们如何生成训练数据和评估我们的方法。最后，第5节总结了论文并讨论了未来的工作。</p><h1 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h1><blockquote><p>各种工作涉及识别CC变体。这些方法主要分为两类：使用被动[2、6、13、18、20]或主动[19、24]测量的识别方法。</p></blockquote><blockquote><p>主动方法可通过主动打开并操纵CC来激发CC反应进行检测。 Padhye和Floyd提出了TBIT [19]，该协议将精心制作的TCP段发送到Web服务器以主动触发拥塞控制。它记录响应丢失的数据包发送了哪些段，因为这种反应在TBIT中所区分的CC变体之间有很大差异。<br><br><br>杨等。目前的CAAI [24]扩展了TBIT的方法。为了估计发送方的cwnd，CAAI人为地延迟了观察所有飞行段的ACK。然后，CAAI导致数据包丢失，并从变化的cwnd中提取特征。这些功能随后用于使用随机森林进行分类。虽然这两种方法都可以实现较高的识别精度，但是由于错误选择的主机，因此依靠主动测量很容易引入测量偏差。<br><br><br>被动方法（与我们一样）不与主机交互，而是依靠流量跟踪来推断使用的流量CC变体，因此，它们允许收集有关实际流量的信息，该信息取决于有利位置而不是主动选择的主机。<br><br><br>Paxson等。和Jaiswal等。使用tcpanaly [20]和tcpflows [13]重建TCP状态机，以比较接收到的数据包和预期数据包。两种方法都需要非常详细的CC甚至实施知识来重建状态机。我们的方法的不同之处在于它不需要详细的CC知识。卡萨格兰德等。 [2]将cwnd中的特征更改用作其方法TCPMoon中的特征。针对这些功能检查了不同的手工规则，以区分CC。对于cwnd估计，作者使用基于TCP时间戳的RTT估计。因此，使用TCPMoon无法识别没有TCP时间戳选项或加密了传输头的流。由于我们的方法仅观察数据包到达的行为，因此不需要任何明文传输协议字段。<br><br><br>Oshio等。 [18]提出了一种基于聚类的方法。他们根据RTT估计值提取cwnd的特征并将其聚类以区分两个竞争的CC变体。我们的方法的不同之处在于，它不仅限于两个相互竞争的变体。哈戈斯等。<br><br><br>[6]使用发送方和接收方之间的未完成字节作为粗略且嘈杂的cwnd估计。使用递归神经网络对该估计值进行细化。精简后的Cwnd的突然减少用作CUBIC，BIC和RENO之间不同的乘法减少因子的估计。尽管此方法使用深度学习是相似的，但它仍然需要手动设计的乘数递减因子，因此只能识别基于损失的CC。我们的方法使用端到端深度学习模型，还识别基于延迟的CC并避免使用手动功能。</p></blockquote><h2 id="active-measurements"><a href="#active-measurements" class="headerlink" title="active measurements"></a>active measurements</h2><ul><li>制造丢包现象（ 通过延迟ack的发送或者是发送crafted packets to senders ）获得终端的变化情况<ul><li>获取了特征数据以后使用随机森林的方法</li></ul></li></ul><h2 id="passive-measurements"><a href="#passive-measurements" class="headerlink" title="passive measurements"></a>passive measurements</h2><ul><li>gather information on real traffic on vantage points ，而不是像active measurements那样观测主动选好的hosts</li><li>rebuild TCP  state machine –》 需要detailed CC domain knowledge and implementation knowledge</li><li>建模去估计Cwnd changes –》 like 使用TCP的时间戳来估计RTT （ 加密了以后就不适用了</li></ul><p><br><br><br></p><h1 id="DeePCCI-design"><a href="#DeePCCI-design" class="headerlink" title="DeePCCI design"></a>DeePCCI design</h1><h2 id="CC-Manifestaion-in-Traffic"><a href="#CC-Manifestaion-in-Traffic" class="headerlink" title="CC Manifestaion in Traffic"></a>CC Manifestaion in Traffic</h2><ul><li>only use <strong>arrival time</strong> of a flow as input<ul><li>unlike Netflow 是什么意思 ？ Netflow没有packet timing嘛</li><li>目的 :associate packets to flow</li></ul></li></ul><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://images.weserv.nl/?url=https://img-blog.csdnimg.cn/20190924094304705.png" alt="在这里插入图片描述"></p><h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><ul><li>用于特征提取</li><li>改进了VGG net  结合了 residual network</li></ul><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>如果packet的size是固定的，就用VGGNet就够了 ，但是由于我们想看的是length-variant的packet，所以使用LSTM–》有记忆<ul><li>用的是unidirectional network     </li></ul></li></ul><p><br><br><br></p><h1 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h1><h2 id="Mininet-based-Network-Testbed"><a href="#Mininet-based-Network-Testbed" class="headerlink" title="Mininet-based Network Testbed"></a>Mininet-based Network Testbed</h2><ul><li>不同的网络环境<ul><li>TCP sender number</li><li>link latency</li><li>bottleneck link’s BDP</li></ul></li><li>选择了三个variant进行对比 ( RENO, CUBIC ,BBR ) <ul><li>每个发送60s 的fully-loaded TCP stream </li><li>观测者比发送者早2s开启     </li></ul></li></ul><h2 id="Single-Host-Network"><a href="#Single-Host-Network" class="headerlink" title="Single-Host Network"></a>Single-Host Network</h2><ul><li><strong>baseline condition</strong></li><li>哑铃状拓扑</li><li>没有背景流量</li></ul><h2 id="Multi-Host-Network"><a href="#Multi-Host-Network" class="headerlink" title="Multi-Host Network"></a>Multi-Host Network</h2><ul><li>reside on each side of the network</li></ul><h2 id="Cross-Traffic-Network"><a href="#Cross-Traffic-Network" class="headerlink" title="Cross-Traffic Network"></a>Cross-Traffic Network</h2><ul><li>side flow</li><li>main flow</li></ul><h2 id="performance"><a href="#performance" class="headerlink" title="performance"></a>performance</h2><h3 id="identifacation-by-Delay-and-Bandwidth"><a href="#identifacation-by-Delay-and-Bandwidth" class="headerlink" title="identifacation by Delay and Bandwidth"></a>identifacation by Delay and Bandwidth</h3><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>带宽越大、延迟越大、host越多越容易识别成功</li></ul><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><ul><li><p>带宽越大越成功是因为</p><ul><li>归因于拥塞窗口的整数离散化，而最大cwnd取决于瓶颈带宽。 ( 我的理解就是：允许的cc窗口的区别度高 ）</li><li>以较大的带宽采样了诸如CUBIC的cubic行为的更多步骤。 较低的带宽意味着较少的采样步骤，并且三次行为很难与例如RENO的线性行为相区别。</li></ul></li><li><p>认为延迟越大越成功</p><ul><li>与histogram的bin-size  有关<blockquote><p>我个人在这里的理解就是： bin-size 就有点像分辨率 如果延迟太小，会导致整个图被横向压扁；如果延迟大一点，整个图就会舒展开，一些特征啥的会更加清晰，容易被CNN识别、提取到<br>有点意思 :)</p></blockquote></li></ul></li><li><p>认为多主机效果更好是因为</p><ul><li>对于相同的延迟，多主机情况也能获得更好的结果。我们将此影响归因于流量竞争。当link饱和时，单主机流的速率不会随着cwnd的增加而迅速增加，<strong>但是在多主机方案中增加流的cwnd可以增加其在队列中的数据包的份额，从而增加其速率。</strong> <strong>因此，对不同拥塞控制变量的cwnd的单独更改会对速率产生更大的影响，从而更强烈地影响数据包到达</strong>，并在更长的时间内影响较小的延迟和带宽问题。</li></ul></li></ul><p><strong>【感觉这一点实际上是利用了这三种方案面对竞争时候的特性有所区别的特点，并不是说：Competing的时候会有种让CC增加cwnd的动力(只有发的多才能收的快 收的快才能滑动)  ，而应该说：面对 competing的时候有不同的特性，有的人会趋于让cwnd增大，所以对应的包发得多，到达的间隔就短了】</strong></p><blockquote><p>如我们所见，<strong>带宽和延迟会影响我们的方法</strong>，延迟/带宽过小会导致识别性能降低。<strong>为了进一步评估，我们将以50Mbps作为带宽</strong>继续进行实验，以更好地了解该方法在何处面临挑战。 </p></blockquote>]]></content>
    
    <summary type="html">
    
      RL+CC
    
    </summary>
    
    
      <category term="PaperReading" scheme="http://yoursite.com/categories/PaperReading/"/>
    
    
      <category term="Network" scheme="http://yoursite.com/tags/Network/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
      <category term="Congestion Control" scheme="http://yoursite.com/tags/Congestion-Control/"/>
    
  </entry>
  
</feed>
