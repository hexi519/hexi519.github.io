<!DOCTYPE html><html lang="en,zh-CN,default"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.0.0"><link rel="icon" type="image/png" sizes="16x16" href="/function%20()%20%7B%0A%20%20%20%20%20%20for%20(var%20_len2%20=%20arguments.length,%20args%20=%20new%20Array(_len2),%20_key2%20=%200;%20_key2%20%3C%20_len2;%20_key2++)%20%7B%0A%20%20%20%20%20%20%20%20args%5B_key2%5D%20=%20arguments%5B_key2%5D;%0A%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20return%20obj%5Bval%5D.apply(obj,%20args);%0A%20%20%20%20%7D"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"hexi519.github.io",root:"/",scheme:"Gemini",version:"8.0.0-rc.4",exturl:!0,sidebar:{position:"left",display:"post",padding:18,offset:12},copycode:!0,bookmark:{enable:!0,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},prism:!1,path:"search.xml"}</script><meta name="description" content="Infocom&#39;18 【一句话概括这个工作】"><meta property="og:type" content="article"><meta property="og:title" content="DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach"><meta property="og:url" content="https://hexi519.github.io/ExtensiveReading/Route/DRL-TE/index.html"><meta property="og:site_name" content="Hesy&#39;s Blog"><meta property="og:description" content="Infocom&#39;18 【一句话概括这个工作】"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/210803-186164.png"><meta property="og:image" content="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211336-513625.png"><meta property="og:image" content="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211424-585348.png"><meta property="og:image" content="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211803-272410.png"><meta property="og:image" content="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201104211846544.png"><meta property="og:image" content="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201104211853832.png"><meta property="og:image" content="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/212915-598687.png"><meta property="og:image" content="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/213935-479446.png"><meta property="og:image" content="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/05/005550-301559.png"><meta property="article:published_time" content="2020-10-19T10:25:51.000Z"><meta property="article:modified_time" content="2020-11-25T07:53:57.252Z"><meta property="article:author" content="Hesy"><meta property="article:tag" content="Network"><meta property="article:tag" content="Reinforcement Learning"><meta property="article:tag" content="Routing"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/210803-186164.png"><link rel="canonical" href="https://hexi519.github.io/ExtensiveReading/Route/DRL-TE/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"en"}</script><title>DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach | Hesy's Blog</title><noscript><style>body{margin-top:2rem}.use-motion .collection-header,.use-motion .comments,.use-motion .footer,.use-motion .header,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header,.use-motion .sidebar,.use-motion .site-brand-container .toggle{opacity:initial}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line{transform:scaleX(1)}.search-pop-overlay,.sidebar-nav{display:none}.sidebar-panel{display:block}</style></noscript><link rel="alternate" href="/atom.xml" title="Hesy's Blog" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="Toggle navigation bar"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Hesy's Blog</h1><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">Seek for your love</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">5</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">29</span></a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="fa fa-tag fa-fw"></i>Tags<span class="badge">9</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="Searching..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">Table of Contents</li><li class="sidebar-nav-overview">Overview</li></ul><section class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#hesy-summary"><span class="nav-number">1.</span> <span class="nav-text">hesy summary</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BE%BF%E4%BA%8E%E5%90%8E%E6%9C%9F%E6%95%B4%E7%90%86%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="nav-number">1.1.</span> <span class="nav-text">便于后期整理的信息</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">2.</span> <span class="nav-text">abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-number">3.</span> <span class="nav-text">1 Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-DRL"><span class="nav-number">4.</span> <span class="nav-text">2 DRL</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Problem-Statement"><span class="nav-number">5.</span> <span class="nav-text">3 Problem Statement</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Proposed-DRL-Based-Control-Framework"><span class="nav-number">6.</span> <span class="nav-text">4. Proposed DRL-Based Control Framework</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Performance-Evaluation"><span class="nav-number">7.</span> <span class="nav-text">5. Performance Evaluation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Related-Work"><span class="nav-number">8.</span> <span class="nav-text">5. Related Work</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%96%91%E9%97%AE"><span class="nav-number">9.</span> <span class="nav-text">疑问</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#intro"><span class="nav-number">9.0.1.</span> <span class="nav-text">intro</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%84%E4%BC%9Aask%E7%A0%9A%E8%88%92"><span class="nav-number">10.</span> <span class="nav-text">组会ask砚舒</span></a></li></div></section><section class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Hesy" src="/img/avatar-hexi.jpg"><p class="site-author-name" itemprop="name">Hesy</p><div class="site-description" itemprop="description">some thoughts to share</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">29</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">5</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">9</span> <span class="site-state-item-name">tags</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleGk1MTk=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hexi519"><i class="fab fa-github fa-fw"></i>GitHub</span> </span><span class="links-of-author-item"><span class="exturl" data-url="bWFpbHRvOmhlc3k1MTlAZ21haWwuY29t" title="E-Mail → mailto:hesy519@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span> </span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSA==" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Hesy_H"><i class="fab fa-plug fa-fw"></i>CSDN</span></span></div><div class="cc-license motion-element" itemprop="license"><span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i> Friend Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cDovL25qemp6Lndpbg==" title="http:&#x2F;&#x2F;njzjz.win">Jinzhe Zeng</span></li><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cHM6Ly9iaWctY2hlbmcuY29t" title="https:&#x2F;&#x2F;big-cheng.com">Daven</span></li><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlc3lfSA==" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;Hesy_H">荷西·H</span></li></ul></div></section></div></aside><div id="sidebar-dimmer"></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleGk1MTkv" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span><noscript><div id="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en"><link itemprop="mainEntityOfPage" href="https://hexi519.github.io/ExtensiveReading/Route/DRL-TE/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/img/avatar-hexi.jpg"><meta itemprop="name" content="Hesy"><meta itemprop="description" content="some thoughts to share"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Hesy's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach<span class="exturl post-edit-link" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleGk1MTkvaGV4aTUxOS5naXRodWIuaW8vX3Bvc3RzL0V4dGVuc2l2ZVJlYWRpbmcvUm91dGUvRFJMLVRFLm1k" title="Edit this post"><i class="fa fa-pen-nib"></i></span></h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2020-10-19 10:25:51" itemprop="dateCreated datePublished" datetime="2020-10-19T10:25:51+00:00">2020-10-19</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">Edited on</span> <time title="Modified: 2020-11-25 07:53:57" itemprop="dateModified" datetime="2020-11-25T07:53:57+00:00">2020-11-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ExtensiveReading/" itemprop="url" rel="index"><span itemprop="name">ExtensiveReading</span></a></span></span><br><span class="post-meta-item" title="Symbols count in article"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">Symbols count in article: </span><span>7.5k</span> </span><span class="post-meta-item" title="Reading time"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">Reading time &asymp;</span> <span>7 mins.</span></span><div class="post-description">Infocom'18 【一句话概括这个工作】</div></div></header><div class="post-body" itemprop="articleBody"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hesy-summary"><a href="#hesy-summary" class="headerlink" title="hesy summary"></a>hesy summary</h1><ul><li>感觉这篇文章文笔不行啊…一看就是中国人写的…[果然，作者全都是中国名…]</li><li>evaluation还是很不错==哪里不错??==</li></ul><hr><ul><li><p>排队论不适合多跳排队问题的建模</p><ul><li>强假设不能满足</li><li>多跳排队还是个open problem</li></ul><p>==那排队论研究的是什么问题??==</p></li></ul><h2 id="便于后期整理的信息"><a href="#便于后期整理的信息" class="headerlink" title="便于后期整理的信息"></a>便于后期整理的信息</h2><ul><li>创新点/主要思想<ul><li>首次用DRL</li><li>提出了DRL-TE的框架</li><li>改进了算法==？？==</li></ul></li><li>算法使用<ul><li>RL</li></ul></li><li>实验设置<ul><li>ns3</li><li>代表性和随机性的网络拓扑</li></ul></li><li>效果<ul><li>提升了吞吐，降低了延迟 ==所以为什么能降低延迟??==</li><li>对网络变化更有鲁棒性 (==如何得出这个结论？==)</li></ul></li></ul><h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><p>​ 现代通信网络已经变得非常复杂且高度动态，这使其难以建模，预测和控制。 在本文中，我们开发了一种新颖的体验驱动方法，可以像人类学习新技能（例如驾驶，游泳等）一样，根据自身的经验而不是准确的数学模型来学习很好地控制通信网络。 具体来说，我们首次建议利用新兴的深度强化学习（DRL）在通信网络中实现无模型控制； 并针对基础网络问题：流量工程（TE），提出了一种新颖且高效的基于DRL的控制框架DRL-TE。通过共同学习网络环境及其动态性，并在强大的深度神经网络（DNN）的指导下进行决策，<strong>所提出的框架最大程度地提高了广泛使用的效用函数</strong>。<strong>我们提出了两种新技术</strong>，即TE感知探索和基于行为者批评的优先体验重播，以优化通用DRL框架，尤其是针对TE的框架。 为了验证和评估所提出的框架，我们在<strong>ns-3</strong>中实施了该框架，<strong>并使用代表性和随机生成的网络拓扑进行了全面测试</strong>。</p><blockquote><p>这里的代表性和随机性</p></blockquote><p>​ 广泛的数据包级仿真结果表明：1）与几种广泛使用的基准方法相比，DRL-TE显着<u>降低了端到端延迟</u>，并不断提高了网络实用性，<u>同时提供了更好或相当的吞吐量</u>； 2）DRL-TE对网络的变化更具有鲁棒性； 和3）DRL-TE始终优于最新的DRL方法（用于连续控制），即深度确定性策略梯度（DDPG），which不能提供令人满意的性能。</p><blockquote><p>创新：</p><ul><li>首次用DRL</li><li>对结合network使用RL做出了巨大的贡献：1. 提出了DRL-TE的框架； 2. 在AC上进行改进，实验证明比ddpg效果要好不少</li></ul></blockquote><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><blockquote><p>Our general goal(e.g. 拯救世界) &amp; SDN is promising</p></blockquote><p>​ 因此，我们的目标是开发一种新颖的，无需经验的无模型方法，该方法可以像人类学习技能（例如驾驶，游泳等）一样，从经验中学习很好地控制通信网络，而不是精确的数学模型。我们认为，某些新兴的联网技术，例如软件定义网络（SDN）[18]，可以很好地支持这种体验/数据驱动的方法。 例如，SDN中的<strong>Openflow</strong>控制器可以用作中央控制单元，用于收集数据，制定决策和部署解决方案。</p><blockquote><p>开始喷前人的工作</p></blockquote><p>​ 一个基本的网络问题是流量工程（TE）：给定一组具有源节点和目标节点的网络流，请找到一种解决方案，以最大化实用功能为目标转发数据流量。 简单且广泛使用的解决方案包括：始终通过最短路径路由流量（例如，开放式最短路径优先（OSPF）[24]）； 或通过多个可用路径平均分配流量（例如，有效负载平衡<strong>（VLB）[38]**）。 显然，它们都不是最优的。 如果存在针对网络环境，用户需求及其动态的准确且数学可解的模型，则可以开发出更好的解决方案。 <u>排队论已被用于对通信网络进行建模并协助资源分配[15]，[25]，[26]，[37]</u>。 **但是，由于以下原因，它可能不适用于涉及多跳路由和端到端性能（例如延迟）的网络问题</strong>：1）在排队论中，queueing network（而不是单个队列）中的许多问题仍然是开放问题，而具有网状拓扑结构的通信网络则表示相当复杂的多点到多点排队网络，其中来自一个队列可以被分布到多个下游队列，并且一个队列可以从多个不同的上游队列接收分组。 2）<u>排队理论只能在一些强假设下（例如，元组到达遵循泊松分布等）提供准确的排队延迟估计，但是在复杂的通信网络中可能不成立</u>。 请注意，即使到达每个源节点的数据包都遵循泊松分布，到达中间节点的数据包也可能不会。</p><p>​ 另外，对**<u>网络效用最大化（NUM）[17]</u><strong>的研究也很深入，它通常通过制定和解决优化问题来提供资源分配解决方案。 但是，</strong>这些方法可能会遇到以下问题**：1）它们通常假定一些关键因素（例如用户需求，链接使用等）作为输入给出，但是，这些因素很难估计或预测。 2）由于给定了资源分配的决策变量（例如TE），因此很难通过显式地将其包含在效用函数中来直接最小化端到端延迟，因此很难在 由于需要一个精确的数学模型来实现此目的，因此它们必须是封闭的形式（尽管如上所述，排队理论在这里可能不起作用）。 3）这些工作未能很好地解决网络动态性问题。 他们中的大多数声称提供了一种“良好”的资源分配解决方案，该解决方案是最佳的或接近最佳的，但仅适用于网络快照。 但是，大多数通信网络时变很大。 这些NUM方法尚未很好地解决如何调整或重新计算资源分配以适应这种动态情况。</p><blockquote><p>讲了下为何用DRL</p></blockquote><ul><li><p>DRL is in succsess</p><ul><li>DRL is promising<ul><li>model-free ,not relying on exact model (e.g. queueing model)<ul><li>handle complicated action space with DDPG</li><li>can handle dynamic env， due to it is AI method</li></ul></li></ul></li></ul></li></ul><blockquote><p>contribution</p></blockquote><ul><li>我们是第一个为TE提供高效，实用的基于DRL的经验驱动控制框架DRL-TE。</li><li>我们讨论并表明，**<u>直接应用最先进的DRL解决方案进行连续控制，即深度确定性策略梯度（DDPG）[16]，对TE问题效果不佳。</u>** 【有意思了。意思来了】</li><li>我们提出了两种新技术，即TE-aware exploration 和 AC-based prioritized experience replay，以优化通用DRL框架，尤其是针对TE的框架。 我们通过使用具有代表性和随机网络拓扑的ns-3进行的广泛数据包级仿真，表明DRL-TE明显优于几种广泛使用的基线方法。</li></ul><h1 id="2-DRL"><a href="#2-DRL" class="headerlink" title="2 DRL"></a>2 DRL</h1><h1 id="3-Problem-Statement"><a href="#3-Problem-Statement" class="headerlink" title="3 Problem Statement"></a>3 Problem Statement</h1><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/210803-186164.png" alt="image-20201104210801863" style="zoom:80%"><p>分割比$w_{k,j}$ , 备选路径集合$P_k$ , traffic load $f_{k,j}$</p><ul><li><p>$\alpha-faireness$ 的文献要好好读读这个指标的含义</p><ul><li><p>又提到了，$\alpha$ 可以被用来balance fairness和efficiency 。 当$\alpha=1$的时候，可以获得proportional fairness</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211336-513625.png" alt="image-20201104211329992" style="zoom:80%"></li><li><p>仿照Remy提了个指标</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211424-585348.png" alt="image-20201104211423959" style="zoom:80%"></li></ul></li></ul><h1 id="4-Proposed-DRL-Based-Control-Framework"><a href="#4-Proposed-DRL-Based-Control-Framework" class="headerlink" title="4. Proposed DRL-Based Control Framework"></a>4. Proposed DRL-Based Control Framework</h1><p>在本节中，我们介绍了针对上述TE问题的建议的基于DRL的控制框架DRL-TE。</p><ul><li><p>state</p><p>点对的集合</p></li></ul><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/211803-272410.png" alt="image-20201104211802927"></p><ul><li><p>actors</p><p>分割比的集合</p><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201104211846544.png" alt="image-20201104211846544"></p></li><li><p>reward</p></li></ul><p><img src="https://images.weserv.nl/?url=C:%5CUsers%5Chesy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201104211853832.png" alt="image-20201104211853832"></p><ul><li><p>algorithm :</p><ul><li><p>AC算法</p></li><li><p>动作加随机噪声</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/212915-598687.png" alt="image-20201104212913054"></p></li></ul></li></ul><p>​ 所提出的控制框架不限于针对abase的任何特定的基础TE解决方案，可以通过许多不同方式来获得该解决方案。 例如，一种简单的解决方案是使用最短路径为每个通信会话传递所有数据包，这在大多数情况下不是最佳的，但足以切断作为探索的基准。 另一种解决方案是将每个通信会话的流量负载平均分配到所有候选路径。 基于NUM的方法也可以用于查找基本解决方案。 例如，我们可以通过解决以下数学编程来获得TE解决方案：</p><img src="https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/04/213935-479446.png" alt="image-20201104213933393"><p>​ In this formulation，目的是使产量方面的总效用最大化。 请注意，很难在效用函数中包含端到端延迟项，因为不存在可以准确地在端到端延迟与其他决策变量&lt;xk，fk,j&gt;</p><p>​ Note that it is hard to include the end- to-end delay term in the utility function since there does not exists a mathematical model that can accurately establish a connection between end-to-end delay and the other decision variables &lt; xk, fk,j &gt;. 这就是为什么NUM上大多数现有作品都没有很好地解决端到端延迟的原因。</p><p>​ 约束（6b）确保每条链路上的总流量负载不超过其容量Ce，其中pj是Pk中的第j条路径。 约束（6c）确保每个会话k的总吞吐量不超过其需求Bk（可以估算）。 约束（6d）在两组决策变量<xk>和&lt;fk，j&gt;之间建立联系。 如果α= 1，Uα（xk）= log xk，则该问题变为凸编程问题，which可以通过我们的实现中使用的Gurobi Optimizer [10]有效解决。</xk></p><blockquote><p>前面也说$\alpha=1$的时候经常用来被用作资源分配，不知道是出于其凸函数方便计算的性质还是出于真实的性质。</p></blockquote><ul><li><p>==？？==</p><ul><li><p><input disabled type="checkbox"> 我觉得第四节中 一定概率选择$a_{base}$而不是$a_{random}$就很扯…</p></li><li><p><input disabled type="checkbox"> NUM到底是什么模型？？这里指的应该是 以网络链路利用率最大化 （Network utility maxmization）</p><ul><li>attention！ 这里的U不是utilization，而是utility！e.g. utility function = - utilization</li></ul></li><li><p><input disabled type="checkbox"> Note that it is hard to include the end- to-end delay term in the utility function since there does not exists a mathematical model that can accurately establish a connection between end-to-end delay and the other decision variables &lt; xk, fk,j &gt;. 【这是个什么锤子…】</p></li><li><p><input disabled type="checkbox"> 所以6b方程式的意思是可以比给定的流量发得少，但是不允许发的多??</p><blockquote><p>哦哦、这个是给定总量的情况下，测效用函数。而飞哥文章的思路是，给定，总量可以变</p></blockquote><p><del>总感觉这个式子怪怪的</del> 那是不是飞哥的建模出了问题了…</p></li></ul></li></ul><hr><blockquote><p>建模完成后就开始说如何解了</p></blockquote><p><strong>AC算法</strong></p><ul><li><p>加上了优先级经验回放，which author claim 是他们的扩展，不是AC本身自带的</p></li><li><p>网络架构</p><ul><li><p>Actor</p><ul><li>2 FC ( 64,32 ) Leaky Rectifier激活函数，输出层softmax作为激活函数来确保输出值的总和等于1。</li></ul></li><li><p>Critic</p><ul><li>2 FC ( 64,32 ) Leaky Rectifier激活函数</li></ul><blockquote><p>A和C最后一层网络架构的不一样的原因是，前者输出动作概率，所以需要softmax，后者只要输出一个数值，所以不需要用softmax归一化。</p></blockquote></li><li><p>本算法对于优先级采样的一些设计/改进</p><ul><li><p>为了以等式（9）给出的概率对N个转换进行采样，将范围[0，p<del>total</del>]划分为N个子范围，并从每个子范围中均匀采样一个转换，其中p<del>total</del>是重播缓冲区中的所有transition的他优先级之和。 正如[30]所建议的，我们使用求和树来实现优先级概率，这类似于二进制堆。</p></li><li><p>区别在于1）叶节点存储转换的优先级； 2）内部节点存储其子节点的总和。 这样，root的值为p<del>total</del>，更新和采样的时间复杂度为O（logN<del>tree</del>），其中N<del>tree</del>是求和树中节点的数量。</p></li><li><p>超参数设置</p><p>ξ：= 0.01，β<del>0</del>：= 0.6，β<del>1</del>：= 0.4，γ：= 0.99，ϕ：= 0.6，η<del>π</del>：= 0.001，η<del>Q</del>： = 0.01，τ：= 0.01，N = 64。</p></li></ul></li></ul></li></ul><h1 id="5-Performance-Evaluation"><a href="#5-Performance-Evaluation" class="headerlink" title="5. Performance Evaluation"></a>5. Performance Evaluation</h1><ul><li><p><strong>Testbed</strong></p><p>ns-3, Tensorflow, with topo of NSFNET[23] &amp; ARPANET[1] &amp; 网络拓扑生成器BRITE [19]随机生成了一个具有20个节点和80个链接的网络拓扑</p></li><li><p>实验设置</p><p>对于每种网络拓扑，我们分配K = 20个通信会话，每个会话都有随机选择的源节点和目标节点。 对于每个通信会话，我们选择3条最短路径（就跳数而言）作为其候选路径。 每个链接的容量设置为100Mbps。 数据包到达每个通信会话的源节点（即流量需求）遵循泊松过程（请注意，数据包到达中间节点可能不遵循泊松过程），其平均值均匀地分布在一个20Mbps大小的窗口内。 在我们的实验中，我们最初将窗口设置为[0，20] Mbps，然后通过以每次运行5Mbps的步长滑动窗口来增加流量需求。 我们为效用函数设置α：= 1和σ：= 1以平衡吞吐量，延迟和公平性，即</p><p><img src="https://images.weserv.nl/?url=https://gitee.com/HesyH/Image-Hosting/raw/master/image4typora/202011/05/005550-301559.png" alt="image-20201105005550050"></p></li><li><p><strong>Baselines</strong></p><ul><li>最短路径（SP）：每个通信会话都使用最短路径来传递其所有数据包。</li><li>负载平衡（LB）：每个通信会话均将其流量负载平均分配给所有候选路径。</li><li>网络实用程序最大化（NUM）：它通过解决凸编程问题Ⅳ中给出的NUM-TE来获得TE解决方案。</li><li>DDPG：为公平起见，我们在保持其他设置（例如状态，动作，奖励和DNN）相同的情况下，用DDPG算法[16]替换为DRL-TE算法（算法1）。</li></ul></li><li><p><strong>Evaluation指标</strong> &amp; 图释说明</p><ul><li>我们将总的端到端吞吐量，端到端平均数据包延迟和网络（即总）效用值用作比较的性能指标。</li><li>我们在图5和6中显示了相应的仿真结果。图1-3每个对应于一个网络拓扑。<ul><li>注意，x轴上的数字是相应交通需求窗口（如上所述）的中心值。</li></ul></li><li>根据奖励显示了在在线学习过程中三种网络拓扑上两种DRL方法（DDPG和DRL-TE）的性能。<ul><li>为了便于说明和比较，我们使用常用方法（r-rmin）/（rmax-rmin）归一化和平滑了奖励值（其中r是实际奖励，rmin和rmax是在线学习期间的最小和最大奖励）和著名的**<u>前后过滤算法[11]</u><strong>。 我们在</strong><u>图4</u>**中给出了相应的仿真结果。</li><li>请注意，对于这些结果，使用窗口[10，30] Mbps生成了相应的流量需求。</li></ul></li></ul></li></ul><ul><li><p><strong>结论</strong></p><ul><li><p>端到端时延</p><ul><li><p>从图1a，2a和3a中可以看出，与所有四种基线方法相比，DRL-TE显着降低了所有三种拓扑的端到端延迟。 例如，在NSF拓扑上，当流量负载为中等时（即流量需求窗口为[10，30] Mbps），DRL-TE可以将端到端延迟显着降低51.6％，28.6％，74.6％ 与SP，LB，NUM和DDPG相比分别为50.0％和50.0％。 总体而言，DRL-TE分别平均降低了55.4％，47.1％，70.5％和44.2％。</p></li><li><p>与吞吐量相比，端到端延迟更难处理，因为如上所述，它缺乏能够很好地捕捉其特性和运行时动态的精确数学模型。 看到NUM导致性能相当差是不足为奇的，因为NUM无法明确解决端到端延迟，并且其设计基于网络状态相当稳定或变化缓慢的假设，这可能不是事实。 尽管诸如SP和LB之类的简单解决方案凭直觉可以提供预期的性能，但最短的路径和负载平衡（可以避免拥塞）可以帮助减少延迟。 DRL-TE毫无疑问在端到端延迟方面提供了卓越的性能，因为它不断学习运行时动态，并在DNN的帮助下做出明智的决策以使其达到最佳状态。</p><blockquote><p>==??== 这一段要好好看下</p></blockquote></li></ul></li><li><p>吞吐量</p><p>即使DRLTE的目的（奖励功能）不是简单地最大化端到端吞吐量，它仍然提供令人满意的性能，如图1和2所示。 1b，2b和3b。 与所有其他方法相比，DRL-TE可以持续提高NSFNST拓扑的吞吐量。 在ARPANET和随机拓扑上，DRL-TE给出的吞吐量值可与LB给出的吞吐量值相媲美（负载均衡在整个过程中应产生很高的收益），但仍高于SP和NUM提供的吞吐量值。</p></li><li><p>效用函数</p><p>如预期的那样，我们可以从图2和3中看到。 从图1c，2c和3c可以看出，DRL-TE在总效用方面胜过所有其他方法，因为其奖励功能已设置为最大化。 平均而言，DRL-TE分别胜过SP，LB，NUM和DDPG 7.7％，9.1％，26.4％和12.6％。</p></li><li><p>使用并且无论选择哪种网络拓扑，吞吐量和延迟都基本上与流量需求有关（无论什么方法，什么拓扑，throughpout和delay就是会随着流量需求增大而上升，the total utility 通常会下降）。 这很容易理解，因为流量负载越高，通常吞吐量就越高，但是由于等待时间更长甚至拥塞而导致的延迟也就越大，从而降低了总实用性。 此外，吞吐量不会单调增加，当网络变得饱和时，由于拥塞和数据包丢失，更高的流量需求甚至可能导致吞吐量变差。 我们还注意到DRL-TE在流量负载和网络拓扑的变化方面具有鲁棒性，因为在所有流量需求设置和所有拓扑中，DRL-TE的性能始终优于所有其他方法。</p></li><li><p>另外，我们还可以从图1和图2中观察到。 1-3指出DDPG在这些拓扑上效果不佳。 例如，与SP和LB相比，就总效用而言，它通常表现较差，即使它提供了稍微更好的端到端延迟。 为了进一步说明DRL-TE为什么比DDPG更好的原因，我们还显示了图4中三种网络拓扑在在线学习过程中奖励价值的变化。显然，在所有这些网络拓扑中，DRL-TE很快（仅在几个范围内） 数以千计的决策时代）达到了很好的解决方案（给予了很高的回报）； 而DDPG似乎停留在具有较低奖励价值的局部最优解决方案上。 特别是，在随机拓扑上，我们只能看到前几百个世代的微小改进，然后它无法找到更好的解决方案（动作）来提高奖励。 这些结果清楚地证明了所提出的新技术的有效性，包括TE感知探索和基于行为者批评的优先体验重播。</p><blockquote><p>==??==问题就来了，DDPG不能加优先级体验重播么…</p></blockquote></li></ul></li></ul><h1 id="5-Related-Work"><a href="#5-Related-Work" class="headerlink" title="5. Related Work"></a>5. Related Work</h1><p>==关于网络的这一部分要好好看下==</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><h3 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h3><ul><li>VLB和ECMP的区别</li><li>标红的句子根本是看不懂。。问下飞哥</li></ul><ul><li><p>我们一定要做分布式的么？不做的话会怎么样–》无法达到全局最优 ? Auto怎么被评论的？</p></li><li><p>Caida数据集</p></li><li><p>ospf最短路径的权重问题？</p></li><li><p>看看人家代码里面的split ratio</p></li><li><p>$\alpha-faireness$指标和另一个CC里面常用的指标的调研</p><ul><li>check下IOT以及Remy里面对于$\alpha$的选取</li></ul></li><li><p>还是那个问题。。这里reward的设立是不是有问题….看下Pensive，人家比较有建模经验</p></li><li><p>路由常关注哪些指标? 有没有流完成时间？？？</p></li><li><p>我觉得第四节中 一定概率选择$a_{base}$而不是$a_{random}$就很扯…</p><ul><li>有机会训练下模型，看看随机选择会不会比$a_{base}$更好</li><li>这里不随机选择的一个原因会不会是因为 随机选择的动作 没有意义</li></ul></li><li><p>evaluation</p><ul><li>前后过滤算法</li><li>结论部分讲端到端时延的其实我没有很懂</li></ul></li></ul><ul><li>经常看到的empirical research/study 是什么意思</li><li>怎么没看到Groubi的用法</li><li>确认下是集中式控制的？就在开头说了下SDN是个好东西</li><li>一句话概括这个工作</li><li>分割比的话 把流拆开来传输，不会导致乱序么</li></ul><h1 id="组会ask砚舒"><a href="#组会ask砚舒" class="headerlink" title="组会ask砚舒"></a>组会ask砚舒</h1><ul><li>现实中OSPF的权重是用什么设置的</li></ul></div><div class="reward-container"><div></div><button onclick='document.getElementById("post-reward").classList.toggle("active")'>Donate</button><div id="post-reward"><div><img src="/img/WechatPay.jpg" alt="Hesy WeChat Pay"><p>WeChat Pay</p></div><div><img src="/img/AliPay.jpg" alt="Hesy Alipay"><p>Alipay</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>Hesy</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://hexi519.github.io/ExtensiveReading/Route/DRL-TE/" title="DRL-TE | Experience-driven Networking, A Deep Reinforcement Learning based Approach">https://hexi519.github.io/ExtensiveReading/Route/DRL-TE/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Network/" rel="tag"># Network</a> <a href="/tags/Reinforcement-Learning/" rel="tag"># Reinforcement Learning</a> <a href="/tags/Routing/" rel="tag"># Routing</a></div><div class="post-nav"><div class="post-nav-item"><a href="/ExtensiveReading/Route/SQR-DLWR/" rel="prev" title="SQR&DLWR|Evaluating and Boosting Reinforcement Learning for Intra-domain Routing"><i class="fa fa-chevron-left"></i> SQR&DLWR|Evaluating and Boosting Reinforcement Learning for Intra-domain Routing</a></div><div class="post-nav-item"><a href="/Summary/rlReview/" rel="next" title="rlReview">rlReview <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div></main><footer class="footer"><div class="footer-inner"><div class="languages"><label class="lang-select-label"><i class="fa fa-language"></i> <span>English</span> <i class="fa fa-angle-up" aria-hidden="true"></i></label> <select class="lang-select" data-canonical=""><option value="en" data-href="/ExtensiveReading/Route/DRL-TE/" selected>English</option><option value="zh-CN" data-href="/zh-CN/ExtensiveReading/Route/DRL-TE/" selected>简体中文</option></select></div><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Hesy</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="Symbols count total">123k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="Reading time total">1:51</span></div><div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZw==">NexT.Gemini</span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//js.njzjz.win/npm/velocity-animate@1/velocity.min.js"></script><script src="//js.njzjz.win/npm/velocity-animate@1/velocity.ui.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-next@8.0.0-rc.4/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-next@8.0.0-rc.4/source/js/motion.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-next@8.0.0-rc.4/source/js/next-boot.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-next@8.0.0-rc.4/source/js/bookmark.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-next@8.0.0-rc.4/source/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><script>if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }</script></body></html>